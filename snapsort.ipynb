{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORCnZvX16IK+2JTO8xr364",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5624e74b7f534c0fb29839351316b84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_121d00dbef2746eab00c31353cebfc24",
              "IPY_MODEL_ed08b7dc77844ea8aaf6f51cab83760b",
              "IPY_MODEL_5a041d324b5e471ab427115feb223953"
            ],
            "layout": "IPY_MODEL_da7e9a56072d4991b22c8487124a3be8"
          }
        },
        "121d00dbef2746eab00c31353cebfc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08dfff2a0654ef38f88bce9da9703d4",
            "placeholder": "​",
            "style": "IPY_MODEL_9b036f35b13c4382ae75675322c5ded7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ed08b7dc77844ea8aaf6f51cab83760b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864ca3b8dfae4f749ccbe86dd65eecc3",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13b4a573255040cfb4d6c6ea4edf5c52",
            "value": 48
          }
        },
        "5a041d324b5e471ab427115feb223953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb3b64574ac04332b7cc8f109f7a9803",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc6a216430a4adc87588f2f75c52b1c",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.79kB/s]"
          }
        },
        "da7e9a56072d4991b22c8487124a3be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08dfff2a0654ef38f88bce9da9703d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b036f35b13c4382ae75675322c5ded7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "864ca3b8dfae4f749ccbe86dd65eecc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b4a573255040cfb4d6c6ea4edf5c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb3b64574ac04332b7cc8f109f7a9803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc6a216430a4adc87588f2f75c52b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b27f5127c92348408a20a4ae82c2b2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fe77a6ab6774808a086504264810225",
              "IPY_MODEL_84116a34043f4a0d846e3309e5751f0e",
              "IPY_MODEL_9e7d68a1b2264c9e9d528df054b3b559"
            ],
            "layout": "IPY_MODEL_41766e502f4647839720b99dfe85fe88"
          }
        },
        "9fe77a6ab6774808a086504264810225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd35c1ab3fa492caadc12240e541690",
            "placeholder": "​",
            "style": "IPY_MODEL_9879085d7c3d403a9d875eaa1d9eea93",
            "value": "vocab.txt: 100%"
          }
        },
        "84116a34043f4a0d846e3309e5751f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e01ad340a3244c8850a50bf0aa393ba",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6378881a04b44ccbe34352d7c72d1db",
            "value": 231508
          }
        },
        "9e7d68a1b2264c9e9d528df054b3b559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38133cb908704c40bec7a6bdf17dc3fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f267a75d9c384b599ebaec63fd4dd945",
            "value": " 232k/232k [00:00&lt;00:00, 5.06MB/s]"
          }
        },
        "41766e502f4647839720b99dfe85fe88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd35c1ab3fa492caadc12240e541690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9879085d7c3d403a9d875eaa1d9eea93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e01ad340a3244c8850a50bf0aa393ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6378881a04b44ccbe34352d7c72d1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38133cb908704c40bec7a6bdf17dc3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f267a75d9c384b599ebaec63fd4dd945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8718337b684a4653afc3da39beb13763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9490c4557e394e4097892278b13b352e",
              "IPY_MODEL_3aab666bd00f4951839a08c1cee705aa",
              "IPY_MODEL_d2150793c3d840469f8cb0c685a82e1e"
            ],
            "layout": "IPY_MODEL_92beb3ecc0724c1f97654951a96baa21"
          }
        },
        "9490c4557e394e4097892278b13b352e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50fc6976ad34b4d98c1ec5f06ebb983",
            "placeholder": "​",
            "style": "IPY_MODEL_84302f4a553848d38a2c2eaf9c30350c",
            "value": "tokenizer.json: 100%"
          }
        },
        "3aab666bd00f4951839a08c1cee705aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24fefc7ca9ad4e2bb683978418255202",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6409cbce47249f09ac63a1da2077b61",
            "value": 466062
          }
        },
        "d2150793c3d840469f8cb0c685a82e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66acf25010c94178ba8854e63ad24b90",
            "placeholder": "​",
            "style": "IPY_MODEL_261b7c1263b44125935dc30c3fa21de0",
            "value": " 466k/466k [00:00&lt;00:00, 5.72MB/s]"
          }
        },
        "92beb3ecc0724c1f97654951a96baa21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50fc6976ad34b4d98c1ec5f06ebb983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84302f4a553848d38a2c2eaf9c30350c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24fefc7ca9ad4e2bb683978418255202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6409cbce47249f09ac63a1da2077b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66acf25010c94178ba8854e63ad24b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261b7c1263b44125935dc30c3fa21de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "558443534fdf49bdb9fb9f71d084b1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_218e79233966450e8ee8785e51684e77",
              "IPY_MODEL_2d953ed271944d76831e18c57c1df550",
              "IPY_MODEL_7a06e975483c4f93a2f0e476be3b92af"
            ],
            "layout": "IPY_MODEL_4f43b1dc39584130a9c68d8e46854268"
          }
        },
        "218e79233966450e8ee8785e51684e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e3afcb99974179bb1f221d02966c7a",
            "placeholder": "​",
            "style": "IPY_MODEL_08e468555a764d078df8a541adb86ee0",
            "value": "config.json: 100%"
          }
        },
        "2d953ed271944d76831e18c57c1df550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b442da220c3429786a9f763e94a8357",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b1ef512de3d43d5bdd52ff5063b4305",
            "value": 570
          }
        },
        "7a06e975483c4f93a2f0e476be3b92af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ca9ec6f0684927a5d0e496f59a6956",
            "placeholder": "​",
            "style": "IPY_MODEL_30e55fcdfae24f66a74b120b446cae3f",
            "value": " 570/570 [00:00&lt;00:00, 36.7kB/s]"
          }
        },
        "4f43b1dc39584130a9c68d8e46854268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e3afcb99974179bb1f221d02966c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e468555a764d078df8a541adb86ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b442da220c3429786a9f763e94a8357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1ef512de3d43d5bdd52ff5063b4305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50ca9ec6f0684927a5d0e496f59a6956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e55fcdfae24f66a74b120b446cae3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ff8ab8a57c45c4832173dd9345e792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4288a454d474e5faf4c340ace95ed67",
              "IPY_MODEL_bc18d1f54ffe4662b77de8fe8249be3f",
              "IPY_MODEL_857661e1be5245f99590a1240958abe7"
            ],
            "layout": "IPY_MODEL_b11c1ad5c7f843919d5bcc6620aa9603"
          }
        },
        "f4288a454d474e5faf4c340ace95ed67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62cefd2d1ae94f409f52f032867a3694",
            "placeholder": "​",
            "style": "IPY_MODEL_b5294d29852a492b854da5fb3af173ab",
            "value": "config.json: 100%"
          }
        },
        "bc18d1f54ffe4662b77de8fe8249be3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5702ccae32ae4767a77047812c3dd2fb",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0ba2b51bf164b6fb600a43b5529817b",
            "value": 483
          }
        },
        "857661e1be5245f99590a1240958abe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6772d70dd8245ed95ca956185061ee0",
            "placeholder": "​",
            "style": "IPY_MODEL_feadf1aabd484c508997deb915a802ab",
            "value": " 483/483 [00:00&lt;00:00, 8.39kB/s]"
          }
        },
        "b11c1ad5c7f843919d5bcc6620aa9603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62cefd2d1ae94f409f52f032867a3694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5294d29852a492b854da5fb3af173ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5702ccae32ae4767a77047812c3dd2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ba2b51bf164b6fb600a43b5529817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6772d70dd8245ed95ca956185061ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feadf1aabd484c508997deb915a802ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00e251cbf71f43bdba3cd086676d2e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fafc0e6730941cfa3cfdc6823bf67a0",
              "IPY_MODEL_0d639ab1b7654e248a684a2ea4bfc043",
              "IPY_MODEL_1b9898e22f3b4c40b8f13889f3236374"
            ],
            "layout": "IPY_MODEL_98a8d988fe7c438fb40821bb4e0df91f"
          }
        },
        "0fafc0e6730941cfa3cfdc6823bf67a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5400aac1baad4565b58631049b5dfd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_8cdee0c5767c431c89417c28a9fd5b6a",
            "value": "model.safetensors: 100%"
          }
        },
        "0d639ab1b7654e248a684a2ea4bfc043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312e4acc11a3414bb3574591cf356de7",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e73cf20ac0814be0b923adb358723aa2",
            "value": 267954768
          }
        },
        "1b9898e22f3b4c40b8f13889f3236374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_055a70e802164a42b9cb39fd2d70402e",
            "placeholder": "​",
            "style": "IPY_MODEL_45365210a7c74d44b948d40724ad19ba",
            "value": " 268M/268M [00:03&lt;00:00, 78.9MB/s]"
          }
        },
        "98a8d988fe7c438fb40821bb4e0df91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5400aac1baad4565b58631049b5dfd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdee0c5767c431c89417c28a9fd5b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312e4acc11a3414bb3574591cf356de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73cf20ac0814be0b923adb358723aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "055a70e802164a42b9cb39fd2d70402e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45365210a7c74d44b948d40724ad19ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e49a23c294947fe874dd55f18d97740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be77313fefa64096b75cdd8341b82bd0",
              "IPY_MODEL_7040d0bada1e43ccbddd22b71b8eadf6",
              "IPY_MODEL_f0773dd0f43b4db7be83995036ee2457"
            ],
            "layout": "IPY_MODEL_cdb5f1ed69884b1d8c7eb98b77ebd613"
          }
        },
        "be77313fefa64096b75cdd8341b82bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea9f4c846ea45c7ae66aa5ebe6f0e58",
            "placeholder": "​",
            "style": "IPY_MODEL_b8027e0dc5f64b05a9b43923acf8b854",
            "value": "config.json: 100%"
          }
        },
        "7040d0bada1e43ccbddd22b71b8eadf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b6577dfe6d4e4787ab99e6fde475ad",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04144e12297147a8bc8bfa538e5a570a",
            "value": 483
          }
        },
        "f0773dd0f43b4db7be83995036ee2457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af6dd5837cf407c8f0628dad9e37323",
            "placeholder": "​",
            "style": "IPY_MODEL_55502bc1f2ad4c129b39a59287e0fb16",
            "value": " 483/483 [00:00&lt;00:00, 49.4kB/s]"
          }
        },
        "cdb5f1ed69884b1d8c7eb98b77ebd613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea9f4c846ea45c7ae66aa5ebe6f0e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8027e0dc5f64b05a9b43923acf8b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66b6577dfe6d4e4787ab99e6fde475ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04144e12297147a8bc8bfa538e5a570a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4af6dd5837cf407c8f0628dad9e37323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55502bc1f2ad4c129b39a59287e0fb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06f9b30ff35f4328ac6f056ae7465f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_098098aca15749c0b4745a67a1d05d1a",
              "IPY_MODEL_7ea4d3357b2b445ca3189a76e63dbed9",
              "IPY_MODEL_0d7bacbe14ff4791b5b8cb48ce072395"
            ],
            "layout": "IPY_MODEL_bcb0f8d183c54df3aac9945f4d60531b"
          }
        },
        "098098aca15749c0b4745a67a1d05d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feaca0db8642415e9937743bb575922c",
            "placeholder": "​",
            "style": "IPY_MODEL_300d73de38e242de90d528972ef5be64",
            "value": "model.safetensors: 100%"
          }
        },
        "7ea4d3357b2b445ca3189a76e63dbed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da6ca9a01e74447af4afacf6e9e6f83",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aeb7a6777c94198b6eb5adc86b31faf",
            "value": 267954768
          }
        },
        "0d7bacbe14ff4791b5b8cb48ce072395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d923ec5306414e9d9407eec1d6b467b3",
            "placeholder": "​",
            "style": "IPY_MODEL_c959c1e7929a4b8eb1bb1a41b6573b71",
            "value": " 268M/268M [00:01&lt;00:00, 257MB/s]"
          }
        },
        "bcb0f8d183c54df3aac9945f4d60531b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feaca0db8642415e9937743bb575922c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300d73de38e242de90d528972ef5be64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da6ca9a01e74447af4afacf6e9e6f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aeb7a6777c94198b6eb5adc86b31faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d923ec5306414e9d9407eec1d6b467b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c959c1e7929a4b8eb1bb1a41b6573b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebafaee2ca094e12b04fb0a6357e159b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f30b01fdc52840b6aec8bf37a22072a8",
              "IPY_MODEL_aaa9f11ed112483da04f6b85717f0425",
              "IPY_MODEL_f34cbf855efb419bb5694a0f26e217a5"
            ],
            "layout": "IPY_MODEL_d5ba8d6a6d1f431db51b2372a62f1eab"
          }
        },
        "f30b01fdc52840b6aec8bf37a22072a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b266593f5ad4715b8d82069e7cc08df",
            "placeholder": "​",
            "style": "IPY_MODEL_44a8dd5b178345e588a7cbfa7427956f",
            "value": "model.safetensors: 100%"
          }
        },
        "aaa9f11ed112483da04f6b85717f0425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1701e67fa9c943c7828090a1150a29fc",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_896096b08ff14f20b415383f742587b3",
            "value": 440449768
          }
        },
        "f34cbf855efb419bb5694a0f26e217a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372cb8833d5e4a2f92651bd5264a68e7",
            "placeholder": "​",
            "style": "IPY_MODEL_18ba3fbbda064a8bab8ccd11e8b3d2d4",
            "value": " 440M/440M [00:07&lt;00:00, 55.6MB/s]"
          }
        },
        "d5ba8d6a6d1f431db51b2372a62f1eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b266593f5ad4715b8d82069e7cc08df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a8dd5b178345e588a7cbfa7427956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1701e67fa9c943c7828090a1150a29fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896096b08ff14f20b415383f742587b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "372cb8833d5e4a2f92651bd5264a68e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ba3fbbda064a8bab8ccd11e8b3d2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charaannn/snapsort/blob/main/snapsort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the dataset (Make sure train.csv is in the same directory or provide the full path)\n",
        "df = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Show first few rows\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing comments\n",
        "df = df.dropna(subset=[\"comment_text\"])\n",
        "\n",
        "# Define preprocessing function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
        "    text = text.strip()  # Remove leading/trailing spaces\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean_comment\"] = df[\"comment_text\"].apply(clean_text)\n",
        "\n",
        "# Display cleaned text\n",
        "print(\"\\nCleaned Text Samples:\")\n",
        "print(df[[\"comment_text\", \"clean_comment\"]].head())\n",
        "\n",
        "# Initialize BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize a sample comment\n",
        "sample_text = df[\"clean_comment\"].iloc[0]\n",
        "tokens = tokenizer(sample_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "print(\"\\nTokenized Sample Comment:\")\n",
        "print(tokens)\n",
        "\n",
        "# Convert labels (Toxic = 1, Non-Toxic = 0)\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "df[\"toxic_label\"] = df[label_cols].max(axis=1)  # If any label is 1, classify as toxic (1)\n",
        "\n",
        "# Display label distribution\n",
        "print(\"\\nLabel Distribution:\")\n",
        "print(df[\"toxic_label\"].value_counts())\n",
        "\n",
        "# Save preprocessed data\n",
        "df.to_csv(\"cleaned_train.csv\", index=False)\n",
        "print(\"\\nPreprocessed dataset saved as 'cleaned_train.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5624e74b7f534c0fb29839351316b84d",
            "121d00dbef2746eab00c31353cebfc24",
            "ed08b7dc77844ea8aaf6f51cab83760b",
            "5a041d324b5e471ab427115feb223953",
            "da7e9a56072d4991b22c8487124a3be8",
            "e08dfff2a0654ef38f88bce9da9703d4",
            "9b036f35b13c4382ae75675322c5ded7",
            "864ca3b8dfae4f749ccbe86dd65eecc3",
            "13b4a573255040cfb4d6c6ea4edf5c52",
            "eb3b64574ac04332b7cc8f109f7a9803",
            "8cc6a216430a4adc87588f2f75c52b1c",
            "b27f5127c92348408a20a4ae82c2b2ac",
            "9fe77a6ab6774808a086504264810225",
            "84116a34043f4a0d846e3309e5751f0e",
            "9e7d68a1b2264c9e9d528df054b3b559",
            "41766e502f4647839720b99dfe85fe88",
            "5cd35c1ab3fa492caadc12240e541690",
            "9879085d7c3d403a9d875eaa1d9eea93",
            "7e01ad340a3244c8850a50bf0aa393ba",
            "b6378881a04b44ccbe34352d7c72d1db",
            "38133cb908704c40bec7a6bdf17dc3fe",
            "f267a75d9c384b599ebaec63fd4dd945",
            "8718337b684a4653afc3da39beb13763",
            "9490c4557e394e4097892278b13b352e",
            "3aab666bd00f4951839a08c1cee705aa",
            "d2150793c3d840469f8cb0c685a82e1e",
            "92beb3ecc0724c1f97654951a96baa21",
            "b50fc6976ad34b4d98c1ec5f06ebb983",
            "84302f4a553848d38a2c2eaf9c30350c",
            "24fefc7ca9ad4e2bb683978418255202",
            "d6409cbce47249f09ac63a1da2077b61",
            "66acf25010c94178ba8854e63ad24b90",
            "261b7c1263b44125935dc30c3fa21de0",
            "558443534fdf49bdb9fb9f71d084b1f8",
            "218e79233966450e8ee8785e51684e77",
            "2d953ed271944d76831e18c57c1df550",
            "7a06e975483c4f93a2f0e476be3b92af",
            "4f43b1dc39584130a9c68d8e46854268",
            "78e3afcb99974179bb1f221d02966c7a",
            "08e468555a764d078df8a541adb86ee0",
            "5b442da220c3429786a9f763e94a8357",
            "9b1ef512de3d43d5bdd52ff5063b4305",
            "50ca9ec6f0684927a5d0e496f59a6956",
            "30e55fcdfae24f66a74b120b446cae3f"
          ]
        },
        "id": "GSR_HIxMmJUv",
        "outputId": "a27da5db-01c9-4b1b-d899-bc889cecfe10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "None\n",
            "\n",
            "Sample Data:\n",
            "                 id                                       comment_text  toxic  \\\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
            "\n",
            "   severe_toxic  obscene  threat  insult  identity_hate  \n",
            "0             0        0       0       0              0  \n",
            "1             0        0       0       0              0  \n",
            "2             0        0       0       0              0  \n",
            "3             0        0       0       0              0  \n",
            "4             0        0       0       0              0  \n",
            "\n",
            "Missing Values:\n",
            "id               0\n",
            "comment_text     0\n",
            "toxic            0\n",
            "severe_toxic     0\n",
            "obscene          0\n",
            "threat           0\n",
            "insult           0\n",
            "identity_hate    0\n",
            "dtype: int64\n",
            "\n",
            "Cleaned Text Samples:\n",
            "                                        comment_text  \\\n",
            "0  Explanation\\nWhy the edits made under my usern...   \n",
            "1  D'aww! He matches this background colour I'm s...   \n",
            "2  Hey man, I'm really not trying to edit war. It...   \n",
            "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
            "4  You, sir, are my hero. Any chance you remember...   \n",
            "\n",
            "                                       clean_comment  \n",
            "0  explanation why the edits made under my userna...  \n",
            "1  d aww he matches this background colour i m se...  \n",
            "2  hey man i m really not trying to edit war it s...  \n",
            "3  more i can t make any real suggestions on impr...  \n",
            "4  you sir are my hero any chance you remember wh...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5624e74b7f534c0fb29839351316b84d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b27f5127c92348408a20a4ae82c2b2ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8718337b684a4653afc3da39beb13763"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "558443534fdf49bdb9fb9f71d084b1f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenized Sample Comment:\n",
            "{'input_ids': tensor([[  101,  7526,  2339,  1996, 10086,  2015,  2081,  2104,  2026,  5310,\n",
            "         18442, 13076, 12392,  2050,  5470,  2020, 16407,  2027,  4694,  1056,\n",
            "          3158,  9305, 22556,  2074,  8503,  2006,  2070,  3806,  2044,  1045,\n",
            "          5444,  2012,  2047,  2259, 14421,  6904,  2278,  1998,  3531,  2123,\n",
            "          1056,  6366,  1996, 23561,  2013,  1996,  2831,  3931,  2144,  1045,\n",
            "          1049,  3394,  2085,  6486, 16327,  4229,  2676,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "\n",
            "Label Distribution:\n",
            "toxic_label\n",
            "0    143346\n",
            "1     16225\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Preprocessed dataset saved as 'cleaned_train.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uPHO_hLmnMs",
        "outputId": "e6bc8225-b66c-4d27-e30d-5f17009f05f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id               object\n",
            "comment_text     object\n",
            "toxic             int64\n",
            "severe_toxic      int64\n",
            "obscene           int64\n",
            "threat            int64\n",
            "insult            int64\n",
            "identity_hate     int64\n",
            "clean_comment    object\n",
            "toxic_label       int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, index):\n",
        "    comment = str(self.data.loc[index, \"comment_text\"])  # Use the correct text column\n",
        "\n",
        "    # Select only numerical label columns\n",
        "    label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "    labels = self.data.loc[index, label_cols].values.astype(float)  # Ensure labels are numeric\n",
        "\n",
        "    # Tokenize the comment\n",
        "    tokens = self.tokenizer(\n",
        "        comment,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=self.max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
        "        \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
        "        \"labels\": torch.tensor(labels, dtype=torch.float)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "8nXo6a6ynAL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEOpJ1bntKK",
        "outputId": "930df0ae-ddb4-4d37-f4e7-f948e0acd004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())  # Check column names\n",
        "print(df.dtypes)  # Check data types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMwgQlHho2eC",
        "outputId": "044ebc4c-eb82-4e4c-a150-5fe5d64dd6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 id                                       comment_text  toxic  \\\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
            "\n",
            "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
            "0             0        0       0       0              0   \n",
            "1             0        0       0       0              0   \n",
            "2             0        0       0       0              0   \n",
            "3             0        0       0       0              0   \n",
            "4             0        0       0       0              0   \n",
            "\n",
            "                                       clean_comment  toxic_label  \n",
            "0  explanation why the edits made under my userna...            0  \n",
            "1  d aww he matches this background colour i m se...            0  \n",
            "2  hey man i m really not trying to edit war it s...            0  \n",
            "3  more i can t make any real suggestions on impr...            0  \n",
            "4  you sir are my hero any chance you remember wh...            0  \n",
            "id               object\n",
            "comment_text     object\n",
            "toxic             int64\n",
            "severe_toxic      int64\n",
            "obscene           int64\n",
            "threat            int64\n",
            "insult            int64\n",
            "identity_hate     int64\n",
            "clean_comment    object\n",
            "toxic_label       int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToxicCommentDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Define the label columns explicitly\n",
        "        self.label_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "        # Ensure labels are floats (for PyTorch)\n",
        "        self.data[self.label_columns] = self.data[self.label_columns].astype(float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment = str(self.data.loc[index, \"comment_text\"])  # Get text\n",
        "        labels = torch.tensor(self.data.loc[index, self.label_columns].values.astype(float), dtype=torch.float)\n",
        "\n",
        "\n",
        "        # Tokenize text\n",
        "        encoding = self.tokenizer(\n",
        "            comment,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "# Reload dataset with fixed code\n",
        "dataset = ToxicCommentDataset(df, tokenizer)\n",
        "\n",
        "# Check a sample\n",
        "print(dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W154dEvIpJWV",
        "outputId": "39478d7e-896d-4714-f770-8eba3e4eed48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([  101,  7526,  2339,  1996, 10086,  2015,  2081,  2104,  2026,  5310,\n",
            "        18442, 13076, 12392,  2050,  5470,  2020, 16407,  1029,  2027,  4694,\n",
            "         1005,  1056,  3158,  9305, 22556,  1010,  2074,  8503,  2006,  2070,\n",
            "         3806,  2044,  1045,  5444,  2012,  2047,  2259, 14421,  6904,  2278,\n",
            "         1012,  1998,  3531,  2123,  1005,  1056,  6366,  1996, 23561,  2013,\n",
            "         1996,  2831,  3931,  2144,  1045,  1005,  1049,  3394,  2085,  1012,\n",
            "         6486,  1012, 16327,  1012,  4229,  1012,  2676,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([0., 0., 0., 0., 0., 0.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 16  # Adjust based on your system\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Check one batch\n",
        "for batch in train_dataloader:\n",
        "    print(batch)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEzHxd3fqU9I",
        "outputId": "dc82927a-03ed-4726-c9d6-bfbdafb6a628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1000, 1045,  ...,    0,    0,    0],\n",
            "        [ 101, 2017, 2064,  ...,    0,    0,    0],\n",
            "        [ 101, 1045, 6592,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2313, 3985,  ...,    0,    0,    0],\n",
            "        [ 101, 4487, 9284,  ...,    0,    0,    0],\n",
            "        [ 101, 2175, 3805,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertModel\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class ToxicCommentClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(ToxicCommentClassifier, self).__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token representation\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "NW9R3Yjvqfp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 6  # Adjust based on your dataset\n",
        "model = ToxicCommentClassifier(num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "37ff8ab8a57c45c4832173dd9345e792",
            "f4288a454d474e5faf4c340ace95ed67",
            "bc18d1f54ffe4662b77de8fe8249be3f",
            "857661e1be5245f99590a1240958abe7",
            "b11c1ad5c7f843919d5bcc6620aa9603",
            "62cefd2d1ae94f409f52f032867a3694",
            "b5294d29852a492b854da5fb3af173ab",
            "5702ccae32ae4767a77047812c3dd2fb",
            "c0ba2b51bf164b6fb600a43b5529817b",
            "e6772d70dd8245ed95ca956185061ee0",
            "feadf1aabd484c508997deb915a802ab",
            "00e251cbf71f43bdba3cd086676d2e79",
            "0fafc0e6730941cfa3cfdc6823bf67a0",
            "0d639ab1b7654e248a684a2ea4bfc043",
            "1b9898e22f3b4c40b8f13889f3236374",
            "98a8d988fe7c438fb40821bb4e0df91f",
            "5400aac1baad4565b58631049b5dfd9d",
            "8cdee0c5767c431c89417c28a9fd5b6a",
            "312e4acc11a3414bb3574591cf356de7",
            "e73cf20ac0814be0b923adb358723aa2",
            "055a70e802164a42b9cb39fd2d70402e",
            "45365210a7c74d44b948d40724ad19ba"
          ]
        },
        "id": "RoQU338lqhmX",
        "outputId": "b106b469-07de-480f-d361-3eb0d64ac337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ff8ab8a57c45c4832173dd9345e792"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00e251cbf71f43bdba3cd086676d2e79"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "criterion = BCEWithLogitsLoss()  # For multi-label classification\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n"
      ],
      "metadata": {
        "id": "ZjBEXhqbqtOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlgL2nMGqv0a",
        "outputId": "15866bdd-9c6f-492f-c61a-9ca6fa938264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToxicCommentClassifier(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True\n",
        "print(torch.cuda.get_device_name(0))  # Should show \"Tesla T4\" or similar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCI6hGrsO6n",
        "outputId": "e025a605-85d6-4044-e8f6-0db1b6e4637d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Define the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=6)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867,
          "referenced_widgets": [
            "5e49a23c294947fe874dd55f18d97740",
            "be77313fefa64096b75cdd8341b82bd0",
            "7040d0bada1e43ccbddd22b71b8eadf6",
            "f0773dd0f43b4db7be83995036ee2457",
            "cdb5f1ed69884b1d8c7eb98b77ebd613",
            "cea9f4c846ea45c7ae66aa5ebe6f0e58",
            "b8027e0dc5f64b05a9b43923acf8b854",
            "66b6577dfe6d4e4787ab99e6fde475ad",
            "04144e12297147a8bc8bfa538e5a570a",
            "4af6dd5837cf407c8f0628dad9e37323",
            "55502bc1f2ad4c129b39a59287e0fb16",
            "06f9b30ff35f4328ac6f056ae7465f5d",
            "098098aca15749c0b4745a67a1d05d1a",
            "7ea4d3357b2b445ca3189a76e63dbed9",
            "0d7bacbe14ff4791b5b8cb48ce072395",
            "bcb0f8d183c54df3aac9945f4d60531b",
            "feaca0db8642415e9937743bb575922c",
            "300d73de38e242de90d528972ef5be64",
            "1da6ca9a01e74447af4afacf6e9e6f83",
            "7aeb7a6777c94198b6eb5adc86b31faf",
            "d923ec5306414e9d9407eec1d6b467b3",
            "c959c1e7929a4b8eb1bb1a41b6573b71"
          ]
        },
        "id": "WW6B6e3Wsj3B",
        "outputId": "1b3fe62a-4a4d-4f1b-d55b-95df3954603d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e49a23c294947fe874dd55f18d97740"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f9b30ff35f4328ac6f056ae7465f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    input_ids, attention_mask, labels = [t.to(device) for t in batch]"
      ],
      "metadata": {
        "id": "ARnwuA71thFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(input_ids[idx]),\n",
        "            'attention_mask': torch.tensor(attention_mask[idx]),\n",
        "            'labels': torch.tensor(labels[idx])\n",
        "        }\n"
      ],
      "metadata": {
        "id": "GCbd5Suctkdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example data (replace with your dataset)\n",
        "train_inputs = torch.randint(0, 30522, (100, 128))  # 100 samples, each with 128 tokens\n",
        "train_masks = torch.ones(100, 128)  # Attention masks (all ones for simplicity)\n",
        "train_labels = torch.randint(0, 6, (100,))  # 100 labels (assuming 6 classes)\n",
        "\n",
        "# Create TensorDataset (returns a tuple, not a dictionary)\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Define DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define a simple model for testing (replace with your model)\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(128, num_classes)  # Simple linear classifier\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.fc(input_ids.float())  # Dummy forward pass\n",
        "\n",
        "model = SimpleModel()  # Initialize model\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack batch correctly (since TensorDataset returns a tuple)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = (\n",
        "            input_ids.to(device),\n",
        "            attention_mask.to(device),\n",
        "            labels.to(device),\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_Q6aQXuAm-",
        "outputId": "37ce82d0-a141-41e4-d40a-8692c7aea342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 69949.0659\n",
            "Epoch 2/3 - Loss: 64656.6528\n",
            "Epoch 3/3 - Loss: 62143.0940\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example data (replace with your dataset)\n",
        "train_inputs = torch.randint(0, 30522, (100, 128)).float()  # Convert to float\n",
        "train_masks = torch.ones(100, 128).float()  # Convert to float\n",
        "train_labels = torch.randint(0, 6, (100,))  # Labels (no need to convert)\n",
        "\n",
        "# Create TensorDataset\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Define DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define a simple model for testing (replace with your model)\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(128, num_classes)  # Simple linear classifier\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.fc(input_ids)  # No need to apply softmax\n",
        "\n",
        "model = SimpleModel()  # Initialize model\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack batch correctly\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = (\n",
        "            input_ids.to(device).float(),\n",
        "            attention_mask.to(device).float(),\n",
        "            labels.to(device),\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGHqUWrzuT7O",
        "outputId": "75ad793d-6027-4608-d836-03782162883c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 79135.0391\n",
            "Epoch 2/3 - Loss: 78494.4404\n",
            "Epoch 3/3 - Loss: 85267.2095\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example data (replace with real dataset)\n",
        "train_inputs = torch.randint(0, 30522, (100, 128)).float()  # Convert to float\n",
        "train_masks = torch.ones(100, 128).float()  # Convert to float\n",
        "train_labels = torch.randint(0, 6, (100,))  # Labels (integer)\n",
        "\n",
        "# Create TensorDataset\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Define DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define a better model\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)  # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.fc(input_ids)  # No softmax\n",
        "\n",
        "model = ImprovedModel()  # Initialize model\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack batch correctly\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = (\n",
        "            input_ids.to(device).float(),\n",
        "            attention_mask.to(device).float(),\n",
        "            labels.to(device).long(),  # Convert labels to LongTensor\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUrmVbVOuod8",
        "outputId": "68e09902-226d-4b9a-e08f-43fcb78f2be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 49406.1885\n",
            "Epoch 2/3 - Loss: 46548.6963\n",
            "Epoch 3/3 - Loss: 38341.0500\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Example data (Replace with real dataset)\n",
        "train_inputs = torch.randint(0, 30522, (100, 128)).float()\n",
        "train_masks = torch.ones(100, 128).float()\n",
        "train_labels = torch.randint(0, 6, (100,))\n",
        "\n",
        "# Create TensorDataset\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Define DataLoader with larger batch size\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define a better model\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.LayerNorm(256),  # Normalize activations\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),  # Prevent overfitting\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.fc(input_ids)\n",
        "\n",
        "# Initialize model\n",
        "model = ImprovedModel()\n",
        "\n",
        "# Better optimizer & loss function\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, eps=1e-8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack batch correctly\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = (\n",
        "            input_ids.to(device).float(),\n",
        "            attention_mask.to(device).float(),\n",
        "            labels.to(device).long(),\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udUW-xxZuzSS",
        "outputId": "99103305-0f5c-465e-aaad-584e75e02f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 7.4001\n",
            "Epoch 2/5 - Loss: 7.4776\n",
            "Epoch 3/5 - Loss: 7.1901\n",
            "Epoch 4/5 - Loss: 6.9545\n",
            "Epoch 5/5 - Loss: 7.2168\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Example comments (replace with real dataset)\n",
        "comments = [\n",
        "    \"This is the best day ever!\",\n",
        "    \"I hate this so much.\",\n",
        "    \"You are amazing!\",\n",
        "    \"This is terrible, never again!\",\n",
        "    \"Neutral opinion here.\",\n",
        "]\n",
        "\n",
        "# Tokenize comments\n",
        "encodings = tokenizer(comments, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "train_inputs, train_masks = encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
        "\n",
        "# Example labels (1 = toxic, 0 = neutral)\n",
        "train_labels = torch.tensor([0, 1, 0, 1, 0])\n",
        "\n",
        "# Create TensorDataset\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Define DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Define Model with BERT\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(768, num_classes)  # BERT's hidden size is 768\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # [batch_size, 768]\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)  # [batch_size, num_classes]\n",
        "        return logits\n",
        "\n",
        "# Initialize Model\n",
        "model = BertClassifier()\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8, weight_decay=1e-4)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = (\n",
        "            input_ids.to(device),\n",
        "            attention_mask.to(device),\n",
        "            labels.to(device)\n",
        "        )\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)  # Logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f} - Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "ebafaee2ca094e12b04fb0a6357e159b",
            "f30b01fdc52840b6aec8bf37a22072a8",
            "aaa9f11ed112483da04f6b85717f0425",
            "f34cbf855efb419bb5694a0f26e217a5",
            "d5ba8d6a6d1f431db51b2372a62f1eab",
            "5b266593f5ad4715b8d82069e7cc08df",
            "44a8dd5b178345e588a7cbfa7427956f",
            "1701e67fa9c943c7828090a1150a29fc",
            "896096b08ff14f20b415383f742587b3",
            "372cb8833d5e4a2f92651bd5264a68e7",
            "18ba3fbbda064a8bab8ccd11e8b3d2d4"
          ]
        },
        "id": "TFKpe24ewBCB",
        "outputId": "23a597da-0876-4753-8670-02f9b945c9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebafaee2ca094e12b04fb0a6357e159b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 1.9835 - Accuracy: 40.00%\n",
            "Epoch 2/5 - Loss: 1.8305 - Accuracy: 60.00%\n",
            "Epoch 3/5 - Loss: 1.2910 - Accuracy: 100.00%\n",
            "Epoch 4/5 - Loss: 0.9263 - Accuracy: 100.00%\n",
            "Epoch 5/5 - Loss: 1.2160 - Accuracy: 100.00%\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/test.csv\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmS5rn-7xM7h",
        "outputId": "fa6b9582-5292-486c-e256-773fcf3a6972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'comment_text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Define the BERT-based classifier\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Load pre-trained BERT model\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(768, num_classes)  # 768 is BERT's hidden size\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Use the pooler output for classification\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertClassifier(num_classes=2)\n",
        "\n",
        "# Optionally load your trained weights:\n",
        "# model.load_state_dict(torch.load(\"path_to_your_trained_model.pt\"))\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Load your test CSV (ensure the file is in the same directory or provide full path)\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Check the columns to be sure – expected columns: \"id\" and \"comment_text\"\n",
        "print(\"Test CSV Columns:\", df_test.columns)\n",
        "\n",
        "# Get list of comments from the \"comment_text\" column\n",
        "comments = df_test[\"comment_text\"].tolist()\n",
        "\n",
        "# Tokenize the comments using BERT tokenizer\n",
        "encodings = tokenizer(comments, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "input_ids = encodings[\"input_ids\"].to(device)\n",
        "attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask)\n",
        "    # For binary classification, argmax gives the predicted label (0 or 1)\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# Display predictions for each comment\n",
        "for comment, pred in zip(comments, preds.cpu().numpy()):\n",
        "    print(f\"Comment: {comment}\\nPrediction: {pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "collapsed": true,
        "id": "zFS21gt_xlEW",
        "outputId": "7f83206a-fd56-45b7-d1f9-d16f87ab1a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CSV Columns: Index(['id', 'comment_text'], dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 56.09 GiB. GPU 0 has a total capacity of 14.74 GiB of which 11.07 GiB is free. Process 4102 has 3.66 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 233.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6ab5296e0857>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# For binary classification, argmax gives the predicted label (0 or 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-6ab5296e0857>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Use the pooler output for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 56.09 GiB. GPU 0 has a total capacity of 14.74 GiB of which 11.07 GiB is free. Process 4102 has 3.66 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 233.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the BERT-based classifier\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Load pre-trained BERT model\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(768, num_classes)  # BERT's hidden size is 768\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # [batch_size, 768]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)  # [batch_size, num_classes]\n",
        "        return logits\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertClassifier(num_classes=2)\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Load test CSV\n",
        "df_test = pd.read_csv(\"test.csv\")  # CSV should have columns like 'id' and 'comment_text'\n",
        "print(\"Columns in test CSV:\", df_test.columns)\n",
        "\n",
        "# Get comments from the 'comment_text' column\n",
        "comments = df_test[\"comment_text\"].tolist()\n",
        "\n",
        "# Tokenize the comments\n",
        "encodings = tokenizer(comments, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "# Create a TensorDataset and DataLoader for inference\n",
        "test_dataset = TensorDataset(input_ids, attention_mask)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Run inference in batches\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch_input_ids, batch_attention_mask = [tensor.to(device) for tensor in batch]\n",
        "        outputs = model(batch_input_ids, batch_attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "# Optionally, add predictions to the DataFrame\n",
        "df_test['predicted_label'] = predictions\n",
        "\n",
        "# Print out predictions for verification\n",
        "print(df_test[['id', 'comment_text', 'predicted_label']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "sSGFw2pR0Uah",
        "outputId": "0818d1ad-f85c-4b4b-b2c3-7fe67fd64855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in test CSV: Index(['id', 'comment_text'], dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-62351e8b514b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Optionally, add predictions to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the BERT-based classifier\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(768, num_classes)  # BERT's hidden size is 768\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # [batch_size, 768]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)  # [batch_size, num_classes]\n",
        "        return logits\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertClassifier(num_classes=2)\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Load test CSV\n",
        "df_test = pd.read_csv(\"test.csv\")  # CSV should have columns like 'id' and 'comment_text'\n",
        "print(\"✅ Loaded test.csv successfully!\")\n",
        "\n",
        "# Ensure column 'comment_text' exists\n",
        "if \"comment_text\" not in df_test.columns:\n",
        "    raise KeyError(\"Column 'comment_text' not found in the CSV file!\")\n",
        "\n",
        "# Get comments from 'comment_text' column\n",
        "comments = df_test[\"comment_text\"].astype(str).tolist()\n",
        "\n",
        "# Tokenize the comments\n",
        "encodings = tokenizer(comments, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "# Create a TensorDataset and DataLoader for inference\n",
        "test_dataset = TensorDataset(input_ids, attention_mask)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Run inference in batches\n",
        "predictions = []\n",
        "print(\"✅ Starting inference...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_dataloader):\n",
        "        batch_input_ids, batch_attention_mask = [tensor.to(device) for tensor in batch]\n",
        "\n",
        "        outputs = model(batch_input_ids, batch_attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Print progress every 10 batches\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"✅ Processed {batch_idx * len(batch_input_ids)} comments...\")\n",
        "\n",
        "# Add predictions to the DataFrame\n",
        "df_test[\"predicted_label\"] = predictions\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "df_test.to_csv(\"test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"✅ Inference complete! Predictions saved to 'test_predictions.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gt9BKSF1f-5",
        "outputId": "ab1f9f14-f214-45c5-b147-6f7d66ddc9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded test.csv successfully!\n",
            "✅ Starting inference...\n",
            "✅ Processed 0 comments...\n",
            "✅ Processed 40 comments...\n",
            "✅ Processed 80 comments...\n",
            "✅ Processed 120 comments...\n",
            "✅ Processed 160 comments...\n",
            "✅ Processed 200 comments...\n",
            "✅ Processed 240 comments...\n",
            "✅ Processed 280 comments...\n",
            "✅ Processed 320 comments...\n",
            "✅ Processed 360 comments...\n",
            "✅ Processed 400 comments...\n",
            "✅ Processed 440 comments...\n",
            "✅ Processed 480 comments...\n",
            "✅ Processed 520 comments...\n",
            "✅ Processed 560 comments...\n",
            "✅ Processed 600 comments...\n",
            "✅ Processed 640 comments...\n",
            "✅ Processed 680 comments...\n",
            "✅ Processed 720 comments...\n",
            "✅ Processed 760 comments...\n",
            "✅ Processed 800 comments...\n",
            "✅ Processed 840 comments...\n",
            "✅ Processed 880 comments...\n",
            "✅ Processed 920 comments...\n",
            "✅ Processed 960 comments...\n",
            "✅ Processed 1000 comments...\n",
            "✅ Processed 1040 comments...\n",
            "✅ Processed 1080 comments...\n",
            "✅ Processed 1120 comments...\n",
            "✅ Processed 1160 comments...\n",
            "✅ Processed 1200 comments...\n",
            "✅ Processed 1240 comments...\n",
            "✅ Processed 1280 comments...\n",
            "✅ Processed 1320 comments...\n",
            "✅ Processed 1360 comments...\n",
            "✅ Processed 1400 comments...\n",
            "✅ Processed 1440 comments...\n",
            "✅ Processed 1480 comments...\n",
            "✅ Processed 1520 comments...\n",
            "✅ Processed 1560 comments...\n",
            "✅ Processed 1600 comments...\n",
            "✅ Processed 1640 comments...\n",
            "✅ Processed 1680 comments...\n",
            "✅ Processed 1720 comments...\n",
            "✅ Processed 1760 comments...\n",
            "✅ Processed 1800 comments...\n",
            "✅ Processed 1840 comments...\n",
            "✅ Processed 1880 comments...\n",
            "✅ Processed 1920 comments...\n",
            "✅ Processed 1960 comments...\n",
            "✅ Processed 2000 comments...\n",
            "✅ Processed 2040 comments...\n",
            "✅ Processed 2080 comments...\n",
            "✅ Processed 2120 comments...\n",
            "✅ Processed 2160 comments...\n",
            "✅ Processed 2200 comments...\n",
            "✅ Processed 2240 comments...\n",
            "✅ Processed 2280 comments...\n",
            "✅ Processed 2320 comments...\n",
            "✅ Processed 2360 comments...\n",
            "✅ Processed 2400 comments...\n",
            "✅ Processed 2440 comments...\n",
            "✅ Processed 2480 comments...\n",
            "✅ Processed 2520 comments...\n",
            "✅ Processed 2560 comments...\n",
            "✅ Processed 2600 comments...\n",
            "✅ Processed 2640 comments...\n",
            "✅ Processed 2680 comments...\n",
            "✅ Processed 2720 comments...\n",
            "✅ Processed 2760 comments...\n",
            "✅ Processed 2800 comments...\n",
            "✅ Processed 2840 comments...\n",
            "✅ Processed 2880 comments...\n",
            "✅ Processed 2920 comments...\n",
            "✅ Processed 2960 comments...\n",
            "✅ Processed 3000 comments...\n",
            "✅ Processed 3040 comments...\n",
            "✅ Processed 3080 comments...\n",
            "✅ Processed 3120 comments...\n",
            "✅ Processed 3160 comments...\n",
            "✅ Processed 3200 comments...\n",
            "✅ Processed 3240 comments...\n",
            "✅ Processed 3280 comments...\n",
            "✅ Processed 3320 comments...\n",
            "✅ Processed 3360 comments...\n",
            "✅ Processed 3400 comments...\n",
            "✅ Processed 3440 comments...\n",
            "✅ Processed 3480 comments...\n",
            "✅ Processed 3520 comments...\n",
            "✅ Processed 3560 comments...\n",
            "✅ Processed 3600 comments...\n",
            "✅ Processed 3640 comments...\n",
            "✅ Processed 3680 comments...\n",
            "✅ Processed 3720 comments...\n",
            "✅ Processed 3760 comments...\n",
            "✅ Processed 3800 comments...\n",
            "✅ Processed 3840 comments...\n",
            "✅ Processed 3880 comments...\n",
            "✅ Processed 3920 comments...\n",
            "✅ Processed 3960 comments...\n",
            "✅ Processed 4000 comments...\n",
            "✅ Processed 4040 comments...\n",
            "✅ Processed 4080 comments...\n",
            "✅ Processed 4120 comments...\n",
            "✅ Processed 4160 comments...\n",
            "✅ Processed 4200 comments...\n",
            "✅ Processed 4240 comments...\n",
            "✅ Processed 4280 comments...\n",
            "✅ Processed 4320 comments...\n",
            "✅ Processed 4360 comments...\n",
            "✅ Processed 4400 comments...\n",
            "✅ Processed 4440 comments...\n",
            "✅ Processed 4480 comments...\n",
            "✅ Processed 4520 comments...\n",
            "✅ Processed 4560 comments...\n",
            "✅ Processed 4600 comments...\n",
            "✅ Processed 4640 comments...\n",
            "✅ Processed 4680 comments...\n",
            "✅ Processed 4720 comments...\n",
            "✅ Processed 4760 comments...\n",
            "✅ Processed 4800 comments...\n",
            "✅ Processed 4840 comments...\n",
            "✅ Processed 4880 comments...\n",
            "✅ Processed 4920 comments...\n",
            "✅ Processed 4960 comments...\n",
            "✅ Processed 5000 comments...\n",
            "✅ Processed 5040 comments...\n",
            "✅ Processed 5080 comments...\n",
            "✅ Processed 5120 comments...\n",
            "✅ Processed 5160 comments...\n",
            "✅ Processed 5200 comments...\n",
            "✅ Processed 5240 comments...\n",
            "✅ Processed 5280 comments...\n",
            "✅ Processed 5320 comments...\n",
            "✅ Processed 5360 comments...\n",
            "✅ Processed 5400 comments...\n",
            "✅ Processed 5440 comments...\n",
            "✅ Processed 5480 comments...\n",
            "✅ Processed 5520 comments...\n",
            "✅ Processed 5560 comments...\n",
            "✅ Processed 5600 comments...\n",
            "✅ Processed 5640 comments...\n",
            "✅ Processed 5680 comments...\n",
            "✅ Processed 5720 comments...\n",
            "✅ Processed 5760 comments...\n",
            "✅ Processed 5800 comments...\n",
            "✅ Processed 5840 comments...\n",
            "✅ Processed 5880 comments...\n",
            "✅ Processed 5920 comments...\n",
            "✅ Processed 5960 comments...\n",
            "✅ Processed 6000 comments...\n",
            "✅ Processed 6040 comments...\n",
            "✅ Processed 6080 comments...\n",
            "✅ Processed 6120 comments...\n",
            "✅ Processed 6160 comments...\n",
            "✅ Processed 6200 comments...\n",
            "✅ Processed 6240 comments...\n",
            "✅ Processed 6280 comments...\n",
            "✅ Processed 6320 comments...\n",
            "✅ Processed 6360 comments...\n",
            "✅ Processed 6400 comments...\n",
            "✅ Processed 6440 comments...\n",
            "✅ Processed 6480 comments...\n",
            "✅ Processed 6520 comments...\n",
            "✅ Processed 6560 comments...\n",
            "✅ Processed 6600 comments...\n",
            "✅ Processed 6640 comments...\n",
            "✅ Processed 6680 comments...\n",
            "✅ Processed 6720 comments...\n",
            "✅ Processed 6760 comments...\n",
            "✅ Processed 6800 comments...\n",
            "✅ Processed 6840 comments...\n",
            "✅ Processed 6880 comments...\n",
            "✅ Processed 6920 comments...\n",
            "✅ Processed 6960 comments...\n",
            "✅ Processed 7000 comments...\n",
            "✅ Processed 7040 comments...\n",
            "✅ Processed 7080 comments...\n",
            "✅ Processed 7120 comments...\n",
            "✅ Processed 7160 comments...\n",
            "✅ Processed 7200 comments...\n",
            "✅ Processed 7240 comments...\n",
            "✅ Processed 7280 comments...\n",
            "✅ Processed 7320 comments...\n",
            "✅ Processed 7360 comments...\n",
            "✅ Processed 7400 comments...\n",
            "✅ Processed 7440 comments...\n",
            "✅ Processed 7480 comments...\n",
            "✅ Processed 7520 comments...\n",
            "✅ Processed 7560 comments...\n",
            "✅ Processed 7600 comments...\n",
            "✅ Processed 7640 comments...\n",
            "✅ Processed 7680 comments...\n",
            "✅ Processed 7720 comments...\n",
            "✅ Processed 7760 comments...\n",
            "✅ Processed 7800 comments...\n",
            "✅ Processed 7840 comments...\n",
            "✅ Processed 7880 comments...\n",
            "✅ Processed 7920 comments...\n",
            "✅ Processed 7960 comments...\n",
            "✅ Processed 8000 comments...\n",
            "✅ Processed 8040 comments...\n",
            "✅ Processed 8080 comments...\n",
            "✅ Processed 8120 comments...\n",
            "✅ Processed 8160 comments...\n",
            "✅ Processed 8200 comments...\n",
            "✅ Processed 8240 comments...\n",
            "✅ Processed 8280 comments...\n",
            "✅ Processed 8320 comments...\n",
            "✅ Processed 8360 comments...\n",
            "✅ Processed 8400 comments...\n",
            "✅ Processed 8440 comments...\n",
            "✅ Processed 8480 comments...\n",
            "✅ Processed 8520 comments...\n",
            "✅ Processed 8560 comments...\n",
            "✅ Processed 8600 comments...\n",
            "✅ Processed 8640 comments...\n",
            "✅ Processed 8680 comments...\n",
            "✅ Processed 8720 comments...\n",
            "✅ Processed 8760 comments...\n",
            "✅ Processed 8800 comments...\n",
            "✅ Processed 8840 comments...\n",
            "✅ Processed 8880 comments...\n",
            "✅ Processed 8920 comments...\n",
            "✅ Processed 8960 comments...\n",
            "✅ Processed 9000 comments...\n",
            "✅ Processed 9040 comments...\n",
            "✅ Processed 9080 comments...\n",
            "✅ Processed 9120 comments...\n",
            "✅ Processed 9160 comments...\n",
            "✅ Processed 9200 comments...\n",
            "✅ Processed 9240 comments...\n",
            "✅ Processed 9280 comments...\n",
            "✅ Processed 9320 comments...\n",
            "✅ Processed 9360 comments...\n",
            "✅ Processed 9400 comments...\n",
            "✅ Processed 9440 comments...\n",
            "✅ Processed 9480 comments...\n",
            "✅ Processed 9520 comments...\n",
            "✅ Processed 9560 comments...\n",
            "✅ Processed 9600 comments...\n",
            "✅ Processed 9640 comments...\n",
            "✅ Processed 9680 comments...\n",
            "✅ Processed 9720 comments...\n",
            "✅ Processed 9760 comments...\n",
            "✅ Processed 9800 comments...\n",
            "✅ Processed 9840 comments...\n",
            "✅ Processed 9880 comments...\n",
            "✅ Processed 9920 comments...\n",
            "✅ Processed 9960 comments...\n",
            "✅ Processed 10000 comments...\n",
            "✅ Processed 10040 comments...\n",
            "✅ Processed 10080 comments...\n",
            "✅ Processed 10120 comments...\n",
            "✅ Processed 10160 comments...\n",
            "✅ Processed 10200 comments...\n",
            "✅ Processed 10240 comments...\n",
            "✅ Processed 10280 comments...\n",
            "✅ Processed 10320 comments...\n",
            "✅ Processed 10360 comments...\n",
            "✅ Processed 10400 comments...\n",
            "✅ Processed 10440 comments...\n",
            "✅ Processed 10480 comments...\n",
            "✅ Processed 10520 comments...\n",
            "✅ Processed 10560 comments...\n",
            "✅ Processed 10600 comments...\n",
            "✅ Processed 10640 comments...\n",
            "✅ Processed 10680 comments...\n",
            "✅ Processed 10720 comments...\n",
            "✅ Processed 10760 comments...\n",
            "✅ Processed 10800 comments...\n",
            "✅ Processed 10840 comments...\n",
            "✅ Processed 10880 comments...\n",
            "✅ Processed 10920 comments...\n",
            "✅ Processed 10960 comments...\n",
            "✅ Processed 11000 comments...\n",
            "✅ Processed 11040 comments...\n",
            "✅ Processed 11080 comments...\n",
            "✅ Processed 11120 comments...\n",
            "✅ Processed 11160 comments...\n",
            "✅ Processed 11200 comments...\n",
            "✅ Processed 11240 comments...\n",
            "✅ Processed 11280 comments...\n",
            "✅ Processed 11320 comments...\n",
            "✅ Processed 11360 comments...\n",
            "✅ Processed 11400 comments...\n",
            "✅ Processed 11440 comments...\n",
            "✅ Processed 11480 comments...\n",
            "✅ Processed 11520 comments...\n",
            "✅ Processed 11560 comments...\n",
            "✅ Processed 11600 comments...\n",
            "✅ Processed 11640 comments...\n",
            "✅ Processed 11680 comments...\n",
            "✅ Processed 11720 comments...\n",
            "✅ Processed 11760 comments...\n",
            "✅ Processed 11800 comments...\n",
            "✅ Processed 11840 comments...\n",
            "✅ Processed 11880 comments...\n",
            "✅ Processed 11920 comments...\n",
            "✅ Processed 11960 comments...\n",
            "✅ Processed 12000 comments...\n",
            "✅ Processed 12040 comments...\n",
            "✅ Processed 12080 comments...\n",
            "✅ Processed 12120 comments...\n",
            "✅ Processed 12160 comments...\n",
            "✅ Processed 12200 comments...\n",
            "✅ Processed 12240 comments...\n",
            "✅ Processed 12280 comments...\n",
            "✅ Processed 12320 comments...\n",
            "✅ Processed 12360 comments...\n",
            "✅ Processed 12400 comments...\n",
            "✅ Processed 12440 comments...\n",
            "✅ Processed 12480 comments...\n",
            "✅ Processed 12520 comments...\n",
            "✅ Processed 12560 comments...\n",
            "✅ Processed 12600 comments...\n",
            "✅ Processed 12640 comments...\n",
            "✅ Processed 12680 comments...\n",
            "✅ Processed 12720 comments...\n",
            "✅ Processed 12760 comments...\n",
            "✅ Processed 12800 comments...\n",
            "✅ Processed 12840 comments...\n",
            "✅ Processed 12880 comments...\n",
            "✅ Processed 12920 comments...\n",
            "✅ Processed 12960 comments...\n",
            "✅ Processed 13000 comments...\n",
            "✅ Processed 13040 comments...\n",
            "✅ Processed 13080 comments...\n",
            "✅ Processed 13120 comments...\n",
            "✅ Processed 13160 comments...\n",
            "✅ Processed 13200 comments...\n",
            "✅ Processed 13240 comments...\n",
            "✅ Processed 13280 comments...\n",
            "✅ Processed 13320 comments...\n",
            "✅ Processed 13360 comments...\n",
            "✅ Processed 13400 comments...\n",
            "✅ Processed 13440 comments...\n",
            "✅ Processed 13480 comments...\n",
            "✅ Processed 13520 comments...\n",
            "✅ Processed 13560 comments...\n",
            "✅ Processed 13600 comments...\n",
            "✅ Processed 13640 comments...\n",
            "✅ Processed 13680 comments...\n",
            "✅ Processed 13720 comments...\n",
            "✅ Processed 13760 comments...\n",
            "✅ Processed 13800 comments...\n",
            "✅ Processed 13840 comments...\n",
            "✅ Processed 13880 comments...\n",
            "✅ Processed 13920 comments...\n",
            "✅ Processed 13960 comments...\n",
            "✅ Processed 14000 comments...\n",
            "✅ Processed 14040 comments...\n",
            "✅ Processed 14080 comments...\n",
            "✅ Processed 14120 comments...\n",
            "✅ Processed 14160 comments...\n",
            "✅ Processed 14200 comments...\n",
            "✅ Processed 14240 comments...\n",
            "✅ Processed 14280 comments...\n",
            "✅ Processed 14320 comments...\n",
            "✅ Processed 14360 comments...\n",
            "✅ Processed 14400 comments...\n",
            "✅ Processed 14440 comments...\n",
            "✅ Processed 14480 comments...\n",
            "✅ Processed 14520 comments...\n",
            "✅ Processed 14560 comments...\n",
            "✅ Processed 14600 comments...\n",
            "✅ Processed 14640 comments...\n",
            "✅ Processed 14680 comments...\n",
            "✅ Processed 14720 comments...\n",
            "✅ Processed 14760 comments...\n",
            "✅ Processed 14800 comments...\n",
            "✅ Processed 14840 comments...\n",
            "✅ Processed 14880 comments...\n",
            "✅ Processed 14920 comments...\n",
            "✅ Processed 14960 comments...\n",
            "✅ Processed 15000 comments...\n",
            "✅ Processed 15040 comments...\n",
            "✅ Processed 15080 comments...\n",
            "✅ Processed 15120 comments...\n",
            "✅ Processed 15160 comments...\n",
            "✅ Processed 15200 comments...\n",
            "✅ Processed 15240 comments...\n",
            "✅ Processed 15280 comments...\n",
            "✅ Processed 15320 comments...\n",
            "✅ Processed 15360 comments...\n",
            "✅ Processed 15400 comments...\n",
            "✅ Processed 15440 comments...\n",
            "✅ Processed 15480 comments...\n",
            "✅ Processed 15520 comments...\n",
            "✅ Processed 15560 comments...\n",
            "✅ Processed 15600 comments...\n",
            "✅ Processed 15640 comments...\n",
            "✅ Processed 15680 comments...\n",
            "✅ Processed 15720 comments...\n",
            "✅ Processed 15760 comments...\n",
            "✅ Processed 15800 comments...\n",
            "✅ Processed 15840 comments...\n",
            "✅ Processed 15880 comments...\n",
            "✅ Processed 15920 comments...\n",
            "✅ Processed 15960 comments...\n",
            "✅ Processed 16000 comments...\n",
            "✅ Processed 16040 comments...\n",
            "✅ Processed 16080 comments...\n",
            "✅ Processed 16120 comments...\n",
            "✅ Processed 16160 comments...\n",
            "✅ Processed 16200 comments...\n",
            "✅ Processed 16240 comments...\n",
            "✅ Processed 16280 comments...\n",
            "✅ Processed 16320 comments...\n",
            "✅ Processed 16360 comments...\n",
            "✅ Processed 16400 comments...\n",
            "✅ Processed 16440 comments...\n",
            "✅ Processed 16480 comments...\n",
            "✅ Processed 16520 comments...\n",
            "✅ Processed 16560 comments...\n",
            "✅ Processed 16600 comments...\n",
            "✅ Processed 16640 comments...\n",
            "✅ Processed 16680 comments...\n",
            "✅ Processed 16720 comments...\n",
            "✅ Processed 16760 comments...\n",
            "✅ Processed 16800 comments...\n",
            "✅ Processed 16840 comments...\n",
            "✅ Processed 16880 comments...\n",
            "✅ Processed 16920 comments...\n",
            "✅ Processed 16960 comments...\n",
            "✅ Processed 17000 comments...\n",
            "✅ Processed 17040 comments...\n",
            "✅ Processed 17080 comments...\n",
            "✅ Processed 17120 comments...\n",
            "✅ Processed 17160 comments...\n",
            "✅ Processed 17200 comments...\n",
            "✅ Processed 17240 comments...\n",
            "✅ Processed 17280 comments...\n",
            "✅ Processed 17320 comments...\n",
            "✅ Processed 17360 comments...\n",
            "✅ Processed 17400 comments...\n",
            "✅ Processed 17440 comments...\n",
            "✅ Processed 17480 comments...\n",
            "✅ Processed 17520 comments...\n",
            "✅ Processed 17560 comments...\n",
            "✅ Processed 17600 comments...\n",
            "✅ Processed 17640 comments...\n",
            "✅ Processed 17680 comments...\n",
            "✅ Processed 17720 comments...\n",
            "✅ Processed 17760 comments...\n",
            "✅ Processed 17800 comments...\n",
            "✅ Processed 17840 comments...\n",
            "✅ Processed 17880 comments...\n",
            "✅ Processed 17920 comments...\n",
            "✅ Processed 17960 comments...\n",
            "✅ Processed 18000 comments...\n",
            "✅ Processed 18040 comments...\n",
            "✅ Processed 18080 comments...\n",
            "✅ Processed 18120 comments...\n",
            "✅ Processed 18160 comments...\n",
            "✅ Processed 18200 comments...\n",
            "✅ Processed 18240 comments...\n",
            "✅ Processed 18280 comments...\n",
            "✅ Processed 18320 comments...\n",
            "✅ Processed 18360 comments...\n",
            "✅ Processed 18400 comments...\n",
            "✅ Processed 18440 comments...\n",
            "✅ Processed 18480 comments...\n",
            "✅ Processed 18520 comments...\n",
            "✅ Processed 18560 comments...\n",
            "✅ Processed 18600 comments...\n",
            "✅ Processed 18640 comments...\n",
            "✅ Processed 18680 comments...\n",
            "✅ Processed 18720 comments...\n",
            "✅ Processed 18760 comments...\n",
            "✅ Processed 18800 comments...\n",
            "✅ Processed 18840 comments...\n",
            "✅ Processed 18880 comments...\n",
            "✅ Processed 18920 comments...\n",
            "✅ Processed 18960 comments...\n",
            "✅ Processed 19000 comments...\n",
            "✅ Processed 19040 comments...\n",
            "✅ Processed 19080 comments...\n",
            "✅ Processed 19120 comments...\n",
            "✅ Processed 19160 comments...\n",
            "✅ Processed 19200 comments...\n",
            "✅ Processed 19240 comments...\n",
            "✅ Processed 19280 comments...\n",
            "✅ Processed 19320 comments...\n",
            "✅ Processed 19360 comments...\n",
            "✅ Processed 19400 comments...\n",
            "✅ Processed 19440 comments...\n",
            "✅ Processed 19480 comments...\n",
            "✅ Processed 19520 comments...\n",
            "✅ Processed 19560 comments...\n",
            "✅ Processed 19600 comments...\n",
            "✅ Processed 19640 comments...\n",
            "✅ Processed 19680 comments...\n",
            "✅ Processed 19720 comments...\n",
            "✅ Processed 19760 comments...\n",
            "✅ Processed 19800 comments...\n",
            "✅ Processed 19840 comments...\n",
            "✅ Processed 19880 comments...\n",
            "✅ Processed 19920 comments...\n",
            "✅ Processed 19960 comments...\n",
            "✅ Processed 20000 comments...\n",
            "✅ Processed 20040 comments...\n",
            "✅ Processed 20080 comments...\n",
            "✅ Processed 20120 comments...\n",
            "✅ Processed 20160 comments...\n",
            "✅ Processed 20200 comments...\n",
            "✅ Processed 20240 comments...\n",
            "✅ Processed 20280 comments...\n",
            "✅ Processed 20320 comments...\n",
            "✅ Processed 20360 comments...\n",
            "✅ Processed 20400 comments...\n",
            "✅ Processed 20440 comments...\n",
            "✅ Processed 20480 comments...\n",
            "✅ Processed 20520 comments...\n",
            "✅ Processed 20560 comments...\n",
            "✅ Processed 20600 comments...\n",
            "✅ Processed 20640 comments...\n",
            "✅ Processed 20680 comments...\n",
            "✅ Processed 20720 comments...\n",
            "✅ Processed 20760 comments...\n",
            "✅ Processed 20800 comments...\n",
            "✅ Processed 20840 comments...\n",
            "✅ Processed 20880 comments...\n",
            "✅ Processed 20920 comments...\n",
            "✅ Processed 20960 comments...\n",
            "✅ Processed 21000 comments...\n",
            "✅ Processed 21040 comments...\n",
            "✅ Processed 21080 comments...\n",
            "✅ Processed 21120 comments...\n",
            "✅ Processed 21160 comments...\n",
            "✅ Processed 21200 comments...\n",
            "✅ Processed 21240 comments...\n",
            "✅ Processed 21280 comments...\n",
            "✅ Processed 21320 comments...\n",
            "✅ Processed 21360 comments...\n",
            "✅ Processed 21400 comments...\n",
            "✅ Processed 21440 comments...\n",
            "✅ Processed 21480 comments...\n",
            "✅ Processed 21520 comments...\n",
            "✅ Processed 21560 comments...\n",
            "✅ Processed 21600 comments...\n",
            "✅ Processed 21640 comments...\n",
            "✅ Processed 21680 comments...\n",
            "✅ Processed 21720 comments...\n",
            "✅ Processed 21760 comments...\n",
            "✅ Processed 21800 comments...\n",
            "✅ Processed 21840 comments...\n",
            "✅ Processed 21880 comments...\n",
            "✅ Processed 21920 comments...\n",
            "✅ Processed 21960 comments...\n",
            "✅ Processed 22000 comments...\n",
            "✅ Processed 22040 comments...\n",
            "✅ Processed 22080 comments...\n",
            "✅ Processed 22120 comments...\n",
            "✅ Processed 22160 comments...\n",
            "✅ Processed 22200 comments...\n",
            "✅ Processed 22240 comments...\n",
            "✅ Processed 22280 comments...\n",
            "✅ Processed 22320 comments...\n",
            "✅ Processed 22360 comments...\n",
            "✅ Processed 22400 comments...\n",
            "✅ Processed 22440 comments...\n",
            "✅ Processed 22480 comments...\n",
            "✅ Processed 22520 comments...\n",
            "✅ Processed 22560 comments...\n",
            "✅ Processed 22600 comments...\n",
            "✅ Processed 22640 comments...\n",
            "✅ Processed 22680 comments...\n",
            "✅ Processed 22720 comments...\n",
            "✅ Processed 22760 comments...\n",
            "✅ Processed 22800 comments...\n",
            "✅ Processed 22840 comments...\n",
            "✅ Processed 22880 comments...\n",
            "✅ Processed 22920 comments...\n",
            "✅ Processed 22960 comments...\n",
            "✅ Processed 23000 comments...\n",
            "✅ Processed 23040 comments...\n",
            "✅ Processed 23080 comments...\n",
            "✅ Processed 23120 comments...\n",
            "✅ Processed 23160 comments...\n",
            "✅ Processed 23200 comments...\n",
            "✅ Processed 23240 comments...\n",
            "✅ Processed 23280 comments...\n",
            "✅ Processed 23320 comments...\n",
            "✅ Processed 23360 comments...\n",
            "✅ Processed 23400 comments...\n",
            "✅ Processed 23440 comments...\n",
            "✅ Processed 23480 comments...\n",
            "✅ Processed 23520 comments...\n",
            "✅ Processed 23560 comments...\n",
            "✅ Processed 23600 comments...\n",
            "✅ Processed 23640 comments...\n",
            "✅ Processed 23680 comments...\n",
            "✅ Processed 23720 comments...\n",
            "✅ Processed 23760 comments...\n",
            "✅ Processed 23800 comments...\n",
            "✅ Processed 23840 comments...\n",
            "✅ Processed 23880 comments...\n",
            "✅ Processed 23920 comments...\n",
            "✅ Processed 23960 comments...\n",
            "✅ Processed 24000 comments...\n",
            "✅ Processed 24040 comments...\n",
            "✅ Processed 24080 comments...\n",
            "✅ Processed 24120 comments...\n",
            "✅ Processed 24160 comments...\n",
            "✅ Processed 24200 comments...\n",
            "✅ Processed 24240 comments...\n",
            "✅ Processed 24280 comments...\n",
            "✅ Processed 24320 comments...\n",
            "✅ Processed 24360 comments...\n",
            "✅ Processed 24400 comments...\n",
            "✅ Processed 24440 comments...\n",
            "✅ Processed 24480 comments...\n",
            "✅ Processed 24520 comments...\n",
            "✅ Processed 24560 comments...\n",
            "✅ Processed 24600 comments...\n",
            "✅ Processed 24640 comments...\n",
            "✅ Processed 24680 comments...\n",
            "✅ Processed 24720 comments...\n",
            "✅ Processed 24760 comments...\n",
            "✅ Processed 24800 comments...\n",
            "✅ Processed 24840 comments...\n",
            "✅ Processed 24880 comments...\n",
            "✅ Processed 24920 comments...\n",
            "✅ Processed 24960 comments...\n",
            "✅ Processed 25000 comments...\n",
            "✅ Processed 25040 comments...\n",
            "✅ Processed 25080 comments...\n",
            "✅ Processed 25120 comments...\n",
            "✅ Processed 25160 comments...\n",
            "✅ Processed 25200 comments...\n",
            "✅ Processed 25240 comments...\n",
            "✅ Processed 25280 comments...\n",
            "✅ Processed 25320 comments...\n",
            "✅ Processed 25360 comments...\n",
            "✅ Processed 25400 comments...\n",
            "✅ Processed 25440 comments...\n",
            "✅ Processed 25480 comments...\n",
            "✅ Processed 25520 comments...\n",
            "✅ Processed 25560 comments...\n",
            "✅ Processed 25600 comments...\n",
            "✅ Processed 25640 comments...\n",
            "✅ Processed 25680 comments...\n",
            "✅ Processed 25720 comments...\n",
            "✅ Processed 25760 comments...\n",
            "✅ Processed 25800 comments...\n",
            "✅ Processed 25840 comments...\n",
            "✅ Processed 25880 comments...\n",
            "✅ Processed 25920 comments...\n",
            "✅ Processed 25960 comments...\n",
            "✅ Processed 26000 comments...\n",
            "✅ Processed 26040 comments...\n",
            "✅ Processed 26080 comments...\n",
            "✅ Processed 26120 comments...\n",
            "✅ Processed 26160 comments...\n",
            "✅ Processed 26200 comments...\n",
            "✅ Processed 26240 comments...\n",
            "✅ Processed 26280 comments...\n",
            "✅ Processed 26320 comments...\n",
            "✅ Processed 26360 comments...\n",
            "✅ Processed 26400 comments...\n",
            "✅ Processed 26440 comments...\n",
            "✅ Processed 26480 comments...\n",
            "✅ Processed 26520 comments...\n",
            "✅ Processed 26560 comments...\n",
            "✅ Processed 26600 comments...\n",
            "✅ Processed 26640 comments...\n",
            "✅ Processed 26680 comments...\n",
            "✅ Processed 26720 comments...\n",
            "✅ Processed 26760 comments...\n",
            "✅ Processed 26800 comments...\n",
            "✅ Processed 26840 comments...\n",
            "✅ Processed 26880 comments...\n",
            "✅ Processed 26920 comments...\n",
            "✅ Processed 26960 comments...\n",
            "✅ Processed 27000 comments...\n",
            "✅ Processed 27040 comments...\n",
            "✅ Processed 27080 comments...\n",
            "✅ Processed 27120 comments...\n",
            "✅ Processed 27160 comments...\n",
            "✅ Processed 27200 comments...\n",
            "✅ Processed 27240 comments...\n",
            "✅ Processed 27280 comments...\n",
            "✅ Processed 27320 comments...\n",
            "✅ Processed 27360 comments...\n",
            "✅ Processed 27400 comments...\n",
            "✅ Processed 27440 comments...\n",
            "✅ Processed 27480 comments...\n",
            "✅ Processed 27520 comments...\n",
            "✅ Processed 27560 comments...\n",
            "✅ Processed 27600 comments...\n",
            "✅ Processed 27640 comments...\n",
            "✅ Processed 27680 comments...\n",
            "✅ Processed 27720 comments...\n",
            "✅ Processed 27760 comments...\n",
            "✅ Processed 27800 comments...\n",
            "✅ Processed 27840 comments...\n",
            "✅ Processed 27880 comments...\n",
            "✅ Processed 27920 comments...\n",
            "✅ Processed 27960 comments...\n",
            "✅ Processed 28000 comments...\n",
            "✅ Processed 28040 comments...\n",
            "✅ Processed 28080 comments...\n",
            "✅ Processed 28120 comments...\n",
            "✅ Processed 28160 comments...\n",
            "✅ Processed 28200 comments...\n",
            "✅ Processed 28240 comments...\n",
            "✅ Processed 28280 comments...\n",
            "✅ Processed 28320 comments...\n",
            "✅ Processed 28360 comments...\n",
            "✅ Processed 28400 comments...\n",
            "✅ Processed 28440 comments...\n",
            "✅ Processed 28480 comments...\n",
            "✅ Processed 28520 comments...\n",
            "✅ Processed 28560 comments...\n",
            "✅ Processed 28600 comments...\n",
            "✅ Processed 28640 comments...\n",
            "✅ Processed 28680 comments...\n",
            "✅ Processed 28720 comments...\n",
            "✅ Processed 28760 comments...\n",
            "✅ Processed 28800 comments...\n",
            "✅ Processed 28840 comments...\n",
            "✅ Processed 28880 comments...\n",
            "✅ Processed 28920 comments...\n",
            "✅ Processed 28960 comments...\n",
            "✅ Processed 29000 comments...\n",
            "✅ Processed 29040 comments...\n",
            "✅ Processed 29080 comments...\n",
            "✅ Processed 29120 comments...\n",
            "✅ Processed 29160 comments...\n",
            "✅ Processed 29200 comments...\n",
            "✅ Processed 29240 comments...\n",
            "✅ Processed 29280 comments...\n",
            "✅ Processed 29320 comments...\n",
            "✅ Processed 29360 comments...\n",
            "✅ Processed 29400 comments...\n",
            "✅ Processed 29440 comments...\n",
            "✅ Processed 29480 comments...\n",
            "✅ Processed 29520 comments...\n",
            "✅ Processed 29560 comments...\n",
            "✅ Processed 29600 comments...\n",
            "✅ Processed 29640 comments...\n",
            "✅ Processed 29680 comments...\n",
            "✅ Processed 29720 comments...\n",
            "✅ Processed 29760 comments...\n",
            "✅ Processed 29800 comments...\n",
            "✅ Processed 29840 comments...\n",
            "✅ Processed 29880 comments...\n",
            "✅ Processed 29920 comments...\n",
            "✅ Processed 29960 comments...\n",
            "✅ Processed 30000 comments...\n",
            "✅ Processed 30040 comments...\n",
            "✅ Processed 30080 comments...\n",
            "✅ Processed 30120 comments...\n",
            "✅ Processed 30160 comments...\n",
            "✅ Processed 30200 comments...\n",
            "✅ Processed 30240 comments...\n",
            "✅ Processed 30280 comments...\n",
            "✅ Processed 30320 comments...\n",
            "✅ Processed 30360 comments...\n",
            "✅ Processed 30400 comments...\n",
            "✅ Processed 30440 comments...\n",
            "✅ Processed 30480 comments...\n",
            "✅ Processed 30520 comments...\n",
            "✅ Processed 30560 comments...\n",
            "✅ Processed 30600 comments...\n",
            "✅ Processed 30640 comments...\n",
            "✅ Processed 30680 comments...\n",
            "✅ Processed 30720 comments...\n",
            "✅ Processed 30760 comments...\n",
            "✅ Processed 30800 comments...\n",
            "✅ Processed 30840 comments...\n",
            "✅ Processed 30880 comments...\n",
            "✅ Processed 30920 comments...\n",
            "✅ Processed 30960 comments...\n",
            "✅ Processed 31000 comments...\n",
            "✅ Processed 31040 comments...\n",
            "✅ Processed 31080 comments...\n",
            "✅ Processed 31120 comments...\n",
            "✅ Processed 31160 comments...\n",
            "✅ Processed 31200 comments...\n",
            "✅ Processed 31240 comments...\n",
            "✅ Processed 31280 comments...\n",
            "✅ Processed 31320 comments...\n",
            "✅ Processed 31360 comments...\n",
            "✅ Processed 31400 comments...\n",
            "✅ Processed 31440 comments...\n",
            "✅ Processed 31480 comments...\n",
            "✅ Processed 31520 comments...\n",
            "✅ Processed 31560 comments...\n",
            "✅ Processed 31600 comments...\n",
            "✅ Processed 31640 comments...\n",
            "✅ Processed 31680 comments...\n",
            "✅ Processed 31720 comments...\n",
            "✅ Processed 31760 comments...\n",
            "✅ Processed 31800 comments...\n",
            "✅ Processed 31840 comments...\n",
            "✅ Processed 31880 comments...\n",
            "✅ Processed 31920 comments...\n",
            "✅ Processed 31960 comments...\n",
            "✅ Processed 32000 comments...\n",
            "✅ Processed 32040 comments...\n",
            "✅ Processed 32080 comments...\n",
            "✅ Processed 32120 comments...\n",
            "✅ Processed 32160 comments...\n",
            "✅ Processed 32200 comments...\n",
            "✅ Processed 32240 comments...\n",
            "✅ Processed 32280 comments...\n",
            "✅ Processed 32320 comments...\n",
            "✅ Processed 32360 comments...\n",
            "✅ Processed 32400 comments...\n",
            "✅ Processed 32440 comments...\n",
            "✅ Processed 32480 comments...\n",
            "✅ Processed 32520 comments...\n",
            "✅ Processed 32560 comments...\n",
            "✅ Processed 32600 comments...\n",
            "✅ Processed 32640 comments...\n",
            "✅ Processed 32680 comments...\n",
            "✅ Processed 32720 comments...\n",
            "✅ Processed 32760 comments...\n",
            "✅ Processed 32800 comments...\n",
            "✅ Processed 32840 comments...\n",
            "✅ Processed 32880 comments...\n",
            "✅ Processed 32920 comments...\n",
            "✅ Processed 32960 comments...\n",
            "✅ Processed 33000 comments...\n",
            "✅ Processed 33040 comments...\n",
            "✅ Processed 33080 comments...\n",
            "✅ Processed 33120 comments...\n",
            "✅ Processed 33160 comments...\n",
            "✅ Processed 33200 comments...\n",
            "✅ Processed 33240 comments...\n",
            "✅ Processed 33280 comments...\n",
            "✅ Processed 33320 comments...\n",
            "✅ Processed 33360 comments...\n",
            "✅ Processed 33400 comments...\n",
            "✅ Processed 33440 comments...\n",
            "✅ Processed 33480 comments...\n",
            "✅ Processed 33520 comments...\n",
            "✅ Processed 33560 comments...\n",
            "✅ Processed 33600 comments...\n",
            "✅ Processed 33640 comments...\n",
            "✅ Processed 33680 comments...\n",
            "✅ Processed 33720 comments...\n",
            "✅ Processed 33760 comments...\n",
            "✅ Processed 33800 comments...\n",
            "✅ Processed 33840 comments...\n",
            "✅ Processed 33880 comments...\n",
            "✅ Processed 33920 comments...\n",
            "✅ Processed 33960 comments...\n",
            "✅ Processed 34000 comments...\n",
            "✅ Processed 34040 comments...\n",
            "✅ Processed 34080 comments...\n",
            "✅ Processed 34120 comments...\n",
            "✅ Processed 34160 comments...\n",
            "✅ Processed 34200 comments...\n",
            "✅ Processed 34240 comments...\n",
            "✅ Processed 34280 comments...\n",
            "✅ Processed 34320 comments...\n",
            "✅ Processed 34360 comments...\n",
            "✅ Processed 34400 comments...\n",
            "✅ Processed 34440 comments...\n",
            "✅ Processed 34480 comments...\n",
            "✅ Processed 34520 comments...\n",
            "✅ Processed 34560 comments...\n",
            "✅ Processed 34600 comments...\n",
            "✅ Processed 34640 comments...\n",
            "✅ Processed 34680 comments...\n",
            "✅ Processed 34720 comments...\n",
            "✅ Processed 34760 comments...\n",
            "✅ Processed 34800 comments...\n",
            "✅ Processed 34840 comments...\n",
            "✅ Processed 34880 comments...\n",
            "✅ Processed 34920 comments...\n",
            "✅ Processed 34960 comments...\n",
            "✅ Processed 35000 comments...\n",
            "✅ Processed 35040 comments...\n",
            "✅ Processed 35080 comments...\n",
            "✅ Processed 35120 comments...\n",
            "✅ Processed 35160 comments...\n",
            "✅ Processed 35200 comments...\n",
            "✅ Processed 35240 comments...\n",
            "✅ Processed 35280 comments...\n",
            "✅ Processed 35320 comments...\n",
            "✅ Processed 35360 comments...\n",
            "✅ Processed 35400 comments...\n",
            "✅ Processed 35440 comments...\n",
            "✅ Processed 35480 comments...\n",
            "✅ Processed 35520 comments...\n",
            "✅ Processed 35560 comments...\n",
            "✅ Processed 35600 comments...\n",
            "✅ Processed 35640 comments...\n",
            "✅ Processed 35680 comments...\n",
            "✅ Processed 35720 comments...\n",
            "✅ Processed 35760 comments...\n",
            "✅ Processed 35800 comments...\n",
            "✅ Processed 35840 comments...\n",
            "✅ Processed 35880 comments...\n",
            "✅ Processed 35920 comments...\n",
            "✅ Processed 35960 comments...\n",
            "✅ Processed 36000 comments...\n",
            "✅ Processed 36040 comments...\n",
            "✅ Processed 36080 comments...\n",
            "✅ Processed 36120 comments...\n",
            "✅ Processed 36160 comments...\n",
            "✅ Processed 36200 comments...\n",
            "✅ Processed 36240 comments...\n",
            "✅ Processed 36280 comments...\n",
            "✅ Processed 36320 comments...\n",
            "✅ Processed 36360 comments...\n",
            "✅ Processed 36400 comments...\n",
            "✅ Processed 36440 comments...\n",
            "✅ Processed 36480 comments...\n",
            "✅ Processed 36520 comments...\n",
            "✅ Processed 36560 comments...\n",
            "✅ Processed 36600 comments...\n",
            "✅ Processed 36640 comments...\n",
            "✅ Processed 36680 comments...\n",
            "✅ Processed 36720 comments...\n",
            "✅ Processed 36760 comments...\n",
            "✅ Processed 36800 comments...\n",
            "✅ Processed 36840 comments...\n",
            "✅ Processed 36880 comments...\n",
            "✅ Processed 36920 comments...\n",
            "✅ Processed 36960 comments...\n",
            "✅ Processed 37000 comments...\n",
            "✅ Processed 37040 comments...\n",
            "✅ Processed 37080 comments...\n",
            "✅ Processed 37120 comments...\n",
            "✅ Processed 37160 comments...\n",
            "✅ Processed 37200 comments...\n",
            "✅ Processed 37240 comments...\n",
            "✅ Processed 37280 comments...\n",
            "✅ Processed 37320 comments...\n",
            "✅ Processed 37360 comments...\n",
            "✅ Processed 37400 comments...\n",
            "✅ Processed 37440 comments...\n",
            "✅ Processed 37480 comments...\n",
            "✅ Processed 37520 comments...\n",
            "✅ Processed 37560 comments...\n",
            "✅ Processed 37600 comments...\n",
            "✅ Processed 37640 comments...\n",
            "✅ Processed 37680 comments...\n",
            "✅ Processed 37720 comments...\n",
            "✅ Processed 37760 comments...\n",
            "✅ Processed 37800 comments...\n",
            "✅ Processed 37840 comments...\n",
            "✅ Processed 37880 comments...\n",
            "✅ Processed 37920 comments...\n",
            "✅ Processed 37960 comments...\n",
            "✅ Processed 38000 comments...\n",
            "✅ Processed 38040 comments...\n",
            "✅ Processed 38080 comments...\n",
            "✅ Processed 38120 comments...\n",
            "✅ Processed 38160 comments...\n",
            "✅ Processed 38200 comments...\n",
            "✅ Processed 38240 comments...\n",
            "✅ Processed 38280 comments...\n",
            "✅ Processed 38320 comments...\n",
            "✅ Processed 38360 comments...\n",
            "✅ Processed 38400 comments...\n",
            "✅ Processed 38440 comments...\n",
            "✅ Processed 38480 comments...\n",
            "✅ Processed 38520 comments...\n",
            "✅ Processed 38560 comments...\n",
            "✅ Processed 38600 comments...\n",
            "✅ Processed 38640 comments...\n",
            "✅ Processed 38680 comments...\n",
            "✅ Processed 38720 comments...\n",
            "✅ Processed 38760 comments...\n",
            "✅ Processed 38800 comments...\n",
            "✅ Processed 38840 comments...\n",
            "✅ Processed 38880 comments...\n",
            "✅ Processed 38920 comments...\n",
            "✅ Processed 38960 comments...\n",
            "✅ Processed 39000 comments...\n",
            "✅ Processed 39040 comments...\n",
            "✅ Processed 39080 comments...\n",
            "✅ Processed 39120 comments...\n",
            "✅ Processed 39160 comments...\n",
            "✅ Processed 39200 comments...\n",
            "✅ Processed 39240 comments...\n",
            "✅ Processed 39280 comments...\n",
            "✅ Processed 39320 comments...\n",
            "✅ Processed 39360 comments...\n",
            "✅ Processed 39400 comments...\n",
            "✅ Processed 39440 comments...\n",
            "✅ Processed 39480 comments...\n",
            "✅ Processed 39520 comments...\n",
            "✅ Processed 39560 comments...\n",
            "✅ Processed 39600 comments...\n",
            "✅ Processed 39640 comments...\n",
            "✅ Processed 39680 comments...\n",
            "✅ Processed 39720 comments...\n",
            "✅ Processed 39760 comments...\n",
            "✅ Processed 39800 comments...\n",
            "✅ Processed 39840 comments...\n",
            "✅ Processed 39880 comments...\n",
            "✅ Processed 39920 comments...\n",
            "✅ Processed 39960 comments...\n",
            "✅ Processed 40000 comments...\n",
            "✅ Processed 40040 comments...\n",
            "✅ Processed 40080 comments...\n",
            "✅ Processed 40120 comments...\n",
            "✅ Processed 40160 comments...\n",
            "✅ Processed 40200 comments...\n",
            "✅ Processed 40240 comments...\n",
            "✅ Processed 40280 comments...\n",
            "✅ Processed 40320 comments...\n",
            "✅ Processed 40360 comments...\n",
            "✅ Processed 40400 comments...\n",
            "✅ Processed 40440 comments...\n",
            "✅ Processed 40480 comments...\n",
            "✅ Processed 40520 comments...\n",
            "✅ Processed 40560 comments...\n",
            "✅ Processed 40600 comments...\n",
            "✅ Processed 40640 comments...\n",
            "✅ Processed 40680 comments...\n",
            "✅ Processed 40720 comments...\n",
            "✅ Processed 40760 comments...\n",
            "✅ Processed 40800 comments...\n",
            "✅ Processed 40840 comments...\n",
            "✅ Processed 40880 comments...\n",
            "✅ Processed 40920 comments...\n",
            "✅ Processed 40960 comments...\n",
            "✅ Processed 41000 comments...\n",
            "✅ Processed 41040 comments...\n",
            "✅ Processed 41080 comments...\n",
            "✅ Processed 41120 comments...\n",
            "✅ Processed 41160 comments...\n",
            "✅ Processed 41200 comments...\n",
            "✅ Processed 41240 comments...\n",
            "✅ Processed 41280 comments...\n",
            "✅ Processed 41320 comments...\n",
            "✅ Processed 41360 comments...\n",
            "✅ Processed 41400 comments...\n",
            "✅ Processed 41440 comments...\n",
            "✅ Processed 41480 comments...\n",
            "✅ Processed 41520 comments...\n",
            "✅ Processed 41560 comments...\n",
            "✅ Processed 41600 comments...\n",
            "✅ Processed 41640 comments...\n",
            "✅ Processed 41680 comments...\n",
            "✅ Processed 41720 comments...\n",
            "✅ Processed 41760 comments...\n",
            "✅ Processed 41800 comments...\n",
            "✅ Processed 41840 comments...\n",
            "✅ Processed 41880 comments...\n",
            "✅ Processed 41920 comments...\n",
            "✅ Processed 41960 comments...\n",
            "✅ Processed 42000 comments...\n",
            "✅ Processed 42040 comments...\n",
            "✅ Processed 42080 comments...\n",
            "✅ Processed 42120 comments...\n",
            "✅ Processed 42160 comments...\n",
            "✅ Processed 42200 comments...\n",
            "✅ Processed 42240 comments...\n",
            "✅ Processed 42280 comments...\n",
            "✅ Processed 42320 comments...\n",
            "✅ Processed 42360 comments...\n",
            "✅ Processed 42400 comments...\n",
            "✅ Processed 42440 comments...\n",
            "✅ Processed 42480 comments...\n",
            "✅ Processed 42520 comments...\n",
            "✅ Processed 42560 comments...\n",
            "✅ Processed 42600 comments...\n",
            "✅ Processed 42640 comments...\n",
            "✅ Processed 42680 comments...\n",
            "✅ Processed 42720 comments...\n",
            "✅ Processed 42760 comments...\n",
            "✅ Processed 42800 comments...\n",
            "✅ Processed 42840 comments...\n",
            "✅ Processed 42880 comments...\n",
            "✅ Processed 42920 comments...\n",
            "✅ Processed 42960 comments...\n",
            "✅ Processed 43000 comments...\n",
            "✅ Processed 43040 comments...\n",
            "✅ Processed 43080 comments...\n",
            "✅ Processed 43120 comments...\n",
            "✅ Processed 43160 comments...\n",
            "✅ Processed 43200 comments...\n",
            "✅ Processed 43240 comments...\n",
            "✅ Processed 43280 comments...\n",
            "✅ Processed 43320 comments...\n",
            "✅ Processed 43360 comments...\n",
            "✅ Processed 43400 comments...\n",
            "✅ Processed 43440 comments...\n",
            "✅ Processed 43480 comments...\n",
            "✅ Processed 43520 comments...\n",
            "✅ Processed 43560 comments...\n",
            "✅ Processed 43600 comments...\n",
            "✅ Processed 43640 comments...\n",
            "✅ Processed 43680 comments...\n",
            "✅ Processed 43720 comments...\n",
            "✅ Processed 43760 comments...\n",
            "✅ Processed 43800 comments...\n",
            "✅ Processed 43840 comments...\n",
            "✅ Processed 43880 comments...\n",
            "✅ Processed 43920 comments...\n",
            "✅ Processed 43960 comments...\n",
            "✅ Processed 44000 comments...\n",
            "✅ Processed 44040 comments...\n",
            "✅ Processed 44080 comments...\n",
            "✅ Processed 44120 comments...\n",
            "✅ Processed 44160 comments...\n",
            "✅ Processed 44200 comments...\n",
            "✅ Processed 44240 comments...\n",
            "✅ Processed 44280 comments...\n",
            "✅ Processed 44320 comments...\n",
            "✅ Processed 44360 comments...\n",
            "✅ Processed 44400 comments...\n",
            "✅ Processed 44440 comments...\n",
            "✅ Processed 44480 comments...\n",
            "✅ Processed 44520 comments...\n",
            "✅ Processed 44560 comments...\n",
            "✅ Processed 44600 comments...\n",
            "✅ Processed 44640 comments...\n",
            "✅ Processed 44680 comments...\n",
            "✅ Processed 44720 comments...\n",
            "✅ Processed 44760 comments...\n",
            "✅ Processed 44800 comments...\n",
            "✅ Processed 44840 comments...\n",
            "✅ Processed 44880 comments...\n",
            "✅ Processed 44920 comments...\n",
            "✅ Processed 44960 comments...\n",
            "✅ Processed 45000 comments...\n",
            "✅ Processed 45040 comments...\n",
            "✅ Processed 45080 comments...\n",
            "✅ Processed 45120 comments...\n",
            "✅ Processed 45160 comments...\n",
            "✅ Processed 45200 comments...\n",
            "✅ Processed 45240 comments...\n",
            "✅ Processed 45280 comments...\n",
            "✅ Processed 45320 comments...\n",
            "✅ Processed 45360 comments...\n",
            "✅ Processed 45400 comments...\n",
            "✅ Processed 45440 comments...\n",
            "✅ Processed 45480 comments...\n",
            "✅ Processed 45520 comments...\n",
            "✅ Processed 45560 comments...\n",
            "✅ Processed 45600 comments...\n",
            "✅ Processed 45640 comments...\n",
            "✅ Processed 45680 comments...\n",
            "✅ Processed 45720 comments...\n",
            "✅ Processed 45760 comments...\n",
            "✅ Processed 45800 comments...\n",
            "✅ Processed 45840 comments...\n",
            "✅ Processed 45880 comments...\n",
            "✅ Processed 45920 comments...\n",
            "✅ Processed 45960 comments...\n",
            "✅ Processed 46000 comments...\n",
            "✅ Processed 46040 comments...\n",
            "✅ Processed 46080 comments...\n",
            "✅ Processed 46120 comments...\n",
            "✅ Processed 46160 comments...\n",
            "✅ Processed 46200 comments...\n",
            "✅ Processed 46240 comments...\n",
            "✅ Processed 46280 comments...\n",
            "✅ Processed 46320 comments...\n",
            "✅ Processed 46360 comments...\n",
            "✅ Processed 46400 comments...\n",
            "✅ Processed 46440 comments...\n",
            "✅ Processed 46480 comments...\n",
            "✅ Processed 46520 comments...\n",
            "✅ Processed 46560 comments...\n",
            "✅ Processed 46600 comments...\n",
            "✅ Processed 46640 comments...\n",
            "✅ Processed 46680 comments...\n",
            "✅ Processed 46720 comments...\n",
            "✅ Processed 46760 comments...\n",
            "✅ Processed 46800 comments...\n",
            "✅ Processed 46840 comments...\n",
            "✅ Processed 46880 comments...\n",
            "✅ Processed 46920 comments...\n",
            "✅ Processed 46960 comments...\n",
            "✅ Processed 47000 comments...\n",
            "✅ Processed 47040 comments...\n",
            "✅ Processed 47080 comments...\n",
            "✅ Processed 47120 comments...\n",
            "✅ Processed 47160 comments...\n",
            "✅ Processed 47200 comments...\n",
            "✅ Processed 47240 comments...\n",
            "✅ Processed 47280 comments...\n",
            "✅ Processed 47320 comments...\n",
            "✅ Processed 47360 comments...\n",
            "✅ Processed 47400 comments...\n",
            "✅ Processed 47440 comments...\n",
            "✅ Processed 47480 comments...\n",
            "✅ Processed 47520 comments...\n",
            "✅ Processed 47560 comments...\n",
            "✅ Processed 47600 comments...\n",
            "✅ Processed 47640 comments...\n",
            "✅ Processed 47680 comments...\n",
            "✅ Processed 47720 comments...\n",
            "✅ Processed 47760 comments...\n",
            "✅ Processed 47800 comments...\n",
            "✅ Processed 47840 comments...\n",
            "✅ Processed 47880 comments...\n",
            "✅ Processed 47920 comments...\n",
            "✅ Processed 47960 comments...\n",
            "✅ Processed 48000 comments...\n",
            "✅ Processed 48040 comments...\n",
            "✅ Processed 48080 comments...\n",
            "✅ Processed 48120 comments...\n",
            "✅ Processed 48160 comments...\n",
            "✅ Processed 48200 comments...\n",
            "✅ Processed 48240 comments...\n",
            "✅ Processed 48280 comments...\n",
            "✅ Processed 48320 comments...\n",
            "✅ Processed 48360 comments...\n",
            "✅ Processed 48400 comments...\n",
            "✅ Processed 48440 comments...\n",
            "✅ Processed 48480 comments...\n",
            "✅ Processed 48520 comments...\n",
            "✅ Processed 48560 comments...\n",
            "✅ Processed 48600 comments...\n",
            "✅ Processed 48640 comments...\n",
            "✅ Processed 48680 comments...\n",
            "✅ Processed 48720 comments...\n",
            "✅ Processed 48760 comments...\n",
            "✅ Processed 48800 comments...\n",
            "✅ Processed 48840 comments...\n",
            "✅ Processed 48880 comments...\n",
            "✅ Processed 48920 comments...\n",
            "✅ Processed 48960 comments...\n",
            "✅ Processed 49000 comments...\n",
            "✅ Processed 49040 comments...\n",
            "✅ Processed 49080 comments...\n",
            "✅ Processed 49120 comments...\n",
            "✅ Processed 49160 comments...\n",
            "✅ Processed 49200 comments...\n",
            "✅ Processed 49240 comments...\n",
            "✅ Processed 49280 comments...\n",
            "✅ Processed 49320 comments...\n",
            "✅ Processed 49360 comments...\n",
            "✅ Processed 49400 comments...\n",
            "✅ Processed 49440 comments...\n",
            "✅ Processed 49480 comments...\n",
            "✅ Processed 49520 comments...\n",
            "✅ Processed 49560 comments...\n",
            "✅ Processed 49600 comments...\n",
            "✅ Processed 49640 comments...\n",
            "✅ Processed 49680 comments...\n",
            "✅ Processed 49720 comments...\n",
            "✅ Processed 49760 comments...\n",
            "✅ Processed 49800 comments...\n",
            "✅ Processed 49840 comments...\n",
            "✅ Processed 49880 comments...\n",
            "✅ Processed 49920 comments...\n",
            "✅ Processed 49960 comments...\n",
            "✅ Processed 50000 comments...\n",
            "✅ Processed 50040 comments...\n",
            "✅ Processed 50080 comments...\n",
            "✅ Processed 50120 comments...\n",
            "✅ Processed 50160 comments...\n",
            "✅ Processed 50200 comments...\n",
            "✅ Processed 50240 comments...\n",
            "✅ Processed 50280 comments...\n",
            "✅ Processed 50320 comments...\n",
            "✅ Processed 50360 comments...\n",
            "✅ Processed 50400 comments...\n",
            "✅ Processed 50440 comments...\n",
            "✅ Processed 50480 comments...\n",
            "✅ Processed 50520 comments...\n",
            "✅ Processed 50560 comments...\n",
            "✅ Processed 50600 comments...\n",
            "✅ Processed 50640 comments...\n",
            "✅ Processed 50680 comments...\n",
            "✅ Processed 50720 comments...\n",
            "✅ Processed 50760 comments...\n",
            "✅ Processed 50800 comments...\n",
            "✅ Processed 50840 comments...\n",
            "✅ Processed 50880 comments...\n",
            "✅ Processed 50920 comments...\n",
            "✅ Processed 50960 comments...\n",
            "✅ Processed 51000 comments...\n",
            "✅ Processed 51040 comments...\n",
            "✅ Processed 51080 comments...\n",
            "✅ Processed 51120 comments...\n",
            "✅ Processed 51160 comments...\n",
            "✅ Processed 51200 comments...\n",
            "✅ Processed 51240 comments...\n",
            "✅ Processed 51280 comments...\n",
            "✅ Processed 51320 comments...\n",
            "✅ Processed 51360 comments...\n",
            "✅ Processed 51400 comments...\n",
            "✅ Processed 51440 comments...\n",
            "✅ Processed 51480 comments...\n",
            "✅ Processed 51520 comments...\n",
            "✅ Processed 51560 comments...\n",
            "✅ Processed 51600 comments...\n",
            "✅ Processed 51640 comments...\n",
            "✅ Processed 51680 comments...\n",
            "✅ Processed 51720 comments...\n",
            "✅ Processed 51760 comments...\n",
            "✅ Processed 51800 comments...\n",
            "✅ Processed 51840 comments...\n",
            "✅ Processed 51880 comments...\n",
            "✅ Processed 51920 comments...\n",
            "✅ Processed 51960 comments...\n",
            "✅ Processed 52000 comments...\n",
            "✅ Processed 52040 comments...\n",
            "✅ Processed 52080 comments...\n",
            "✅ Processed 52120 comments...\n",
            "✅ Processed 52160 comments...\n",
            "✅ Processed 52200 comments...\n",
            "✅ Processed 52240 comments...\n",
            "✅ Processed 52280 comments...\n",
            "✅ Processed 52320 comments...\n",
            "✅ Processed 52360 comments...\n",
            "✅ Processed 52400 comments...\n",
            "✅ Processed 52440 comments...\n",
            "✅ Processed 52480 comments...\n",
            "✅ Processed 52520 comments...\n",
            "✅ Processed 52560 comments...\n",
            "✅ Processed 52600 comments...\n",
            "✅ Processed 52640 comments...\n",
            "✅ Processed 52680 comments...\n",
            "✅ Processed 52720 comments...\n",
            "✅ Processed 52760 comments...\n",
            "✅ Processed 52800 comments...\n",
            "✅ Processed 52840 comments...\n",
            "✅ Processed 52880 comments...\n",
            "✅ Processed 52920 comments...\n",
            "✅ Processed 52960 comments...\n",
            "✅ Processed 53000 comments...\n",
            "✅ Processed 53040 comments...\n",
            "✅ Processed 53080 comments...\n",
            "✅ Processed 53120 comments...\n",
            "✅ Processed 53160 comments...\n",
            "✅ Processed 53200 comments...\n",
            "✅ Processed 53240 comments...\n",
            "✅ Processed 53280 comments...\n",
            "✅ Processed 53320 comments...\n",
            "✅ Processed 53360 comments...\n",
            "✅ Processed 53400 comments...\n",
            "✅ Processed 53440 comments...\n",
            "✅ Processed 53480 comments...\n",
            "✅ Processed 53520 comments...\n",
            "✅ Processed 53560 comments...\n",
            "✅ Processed 53600 comments...\n",
            "✅ Processed 53640 comments...\n",
            "✅ Processed 53680 comments...\n",
            "✅ Processed 53720 comments...\n",
            "✅ Processed 53760 comments...\n",
            "✅ Processed 53800 comments...\n",
            "✅ Processed 53840 comments...\n",
            "✅ Processed 53880 comments...\n",
            "✅ Processed 53920 comments...\n",
            "✅ Processed 53960 comments...\n",
            "✅ Processed 54000 comments...\n",
            "✅ Processed 54040 comments...\n",
            "✅ Processed 54080 comments...\n",
            "✅ Processed 54120 comments...\n",
            "✅ Processed 54160 comments...\n",
            "✅ Processed 54200 comments...\n",
            "✅ Processed 54240 comments...\n",
            "✅ Processed 54280 comments...\n",
            "✅ Processed 54320 comments...\n",
            "✅ Processed 54360 comments...\n",
            "✅ Processed 54400 comments...\n",
            "✅ Processed 54440 comments...\n",
            "✅ Processed 54480 comments...\n",
            "✅ Processed 54520 comments...\n",
            "✅ Processed 54560 comments...\n",
            "✅ Processed 54600 comments...\n",
            "✅ Processed 54640 comments...\n",
            "✅ Processed 54680 comments...\n",
            "✅ Processed 54720 comments...\n",
            "✅ Processed 54760 comments...\n",
            "✅ Processed 54800 comments...\n",
            "✅ Processed 54840 comments...\n",
            "✅ Processed 54880 comments...\n",
            "✅ Processed 54920 comments...\n",
            "✅ Processed 54960 comments...\n",
            "✅ Processed 55000 comments...\n",
            "✅ Processed 55040 comments...\n",
            "✅ Processed 55080 comments...\n",
            "✅ Processed 55120 comments...\n",
            "✅ Processed 55160 comments...\n",
            "✅ Processed 55200 comments...\n",
            "✅ Processed 55240 comments...\n",
            "✅ Processed 55280 comments...\n",
            "✅ Processed 55320 comments...\n",
            "✅ Processed 55360 comments...\n",
            "✅ Processed 55400 comments...\n",
            "✅ Processed 55440 comments...\n",
            "✅ Processed 55480 comments...\n",
            "✅ Processed 55520 comments...\n",
            "✅ Processed 55560 comments...\n",
            "✅ Processed 55600 comments...\n",
            "✅ Processed 55640 comments...\n",
            "✅ Processed 55680 comments...\n",
            "✅ Processed 55720 comments...\n",
            "✅ Processed 55760 comments...\n",
            "✅ Processed 55800 comments...\n",
            "✅ Processed 55840 comments...\n",
            "✅ Processed 55880 comments...\n",
            "✅ Processed 55920 comments...\n",
            "✅ Processed 55960 comments...\n",
            "✅ Processed 56000 comments...\n",
            "✅ Processed 56040 comments...\n",
            "✅ Processed 56080 comments...\n",
            "✅ Processed 56120 comments...\n",
            "✅ Processed 56160 comments...\n",
            "✅ Processed 56200 comments...\n",
            "✅ Processed 56240 comments...\n",
            "✅ Processed 56280 comments...\n",
            "✅ Processed 56320 comments...\n",
            "✅ Processed 56360 comments...\n",
            "✅ Processed 56400 comments...\n",
            "✅ Processed 56440 comments...\n",
            "✅ Processed 56480 comments...\n",
            "✅ Processed 56520 comments...\n",
            "✅ Processed 56560 comments...\n",
            "✅ Processed 56600 comments...\n",
            "✅ Processed 56640 comments...\n",
            "✅ Processed 56680 comments...\n",
            "✅ Processed 56720 comments...\n",
            "✅ Processed 56760 comments...\n",
            "✅ Processed 56800 comments...\n",
            "✅ Processed 56840 comments...\n",
            "✅ Processed 56880 comments...\n",
            "✅ Processed 56920 comments...\n",
            "✅ Processed 56960 comments...\n",
            "✅ Processed 57000 comments...\n",
            "✅ Processed 57040 comments...\n",
            "✅ Processed 57080 comments...\n",
            "✅ Processed 57120 comments...\n",
            "✅ Processed 57160 comments...\n",
            "✅ Processed 57200 comments...\n",
            "✅ Processed 57240 comments...\n",
            "✅ Processed 57280 comments...\n",
            "✅ Processed 57320 comments...\n",
            "✅ Processed 57360 comments...\n",
            "✅ Processed 57400 comments...\n",
            "✅ Processed 57440 comments...\n",
            "✅ Processed 57480 comments...\n",
            "✅ Processed 57520 comments...\n",
            "✅ Processed 57560 comments...\n",
            "✅ Processed 57600 comments...\n",
            "✅ Processed 57640 comments...\n",
            "✅ Processed 57680 comments...\n",
            "✅ Processed 57720 comments...\n",
            "✅ Processed 57760 comments...\n",
            "✅ Processed 57800 comments...\n",
            "✅ Processed 57840 comments...\n",
            "✅ Processed 57880 comments...\n",
            "✅ Processed 57920 comments...\n",
            "✅ Processed 57960 comments...\n",
            "✅ Processed 58000 comments...\n",
            "✅ Processed 58040 comments...\n",
            "✅ Processed 58080 comments...\n",
            "✅ Processed 58120 comments...\n",
            "✅ Processed 58160 comments...\n",
            "✅ Processed 58200 comments...\n",
            "✅ Processed 58240 comments...\n",
            "✅ Processed 58280 comments...\n",
            "✅ Processed 58320 comments...\n",
            "✅ Processed 58360 comments...\n",
            "✅ Processed 58400 comments...\n",
            "✅ Processed 58440 comments...\n",
            "✅ Processed 58480 comments...\n",
            "✅ Processed 58520 comments...\n",
            "✅ Processed 58560 comments...\n",
            "✅ Processed 58600 comments...\n",
            "✅ Processed 58640 comments...\n",
            "✅ Processed 58680 comments...\n",
            "✅ Processed 58720 comments...\n",
            "✅ Processed 58760 comments...\n",
            "✅ Processed 58800 comments...\n",
            "✅ Processed 58840 comments...\n",
            "✅ Processed 58880 comments...\n",
            "✅ Processed 58920 comments...\n",
            "✅ Processed 58960 comments...\n",
            "✅ Processed 59000 comments...\n",
            "✅ Processed 59040 comments...\n",
            "✅ Processed 59080 comments...\n",
            "✅ Processed 59120 comments...\n",
            "✅ Processed 59160 comments...\n",
            "✅ Processed 59200 comments...\n",
            "✅ Processed 59240 comments...\n",
            "✅ Processed 59280 comments...\n",
            "✅ Processed 59320 comments...\n",
            "✅ Processed 59360 comments...\n",
            "✅ Processed 59400 comments...\n",
            "✅ Processed 59440 comments...\n",
            "✅ Processed 59480 comments...\n",
            "✅ Processed 59520 comments...\n",
            "✅ Processed 59560 comments...\n",
            "✅ Processed 59600 comments...\n",
            "✅ Processed 59640 comments...\n",
            "✅ Processed 59680 comments...\n",
            "✅ Processed 59720 comments...\n",
            "✅ Processed 59760 comments...\n",
            "✅ Processed 59800 comments...\n",
            "✅ Processed 59840 comments...\n",
            "✅ Processed 59880 comments...\n",
            "✅ Processed 59920 comments...\n",
            "✅ Processed 59960 comments...\n",
            "✅ Processed 60000 comments...\n",
            "✅ Processed 60040 comments...\n",
            "✅ Processed 60080 comments...\n",
            "✅ Processed 60120 comments...\n",
            "✅ Processed 60160 comments...\n",
            "✅ Processed 60200 comments...\n",
            "✅ Processed 60240 comments...\n",
            "✅ Processed 60280 comments...\n",
            "✅ Processed 60320 comments...\n",
            "✅ Processed 60360 comments...\n",
            "✅ Processed 60400 comments...\n",
            "✅ Processed 60440 comments...\n",
            "✅ Processed 60480 comments...\n",
            "✅ Processed 60520 comments...\n",
            "✅ Processed 60560 comments...\n",
            "✅ Processed 60600 comments...\n",
            "✅ Processed 60640 comments...\n",
            "✅ Processed 60680 comments...\n",
            "✅ Processed 60720 comments...\n",
            "✅ Processed 60760 comments...\n",
            "✅ Processed 60800 comments...\n",
            "✅ Processed 60840 comments...\n",
            "✅ Processed 60880 comments...\n",
            "✅ Processed 60920 comments...\n",
            "✅ Processed 60960 comments...\n",
            "✅ Processed 61000 comments...\n",
            "✅ Processed 61040 comments...\n",
            "✅ Processed 61080 comments...\n",
            "✅ Processed 61120 comments...\n",
            "✅ Processed 61160 comments...\n",
            "✅ Processed 61200 comments...\n",
            "✅ Processed 61240 comments...\n",
            "✅ Processed 61280 comments...\n",
            "✅ Processed 61320 comments...\n",
            "✅ Processed 61360 comments...\n",
            "✅ Processed 61400 comments...\n",
            "✅ Processed 61440 comments...\n",
            "✅ Processed 61480 comments...\n",
            "✅ Processed 61520 comments...\n",
            "✅ Processed 61560 comments...\n",
            "✅ Processed 61600 comments...\n",
            "✅ Processed 61640 comments...\n",
            "✅ Processed 61680 comments...\n",
            "✅ Processed 61720 comments...\n",
            "✅ Processed 61760 comments...\n",
            "✅ Processed 61800 comments...\n",
            "✅ Processed 61840 comments...\n",
            "✅ Processed 61880 comments...\n",
            "✅ Processed 61920 comments...\n",
            "✅ Processed 61960 comments...\n",
            "✅ Processed 62000 comments...\n",
            "✅ Processed 62040 comments...\n",
            "✅ Processed 62080 comments...\n",
            "✅ Processed 62120 comments...\n",
            "✅ Processed 62160 comments...\n",
            "✅ Processed 62200 comments...\n",
            "✅ Processed 62240 comments...\n",
            "✅ Processed 62280 comments...\n",
            "✅ Processed 62320 comments...\n",
            "✅ Processed 62360 comments...\n",
            "✅ Processed 62400 comments...\n",
            "✅ Processed 62440 comments...\n",
            "✅ Processed 62480 comments...\n",
            "✅ Processed 62520 comments...\n",
            "✅ Processed 62560 comments...\n",
            "✅ Processed 62600 comments...\n",
            "✅ Processed 62640 comments...\n",
            "✅ Processed 62680 comments...\n",
            "✅ Processed 62720 comments...\n",
            "✅ Processed 62760 comments...\n",
            "✅ Processed 62800 comments...\n",
            "✅ Processed 62840 comments...\n",
            "✅ Processed 62880 comments...\n",
            "✅ Processed 62920 comments...\n",
            "✅ Processed 62960 comments...\n",
            "✅ Processed 63000 comments...\n",
            "✅ Processed 63040 comments...\n",
            "✅ Processed 63080 comments...\n",
            "✅ Processed 63120 comments...\n",
            "✅ Processed 63160 comments...\n",
            "✅ Processed 63200 comments...\n",
            "✅ Processed 63240 comments...\n",
            "✅ Processed 63280 comments...\n",
            "✅ Processed 63320 comments...\n",
            "✅ Processed 63360 comments...\n",
            "✅ Processed 63400 comments...\n",
            "✅ Processed 63440 comments...\n",
            "✅ Processed 63480 comments...\n",
            "✅ Processed 63520 comments...\n",
            "✅ Processed 63560 comments...\n",
            "✅ Processed 63600 comments...\n",
            "✅ Processed 63640 comments...\n",
            "✅ Processed 63680 comments...\n",
            "✅ Processed 63720 comments...\n",
            "✅ Processed 63760 comments...\n",
            "✅ Processed 63800 comments...\n",
            "✅ Processed 63840 comments...\n",
            "✅ Processed 63880 comments...\n",
            "✅ Processed 63920 comments...\n",
            "✅ Processed 63960 comments...\n",
            "✅ Processed 64000 comments...\n",
            "✅ Processed 64040 comments...\n",
            "✅ Processed 64080 comments...\n",
            "✅ Processed 64120 comments...\n",
            "✅ Processed 64160 comments...\n",
            "✅ Processed 64200 comments...\n",
            "✅ Processed 64240 comments...\n",
            "✅ Processed 64280 comments...\n",
            "✅ Processed 64320 comments...\n",
            "✅ Processed 64360 comments...\n",
            "✅ Processed 64400 comments...\n",
            "✅ Processed 64440 comments...\n",
            "✅ Processed 64480 comments...\n",
            "✅ Processed 64520 comments...\n",
            "✅ Processed 64560 comments...\n",
            "✅ Processed 64600 comments...\n",
            "✅ Processed 64640 comments...\n",
            "✅ Processed 64680 comments...\n",
            "✅ Processed 64720 comments...\n",
            "✅ Processed 64760 comments...\n",
            "✅ Processed 64800 comments...\n",
            "✅ Processed 64840 comments...\n",
            "✅ Processed 64880 comments...\n",
            "✅ Processed 64920 comments...\n",
            "✅ Processed 64960 comments...\n",
            "✅ Processed 65000 comments...\n",
            "✅ Processed 65040 comments...\n",
            "✅ Processed 65080 comments...\n",
            "✅ Processed 65120 comments...\n",
            "✅ Processed 65160 comments...\n",
            "✅ Processed 65200 comments...\n",
            "✅ Processed 65240 comments...\n",
            "✅ Processed 65280 comments...\n",
            "✅ Processed 65320 comments...\n",
            "✅ Processed 65360 comments...\n",
            "✅ Processed 65400 comments...\n",
            "✅ Processed 65440 comments...\n",
            "✅ Processed 65480 comments...\n",
            "✅ Processed 65520 comments...\n",
            "✅ Processed 65560 comments...\n",
            "✅ Processed 65600 comments...\n",
            "✅ Processed 65640 comments...\n",
            "✅ Processed 65680 comments...\n",
            "✅ Processed 65720 comments...\n",
            "✅ Processed 65760 comments...\n",
            "✅ Processed 65800 comments...\n",
            "✅ Processed 65840 comments...\n",
            "✅ Processed 65880 comments...\n",
            "✅ Processed 65920 comments...\n",
            "✅ Processed 65960 comments...\n",
            "✅ Processed 66000 comments...\n",
            "✅ Processed 66040 comments...\n",
            "✅ Processed 66080 comments...\n",
            "✅ Processed 66120 comments...\n",
            "✅ Processed 66160 comments...\n",
            "✅ Processed 66200 comments...\n",
            "✅ Processed 66240 comments...\n",
            "✅ Processed 66280 comments...\n",
            "✅ Processed 66320 comments...\n",
            "✅ Processed 66360 comments...\n",
            "✅ Processed 66400 comments...\n",
            "✅ Processed 66440 comments...\n",
            "✅ Processed 66480 comments...\n",
            "✅ Processed 66520 comments...\n",
            "✅ Processed 66560 comments...\n",
            "✅ Processed 66600 comments...\n",
            "✅ Processed 66640 comments...\n",
            "✅ Processed 66680 comments...\n",
            "✅ Processed 66720 comments...\n",
            "✅ Processed 66760 comments...\n",
            "✅ Processed 66800 comments...\n",
            "✅ Processed 66840 comments...\n",
            "✅ Processed 66880 comments...\n",
            "✅ Processed 66920 comments...\n",
            "✅ Processed 66960 comments...\n",
            "✅ Processed 67000 comments...\n",
            "✅ Processed 67040 comments...\n",
            "✅ Processed 67080 comments...\n",
            "✅ Processed 67120 comments...\n",
            "✅ Processed 67160 comments...\n",
            "✅ Processed 67200 comments...\n",
            "✅ Processed 67240 comments...\n",
            "✅ Processed 67280 comments...\n",
            "✅ Processed 67320 comments...\n",
            "✅ Processed 67360 comments...\n",
            "✅ Processed 67400 comments...\n",
            "✅ Processed 67440 comments...\n",
            "✅ Processed 67480 comments...\n",
            "✅ Processed 67520 comments...\n",
            "✅ Processed 67560 comments...\n",
            "✅ Processed 67600 comments...\n",
            "✅ Processed 67640 comments...\n",
            "✅ Processed 67680 comments...\n",
            "✅ Processed 67720 comments...\n",
            "✅ Processed 67760 comments...\n",
            "✅ Processed 67800 comments...\n",
            "✅ Processed 67840 comments...\n",
            "✅ Processed 67880 comments...\n",
            "✅ Processed 67920 comments...\n",
            "✅ Processed 67960 comments...\n",
            "✅ Processed 68000 comments...\n",
            "✅ Processed 68040 comments...\n",
            "✅ Processed 68080 comments...\n",
            "✅ Processed 68120 comments...\n",
            "✅ Processed 68160 comments...\n",
            "✅ Processed 68200 comments...\n",
            "✅ Processed 68240 comments...\n",
            "✅ Processed 68280 comments...\n",
            "✅ Processed 68320 comments...\n",
            "✅ Processed 68360 comments...\n",
            "✅ Processed 68400 comments...\n",
            "✅ Processed 68440 comments...\n",
            "✅ Processed 68480 comments...\n",
            "✅ Processed 68520 comments...\n",
            "✅ Processed 68560 comments...\n",
            "✅ Processed 68600 comments...\n",
            "✅ Processed 68640 comments...\n",
            "✅ Processed 68680 comments...\n",
            "✅ Processed 68720 comments...\n",
            "✅ Processed 68760 comments...\n",
            "✅ Processed 68800 comments...\n",
            "✅ Processed 68840 comments...\n",
            "✅ Processed 68880 comments...\n",
            "✅ Processed 68920 comments...\n",
            "✅ Processed 68960 comments...\n",
            "✅ Processed 69000 comments...\n",
            "✅ Processed 69040 comments...\n",
            "✅ Processed 69080 comments...\n",
            "✅ Processed 69120 comments...\n",
            "✅ Processed 69160 comments...\n",
            "✅ Processed 69200 comments...\n",
            "✅ Processed 69240 comments...\n",
            "✅ Processed 69280 comments...\n",
            "✅ Processed 69320 comments...\n",
            "✅ Processed 69360 comments...\n",
            "✅ Processed 69400 comments...\n",
            "✅ Processed 69440 comments...\n",
            "✅ Processed 69480 comments...\n",
            "✅ Processed 69520 comments...\n",
            "✅ Processed 69560 comments...\n",
            "✅ Processed 69600 comments...\n",
            "✅ Processed 69640 comments...\n",
            "✅ Processed 69680 comments...\n",
            "✅ Processed 69720 comments...\n",
            "✅ Processed 69760 comments...\n",
            "✅ Processed 69800 comments...\n",
            "✅ Processed 69840 comments...\n",
            "✅ Processed 69880 comments...\n",
            "✅ Processed 69920 comments...\n",
            "✅ Processed 69960 comments...\n",
            "✅ Processed 70000 comments...\n",
            "✅ Processed 70040 comments...\n",
            "✅ Processed 70080 comments...\n",
            "✅ Processed 70120 comments...\n",
            "✅ Processed 70160 comments...\n",
            "✅ Processed 70200 comments...\n",
            "✅ Processed 70240 comments...\n",
            "✅ Processed 70280 comments...\n",
            "✅ Processed 70320 comments...\n",
            "✅ Processed 70360 comments...\n",
            "✅ Processed 70400 comments...\n",
            "✅ Processed 70440 comments...\n",
            "✅ Processed 70480 comments...\n",
            "✅ Processed 70520 comments...\n",
            "✅ Processed 70560 comments...\n",
            "✅ Processed 70600 comments...\n",
            "✅ Processed 70640 comments...\n",
            "✅ Processed 70680 comments...\n",
            "✅ Processed 70720 comments...\n",
            "✅ Processed 70760 comments...\n",
            "✅ Processed 70800 comments...\n",
            "✅ Processed 70840 comments...\n",
            "✅ Processed 70880 comments...\n",
            "✅ Processed 70920 comments...\n",
            "✅ Processed 70960 comments...\n",
            "✅ Processed 71000 comments...\n",
            "✅ Processed 71040 comments...\n",
            "✅ Processed 71080 comments...\n",
            "✅ Processed 71120 comments...\n",
            "✅ Processed 71160 comments...\n",
            "✅ Processed 71200 comments...\n",
            "✅ Processed 71240 comments...\n",
            "✅ Processed 71280 comments...\n",
            "✅ Processed 71320 comments...\n",
            "✅ Processed 71360 comments...\n",
            "✅ Processed 71400 comments...\n",
            "✅ Processed 71440 comments...\n",
            "✅ Processed 71480 comments...\n",
            "✅ Processed 71520 comments...\n",
            "✅ Processed 71560 comments...\n",
            "✅ Processed 71600 comments...\n",
            "✅ Processed 71640 comments...\n",
            "✅ Processed 71680 comments...\n",
            "✅ Processed 71720 comments...\n",
            "✅ Processed 71760 comments...\n",
            "✅ Processed 71800 comments...\n",
            "✅ Processed 71840 comments...\n",
            "✅ Processed 71880 comments...\n",
            "✅ Processed 71920 comments...\n",
            "✅ Processed 71960 comments...\n",
            "✅ Processed 72000 comments...\n",
            "✅ Processed 72040 comments...\n",
            "✅ Processed 72080 comments...\n",
            "✅ Processed 72120 comments...\n",
            "✅ Processed 72160 comments...\n",
            "✅ Processed 72200 comments...\n",
            "✅ Processed 72240 comments...\n",
            "✅ Processed 72280 comments...\n",
            "✅ Processed 72320 comments...\n",
            "✅ Processed 72360 comments...\n",
            "✅ Processed 72400 comments...\n",
            "✅ Processed 72440 comments...\n",
            "✅ Processed 72480 comments...\n",
            "✅ Processed 72520 comments...\n",
            "✅ Processed 72560 comments...\n",
            "✅ Processed 72600 comments...\n",
            "✅ Processed 72640 comments...\n",
            "✅ Processed 72680 comments...\n",
            "✅ Processed 72720 comments...\n",
            "✅ Processed 72760 comments...\n",
            "✅ Processed 72800 comments...\n",
            "✅ Processed 72840 comments...\n",
            "✅ Processed 72880 comments...\n",
            "✅ Processed 72920 comments...\n",
            "✅ Processed 72960 comments...\n",
            "✅ Processed 73000 comments...\n",
            "✅ Processed 73040 comments...\n",
            "✅ Processed 73080 comments...\n",
            "✅ Processed 73120 comments...\n",
            "✅ Processed 73160 comments...\n",
            "✅ Processed 73200 comments...\n",
            "✅ Processed 73240 comments...\n",
            "✅ Processed 73280 comments...\n",
            "✅ Processed 73320 comments...\n",
            "✅ Processed 73360 comments...\n",
            "✅ Processed 73400 comments...\n",
            "✅ Processed 73440 comments...\n",
            "✅ Processed 73480 comments...\n",
            "✅ Processed 73520 comments...\n",
            "✅ Processed 73560 comments...\n",
            "✅ Processed 73600 comments...\n",
            "✅ Processed 73640 comments...\n",
            "✅ Processed 73680 comments...\n",
            "✅ Processed 73720 comments...\n",
            "✅ Processed 73760 comments...\n",
            "✅ Processed 73800 comments...\n",
            "✅ Processed 73840 comments...\n",
            "✅ Processed 73880 comments...\n",
            "✅ Processed 73920 comments...\n",
            "✅ Processed 73960 comments...\n",
            "✅ Processed 74000 comments...\n",
            "✅ Processed 74040 comments...\n",
            "✅ Processed 74080 comments...\n",
            "✅ Processed 74120 comments...\n",
            "✅ Processed 74160 comments...\n",
            "✅ Processed 74200 comments...\n",
            "✅ Processed 74240 comments...\n",
            "✅ Processed 74280 comments...\n",
            "✅ Processed 74320 comments...\n",
            "✅ Processed 74360 comments...\n",
            "✅ Processed 74400 comments...\n",
            "✅ Processed 74440 comments...\n",
            "✅ Processed 74480 comments...\n",
            "✅ Processed 74520 comments...\n",
            "✅ Processed 74560 comments...\n",
            "✅ Processed 74600 comments...\n",
            "✅ Processed 74640 comments...\n",
            "✅ Processed 74680 comments...\n",
            "✅ Processed 74720 comments...\n",
            "✅ Processed 74760 comments...\n",
            "✅ Processed 74800 comments...\n",
            "✅ Processed 74840 comments...\n",
            "✅ Processed 74880 comments...\n",
            "✅ Processed 74920 comments...\n",
            "✅ Processed 74960 comments...\n",
            "✅ Processed 75000 comments...\n",
            "✅ Processed 75040 comments...\n",
            "✅ Processed 75080 comments...\n",
            "✅ Processed 75120 comments...\n",
            "✅ Processed 75160 comments...\n",
            "✅ Processed 75200 comments...\n",
            "✅ Processed 75240 comments...\n",
            "✅ Processed 75280 comments...\n",
            "✅ Processed 75320 comments...\n",
            "✅ Processed 75360 comments...\n",
            "✅ Processed 75400 comments...\n",
            "✅ Processed 75440 comments...\n",
            "✅ Processed 75480 comments...\n",
            "✅ Processed 75520 comments...\n",
            "✅ Processed 75560 comments...\n",
            "✅ Processed 75600 comments...\n",
            "✅ Processed 75640 comments...\n",
            "✅ Processed 75680 comments...\n",
            "✅ Processed 75720 comments...\n",
            "✅ Processed 75760 comments...\n",
            "✅ Processed 75800 comments...\n",
            "✅ Processed 75840 comments...\n",
            "✅ Processed 75880 comments...\n",
            "✅ Processed 75920 comments...\n",
            "✅ Processed 75960 comments...\n",
            "✅ Processed 76000 comments...\n",
            "✅ Processed 76040 comments...\n",
            "✅ Processed 76080 comments...\n",
            "✅ Processed 76120 comments...\n",
            "✅ Processed 76160 comments...\n",
            "✅ Processed 76200 comments...\n",
            "✅ Processed 76240 comments...\n",
            "✅ Processed 76280 comments...\n",
            "✅ Processed 76320 comments...\n",
            "✅ Processed 76360 comments...\n",
            "✅ Processed 76400 comments...\n",
            "✅ Processed 76440 comments...\n",
            "✅ Processed 76480 comments...\n",
            "✅ Processed 76520 comments...\n",
            "✅ Processed 76560 comments...\n",
            "✅ Processed 76600 comments...\n",
            "✅ Processed 76640 comments...\n",
            "✅ Processed 76680 comments...\n",
            "✅ Processed 76720 comments...\n",
            "✅ Processed 76760 comments...\n",
            "✅ Processed 76800 comments...\n",
            "✅ Processed 76840 comments...\n",
            "✅ Processed 76880 comments...\n",
            "✅ Processed 76920 comments...\n",
            "✅ Processed 76960 comments...\n",
            "✅ Processed 77000 comments...\n",
            "✅ Processed 77040 comments...\n",
            "✅ Processed 77080 comments...\n",
            "✅ Processed 77120 comments...\n",
            "✅ Processed 77160 comments...\n",
            "✅ Processed 77200 comments...\n",
            "✅ Processed 77240 comments...\n",
            "✅ Processed 77280 comments...\n",
            "✅ Processed 77320 comments...\n",
            "✅ Processed 77360 comments...\n",
            "✅ Processed 77400 comments...\n",
            "✅ Processed 77440 comments...\n",
            "✅ Processed 77480 comments...\n",
            "✅ Processed 77520 comments...\n",
            "✅ Processed 77560 comments...\n",
            "✅ Processed 77600 comments...\n",
            "✅ Processed 77640 comments...\n",
            "✅ Processed 77680 comments...\n",
            "✅ Processed 77720 comments...\n",
            "✅ Processed 77760 comments...\n",
            "✅ Processed 77800 comments...\n",
            "✅ Processed 77840 comments...\n",
            "✅ Processed 77880 comments...\n",
            "✅ Processed 77920 comments...\n",
            "✅ Processed 77960 comments...\n",
            "✅ Processed 78000 comments...\n",
            "✅ Processed 78040 comments...\n",
            "✅ Processed 78080 comments...\n",
            "✅ Processed 78120 comments...\n",
            "✅ Processed 78160 comments...\n",
            "✅ Processed 78200 comments...\n",
            "✅ Processed 78240 comments...\n",
            "✅ Processed 78280 comments...\n",
            "✅ Processed 78320 comments...\n",
            "✅ Processed 78360 comments...\n",
            "✅ Processed 78400 comments...\n",
            "✅ Processed 78440 comments...\n",
            "✅ Processed 78480 comments...\n",
            "✅ Processed 78520 comments...\n",
            "✅ Processed 78560 comments...\n",
            "✅ Processed 78600 comments...\n",
            "✅ Processed 78640 comments...\n",
            "✅ Processed 78680 comments...\n",
            "✅ Processed 78720 comments...\n",
            "✅ Processed 78760 comments...\n",
            "✅ Processed 78800 comments...\n",
            "✅ Processed 78840 comments...\n",
            "✅ Processed 78880 comments...\n",
            "✅ Processed 78920 comments...\n",
            "✅ Processed 78960 comments...\n",
            "✅ Processed 79000 comments...\n",
            "✅ Processed 79040 comments...\n",
            "✅ Processed 79080 comments...\n",
            "✅ Processed 79120 comments...\n",
            "✅ Processed 79160 comments...\n",
            "✅ Processed 79200 comments...\n",
            "✅ Processed 79240 comments...\n",
            "✅ Processed 79280 comments...\n",
            "✅ Processed 79320 comments...\n",
            "✅ Processed 79360 comments...\n",
            "✅ Processed 79400 comments...\n",
            "✅ Processed 79440 comments...\n",
            "✅ Processed 79480 comments...\n",
            "✅ Processed 79520 comments...\n",
            "✅ Processed 79560 comments...\n",
            "✅ Processed 79600 comments...\n",
            "✅ Processed 79640 comments...\n",
            "✅ Processed 79680 comments...\n",
            "✅ Processed 79720 comments...\n",
            "✅ Processed 79760 comments...\n",
            "✅ Processed 79800 comments...\n",
            "✅ Processed 79840 comments...\n",
            "✅ Processed 79880 comments...\n",
            "✅ Processed 79920 comments...\n",
            "✅ Processed 79960 comments...\n",
            "✅ Processed 80000 comments...\n",
            "✅ Processed 80040 comments...\n",
            "✅ Processed 80080 comments...\n",
            "✅ Processed 80120 comments...\n",
            "✅ Processed 80160 comments...\n",
            "✅ Processed 80200 comments...\n",
            "✅ Processed 80240 comments...\n",
            "✅ Processed 80280 comments...\n",
            "✅ Processed 80320 comments...\n",
            "✅ Processed 80360 comments...\n",
            "✅ Processed 80400 comments...\n",
            "✅ Processed 80440 comments...\n",
            "✅ Processed 80480 comments...\n",
            "✅ Processed 80520 comments...\n",
            "✅ Processed 80560 comments...\n",
            "✅ Processed 80600 comments...\n",
            "✅ Processed 80640 comments...\n",
            "✅ Processed 80680 comments...\n",
            "✅ Processed 80720 comments...\n",
            "✅ Processed 80760 comments...\n",
            "✅ Processed 80800 comments...\n",
            "✅ Processed 80840 comments...\n",
            "✅ Processed 80880 comments...\n",
            "✅ Processed 80920 comments...\n",
            "✅ Processed 80960 comments...\n",
            "✅ Processed 81000 comments...\n",
            "✅ Processed 81040 comments...\n",
            "✅ Processed 81080 comments...\n",
            "✅ Processed 81120 comments...\n",
            "✅ Processed 81160 comments...\n",
            "✅ Processed 81200 comments...\n",
            "✅ Processed 81240 comments...\n",
            "✅ Processed 81280 comments...\n",
            "✅ Processed 81320 comments...\n",
            "✅ Processed 81360 comments...\n",
            "✅ Processed 81400 comments...\n",
            "✅ Processed 81440 comments...\n",
            "✅ Processed 81480 comments...\n",
            "✅ Processed 81520 comments...\n",
            "✅ Processed 81560 comments...\n",
            "✅ Processed 81600 comments...\n",
            "✅ Processed 81640 comments...\n",
            "✅ Processed 81680 comments...\n",
            "✅ Processed 81720 comments...\n",
            "✅ Processed 81760 comments...\n",
            "✅ Processed 81800 comments...\n",
            "✅ Processed 81840 comments...\n",
            "✅ Processed 81880 comments...\n",
            "✅ Processed 81920 comments...\n",
            "✅ Processed 81960 comments...\n",
            "✅ Processed 82000 comments...\n",
            "✅ Processed 82040 comments...\n",
            "✅ Processed 82080 comments...\n",
            "✅ Processed 82120 comments...\n",
            "✅ Processed 82160 comments...\n",
            "✅ Processed 82200 comments...\n",
            "✅ Processed 82240 comments...\n",
            "✅ Processed 82280 comments...\n",
            "✅ Processed 82320 comments...\n",
            "✅ Processed 82360 comments...\n",
            "✅ Processed 82400 comments...\n",
            "✅ Processed 82440 comments...\n",
            "✅ Processed 82480 comments...\n",
            "✅ Processed 82520 comments...\n",
            "✅ Processed 82560 comments...\n",
            "✅ Processed 82600 comments...\n",
            "✅ Processed 82640 comments...\n",
            "✅ Processed 82680 comments...\n",
            "✅ Processed 82720 comments...\n",
            "✅ Processed 82760 comments...\n",
            "✅ Processed 82800 comments...\n",
            "✅ Processed 82840 comments...\n",
            "✅ Processed 82880 comments...\n",
            "✅ Processed 82920 comments...\n",
            "✅ Processed 82960 comments...\n",
            "✅ Processed 83000 comments...\n",
            "✅ Processed 83040 comments...\n",
            "✅ Processed 83080 comments...\n",
            "✅ Processed 83120 comments...\n",
            "✅ Processed 83160 comments...\n",
            "✅ Processed 83200 comments...\n",
            "✅ Processed 83240 comments...\n",
            "✅ Processed 83280 comments...\n",
            "✅ Processed 83320 comments...\n",
            "✅ Processed 83360 comments...\n",
            "✅ Processed 83400 comments...\n",
            "✅ Processed 83440 comments...\n",
            "✅ Processed 83480 comments...\n",
            "✅ Processed 83520 comments...\n",
            "✅ Processed 83560 comments...\n",
            "✅ Processed 83600 comments...\n",
            "✅ Processed 83640 comments...\n",
            "✅ Processed 83680 comments...\n",
            "✅ Processed 83720 comments...\n",
            "✅ Processed 83760 comments...\n",
            "✅ Processed 83800 comments...\n",
            "✅ Processed 83840 comments...\n",
            "✅ Processed 83880 comments...\n",
            "✅ Processed 83920 comments...\n",
            "✅ Processed 83960 comments...\n",
            "✅ Processed 84000 comments...\n",
            "✅ Processed 84040 comments...\n",
            "✅ Processed 84080 comments...\n",
            "✅ Processed 84120 comments...\n",
            "✅ Processed 84160 comments...\n",
            "✅ Processed 84200 comments...\n",
            "✅ Processed 84240 comments...\n",
            "✅ Processed 84280 comments...\n",
            "✅ Processed 84320 comments...\n",
            "✅ Processed 84360 comments...\n",
            "✅ Processed 84400 comments...\n",
            "✅ Processed 84440 comments...\n",
            "✅ Processed 84480 comments...\n",
            "✅ Processed 84520 comments...\n",
            "✅ Processed 84560 comments...\n",
            "✅ Processed 84600 comments...\n",
            "✅ Processed 84640 comments...\n",
            "✅ Processed 84680 comments...\n",
            "✅ Processed 84720 comments...\n",
            "✅ Processed 84760 comments...\n",
            "✅ Processed 84800 comments...\n",
            "✅ Processed 84840 comments...\n",
            "✅ Processed 84880 comments...\n",
            "✅ Processed 84920 comments...\n",
            "✅ Processed 84960 comments...\n",
            "✅ Processed 85000 comments...\n",
            "✅ Processed 85040 comments...\n",
            "✅ Processed 85080 comments...\n",
            "✅ Processed 85120 comments...\n",
            "✅ Processed 85160 comments...\n",
            "✅ Processed 85200 comments...\n",
            "✅ Processed 85240 comments...\n",
            "✅ Processed 85280 comments...\n",
            "✅ Processed 85320 comments...\n",
            "✅ Processed 85360 comments...\n",
            "✅ Processed 85400 comments...\n",
            "✅ Processed 85440 comments...\n",
            "✅ Processed 85480 comments...\n",
            "✅ Processed 85520 comments...\n",
            "✅ Processed 85560 comments...\n",
            "✅ Processed 85600 comments...\n",
            "✅ Processed 85640 comments...\n",
            "✅ Processed 85680 comments...\n",
            "✅ Processed 85720 comments...\n",
            "✅ Processed 85760 comments...\n",
            "✅ Processed 85800 comments...\n",
            "✅ Processed 85840 comments...\n",
            "✅ Processed 85880 comments...\n",
            "✅ Processed 85920 comments...\n",
            "✅ Processed 85960 comments...\n",
            "✅ Processed 86000 comments...\n",
            "✅ Processed 86040 comments...\n",
            "✅ Processed 86080 comments...\n",
            "✅ Processed 86120 comments...\n",
            "✅ Processed 86160 comments...\n",
            "✅ Processed 86200 comments...\n",
            "✅ Processed 86240 comments...\n",
            "✅ Processed 86280 comments...\n",
            "✅ Processed 86320 comments...\n",
            "✅ Processed 86360 comments...\n",
            "✅ Processed 86400 comments...\n",
            "✅ Processed 86440 comments...\n",
            "✅ Processed 86480 comments...\n",
            "✅ Processed 86520 comments...\n",
            "✅ Processed 86560 comments...\n",
            "✅ Processed 86600 comments...\n",
            "✅ Processed 86640 comments...\n",
            "✅ Processed 86680 comments...\n",
            "✅ Processed 86720 comments...\n",
            "✅ Processed 86760 comments...\n",
            "✅ Processed 86800 comments...\n",
            "✅ Processed 86840 comments...\n",
            "✅ Processed 86880 comments...\n",
            "✅ Processed 86920 comments...\n",
            "✅ Processed 86960 comments...\n",
            "✅ Processed 87000 comments...\n",
            "✅ Processed 87040 comments...\n",
            "✅ Processed 87080 comments...\n",
            "✅ Processed 87120 comments...\n",
            "✅ Processed 87160 comments...\n",
            "✅ Processed 87200 comments...\n",
            "✅ Processed 87240 comments...\n",
            "✅ Processed 87280 comments...\n",
            "✅ Processed 87320 comments...\n",
            "✅ Processed 87360 comments...\n",
            "✅ Processed 87400 comments...\n",
            "✅ Processed 87440 comments...\n",
            "✅ Processed 87480 comments...\n",
            "✅ Processed 87520 comments...\n",
            "✅ Processed 87560 comments...\n",
            "✅ Processed 87600 comments...\n",
            "✅ Processed 87640 comments...\n",
            "✅ Processed 87680 comments...\n",
            "✅ Processed 87720 comments...\n",
            "✅ Processed 87760 comments...\n",
            "✅ Processed 87800 comments...\n",
            "✅ Processed 87840 comments...\n",
            "✅ Processed 87880 comments...\n",
            "✅ Processed 87920 comments...\n",
            "✅ Processed 87960 comments...\n",
            "✅ Processed 88000 comments...\n",
            "✅ Processed 88040 comments...\n",
            "✅ Processed 88080 comments...\n",
            "✅ Processed 88120 comments...\n",
            "✅ Processed 88160 comments...\n",
            "✅ Processed 88200 comments...\n",
            "✅ Processed 88240 comments...\n",
            "✅ Processed 88280 comments...\n",
            "✅ Processed 88320 comments...\n",
            "✅ Processed 88360 comments...\n",
            "✅ Processed 88400 comments...\n",
            "✅ Processed 88440 comments...\n",
            "✅ Processed 88480 comments...\n",
            "✅ Processed 88520 comments...\n",
            "✅ Processed 88560 comments...\n",
            "✅ Processed 88600 comments...\n",
            "✅ Processed 88640 comments...\n",
            "✅ Processed 88680 comments...\n",
            "✅ Processed 88720 comments...\n",
            "✅ Processed 88760 comments...\n",
            "✅ Processed 88800 comments...\n",
            "✅ Processed 88840 comments...\n",
            "✅ Processed 88880 comments...\n",
            "✅ Processed 88920 comments...\n",
            "✅ Processed 88960 comments...\n",
            "✅ Processed 89000 comments...\n",
            "✅ Processed 89040 comments...\n",
            "✅ Processed 89080 comments...\n",
            "✅ Processed 89120 comments...\n",
            "✅ Processed 89160 comments...\n",
            "✅ Processed 89200 comments...\n",
            "✅ Processed 89240 comments...\n",
            "✅ Processed 89280 comments...\n",
            "✅ Processed 89320 comments...\n",
            "✅ Processed 89360 comments...\n",
            "✅ Processed 89400 comments...\n",
            "✅ Processed 89440 comments...\n",
            "✅ Processed 89480 comments...\n",
            "✅ Processed 89520 comments...\n",
            "✅ Processed 89560 comments...\n",
            "✅ Processed 89600 comments...\n",
            "✅ Processed 89640 comments...\n",
            "✅ Processed 89680 comments...\n",
            "✅ Processed 89720 comments...\n",
            "✅ Processed 89760 comments...\n",
            "✅ Processed 89800 comments...\n",
            "✅ Processed 89840 comments...\n",
            "✅ Processed 89880 comments...\n",
            "✅ Processed 89920 comments...\n",
            "✅ Processed 89960 comments...\n",
            "✅ Processed 90000 comments...\n",
            "✅ Processed 90040 comments...\n",
            "✅ Processed 90080 comments...\n",
            "✅ Processed 90120 comments...\n",
            "✅ Processed 90160 comments...\n",
            "✅ Processed 90200 comments...\n",
            "✅ Processed 90240 comments...\n",
            "✅ Processed 90280 comments...\n",
            "✅ Processed 90320 comments...\n",
            "✅ Processed 90360 comments...\n",
            "✅ Processed 90400 comments...\n",
            "✅ Processed 90440 comments...\n",
            "✅ Processed 90480 comments...\n",
            "✅ Processed 90520 comments...\n",
            "✅ Processed 90560 comments...\n",
            "✅ Processed 90600 comments...\n",
            "✅ Processed 90640 comments...\n",
            "✅ Processed 90680 comments...\n",
            "✅ Processed 90720 comments...\n",
            "✅ Processed 90760 comments...\n",
            "✅ Processed 90800 comments...\n",
            "✅ Processed 90840 comments...\n",
            "✅ Processed 90880 comments...\n",
            "✅ Processed 90920 comments...\n",
            "✅ Processed 90960 comments...\n",
            "✅ Processed 91000 comments...\n",
            "✅ Processed 91040 comments...\n",
            "✅ Processed 91080 comments...\n",
            "✅ Processed 91120 comments...\n",
            "✅ Processed 91160 comments...\n",
            "✅ Processed 91200 comments...\n",
            "✅ Processed 91240 comments...\n",
            "✅ Processed 91280 comments...\n",
            "✅ Processed 91320 comments...\n",
            "✅ Processed 91360 comments...\n",
            "✅ Processed 91400 comments...\n",
            "✅ Processed 91440 comments...\n",
            "✅ Processed 91480 comments...\n",
            "✅ Processed 91520 comments...\n",
            "✅ Processed 91560 comments...\n",
            "✅ Processed 91600 comments...\n",
            "✅ Processed 91640 comments...\n",
            "✅ Processed 91680 comments...\n",
            "✅ Processed 91720 comments...\n",
            "✅ Processed 91760 comments...\n",
            "✅ Processed 91800 comments...\n",
            "✅ Processed 91840 comments...\n",
            "✅ Processed 91880 comments...\n",
            "✅ Processed 91920 comments...\n",
            "✅ Processed 91960 comments...\n",
            "✅ Processed 92000 comments...\n",
            "✅ Processed 92040 comments...\n",
            "✅ Processed 92080 comments...\n",
            "✅ Processed 92120 comments...\n",
            "✅ Processed 92160 comments...\n",
            "✅ Processed 92200 comments...\n",
            "✅ Processed 92240 comments...\n",
            "✅ Processed 92280 comments...\n",
            "✅ Processed 92320 comments...\n",
            "✅ Processed 92360 comments...\n",
            "✅ Processed 92400 comments...\n",
            "✅ Processed 92440 comments...\n",
            "✅ Processed 92480 comments...\n",
            "✅ Processed 92520 comments...\n",
            "✅ Processed 92560 comments...\n",
            "✅ Processed 92600 comments...\n",
            "✅ Processed 92640 comments...\n",
            "✅ Processed 92680 comments...\n",
            "✅ Processed 92720 comments...\n",
            "✅ Processed 92760 comments...\n",
            "✅ Processed 92800 comments...\n",
            "✅ Processed 92840 comments...\n",
            "✅ Processed 92880 comments...\n",
            "✅ Processed 92920 comments...\n",
            "✅ Processed 92960 comments...\n",
            "✅ Processed 93000 comments...\n",
            "✅ Processed 93040 comments...\n",
            "✅ Processed 93080 comments...\n",
            "✅ Processed 93120 comments...\n",
            "✅ Processed 93160 comments...\n",
            "✅ Processed 93200 comments...\n",
            "✅ Processed 93240 comments...\n",
            "✅ Processed 93280 comments...\n",
            "✅ Processed 93320 comments...\n",
            "✅ Processed 93360 comments...\n",
            "✅ Processed 93400 comments...\n",
            "✅ Processed 93440 comments...\n",
            "✅ Processed 93480 comments...\n",
            "✅ Processed 93520 comments...\n",
            "✅ Processed 93560 comments...\n",
            "✅ Processed 93600 comments...\n",
            "✅ Processed 93640 comments...\n",
            "✅ Processed 93680 comments...\n",
            "✅ Processed 93720 comments...\n",
            "✅ Processed 93760 comments...\n",
            "✅ Processed 93800 comments...\n",
            "✅ Processed 93840 comments...\n",
            "✅ Processed 93880 comments...\n",
            "✅ Processed 93920 comments...\n",
            "✅ Processed 93960 comments...\n",
            "✅ Processed 94000 comments...\n",
            "✅ Processed 94040 comments...\n",
            "✅ Processed 94080 comments...\n",
            "✅ Processed 94120 comments...\n",
            "✅ Processed 94160 comments...\n",
            "✅ Processed 94200 comments...\n",
            "✅ Processed 94240 comments...\n",
            "✅ Processed 94280 comments...\n",
            "✅ Processed 94320 comments...\n",
            "✅ Processed 94360 comments...\n",
            "✅ Processed 94400 comments...\n",
            "✅ Processed 94440 comments...\n",
            "✅ Processed 94480 comments...\n",
            "✅ Processed 94520 comments...\n",
            "✅ Processed 94560 comments...\n",
            "✅ Processed 94600 comments...\n",
            "✅ Processed 94640 comments...\n",
            "✅ Processed 94680 comments...\n",
            "✅ Processed 94720 comments...\n",
            "✅ Processed 94760 comments...\n",
            "✅ Processed 94800 comments...\n",
            "✅ Processed 94840 comments...\n",
            "✅ Processed 94880 comments...\n",
            "✅ Processed 94920 comments...\n",
            "✅ Processed 94960 comments...\n",
            "✅ Processed 95000 comments...\n",
            "✅ Processed 95040 comments...\n",
            "✅ Processed 95080 comments...\n",
            "✅ Processed 95120 comments...\n",
            "✅ Processed 95160 comments...\n",
            "✅ Processed 95200 comments...\n",
            "✅ Processed 95240 comments...\n",
            "✅ Processed 95280 comments...\n",
            "✅ Processed 95320 comments...\n",
            "✅ Processed 95360 comments...\n",
            "✅ Processed 95400 comments...\n",
            "✅ Processed 95440 comments...\n",
            "✅ Processed 95480 comments...\n",
            "✅ Processed 95520 comments...\n",
            "✅ Processed 95560 comments...\n",
            "✅ Processed 95600 comments...\n",
            "✅ Processed 95640 comments...\n",
            "✅ Processed 95680 comments...\n",
            "✅ Processed 95720 comments...\n",
            "✅ Processed 95760 comments...\n",
            "✅ Processed 95800 comments...\n",
            "✅ Processed 95840 comments...\n",
            "✅ Processed 95880 comments...\n",
            "✅ Processed 95920 comments...\n",
            "✅ Processed 95960 comments...\n",
            "✅ Processed 96000 comments...\n",
            "✅ Processed 96040 comments...\n",
            "✅ Processed 96080 comments...\n",
            "✅ Processed 96120 comments...\n",
            "✅ Processed 96160 comments...\n",
            "✅ Processed 96200 comments...\n",
            "✅ Processed 96240 comments...\n",
            "✅ Processed 96280 comments...\n",
            "✅ Processed 96320 comments...\n",
            "✅ Processed 96360 comments...\n",
            "✅ Processed 96400 comments...\n",
            "✅ Processed 96440 comments...\n",
            "✅ Processed 96480 comments...\n",
            "✅ Processed 96520 comments...\n",
            "✅ Processed 96560 comments...\n",
            "✅ Processed 96600 comments...\n",
            "✅ Processed 96640 comments...\n",
            "✅ Processed 96680 comments...\n",
            "✅ Processed 96720 comments...\n",
            "✅ Processed 96760 comments...\n",
            "✅ Processed 96800 comments...\n",
            "✅ Processed 96840 comments...\n",
            "✅ Processed 96880 comments...\n",
            "✅ Processed 96920 comments...\n",
            "✅ Processed 96960 comments...\n",
            "✅ Processed 97000 comments...\n",
            "✅ Processed 97040 comments...\n",
            "✅ Processed 97080 comments...\n",
            "✅ Processed 97120 comments...\n",
            "✅ Processed 97160 comments...\n",
            "✅ Processed 97200 comments...\n",
            "✅ Processed 97240 comments...\n",
            "✅ Processed 97280 comments...\n",
            "✅ Processed 97320 comments...\n",
            "✅ Processed 97360 comments...\n",
            "✅ Processed 97400 comments...\n",
            "✅ Processed 97440 comments...\n",
            "✅ Processed 97480 comments...\n",
            "✅ Processed 97520 comments...\n",
            "✅ Processed 97560 comments...\n",
            "✅ Processed 97600 comments...\n",
            "✅ Processed 97640 comments...\n",
            "✅ Processed 97680 comments...\n",
            "✅ Processed 97720 comments...\n",
            "✅ Processed 97760 comments...\n",
            "✅ Processed 97800 comments...\n",
            "✅ Processed 97840 comments...\n",
            "✅ Processed 97880 comments...\n",
            "✅ Processed 97920 comments...\n",
            "✅ Processed 97960 comments...\n",
            "✅ Processed 98000 comments...\n",
            "✅ Processed 98040 comments...\n",
            "✅ Processed 98080 comments...\n",
            "✅ Processed 98120 comments...\n",
            "✅ Processed 98160 comments...\n",
            "✅ Processed 98200 comments...\n",
            "✅ Processed 98240 comments...\n",
            "✅ Processed 98280 comments...\n",
            "✅ Processed 98320 comments...\n",
            "✅ Processed 98360 comments...\n",
            "✅ Processed 98400 comments...\n",
            "✅ Processed 98440 comments...\n",
            "✅ Processed 98480 comments...\n",
            "✅ Processed 98520 comments...\n",
            "✅ Processed 98560 comments...\n",
            "✅ Processed 98600 comments...\n",
            "✅ Processed 98640 comments...\n",
            "✅ Processed 98680 comments...\n",
            "✅ Processed 98720 comments...\n",
            "✅ Processed 98760 comments...\n",
            "✅ Processed 98800 comments...\n",
            "✅ Processed 98840 comments...\n",
            "✅ Processed 98880 comments...\n",
            "✅ Processed 98920 comments...\n",
            "✅ Processed 98960 comments...\n",
            "✅ Processed 99000 comments...\n",
            "✅ Processed 99040 comments...\n",
            "✅ Processed 99080 comments...\n",
            "✅ Processed 99120 comments...\n",
            "✅ Processed 99160 comments...\n",
            "✅ Processed 99200 comments...\n",
            "✅ Processed 99240 comments...\n",
            "✅ Processed 99280 comments...\n",
            "✅ Processed 99320 comments...\n",
            "✅ Processed 99360 comments...\n",
            "✅ Processed 99400 comments...\n",
            "✅ Processed 99440 comments...\n",
            "✅ Processed 99480 comments...\n",
            "✅ Processed 99520 comments...\n",
            "✅ Processed 99560 comments...\n",
            "✅ Processed 99600 comments...\n",
            "✅ Processed 99640 comments...\n",
            "✅ Processed 99680 comments...\n",
            "✅ Processed 99720 comments...\n",
            "✅ Processed 99760 comments...\n",
            "✅ Processed 99800 comments...\n",
            "✅ Processed 99840 comments...\n",
            "✅ Processed 99880 comments...\n",
            "✅ Processed 99920 comments...\n",
            "✅ Processed 99960 comments...\n",
            "✅ Processed 100000 comments...\n",
            "✅ Processed 100040 comments...\n",
            "✅ Processed 100080 comments...\n",
            "✅ Processed 100120 comments...\n",
            "✅ Processed 100160 comments...\n",
            "✅ Processed 100200 comments...\n",
            "✅ Processed 100240 comments...\n",
            "✅ Processed 100280 comments...\n",
            "✅ Processed 100320 comments...\n",
            "✅ Processed 100360 comments...\n",
            "✅ Processed 100400 comments...\n",
            "✅ Processed 100440 comments...\n",
            "✅ Processed 100480 comments...\n",
            "✅ Processed 100520 comments...\n",
            "✅ Processed 100560 comments...\n",
            "✅ Processed 100600 comments...\n",
            "✅ Processed 100640 comments...\n",
            "✅ Processed 100680 comments...\n",
            "✅ Processed 100720 comments...\n",
            "✅ Processed 100760 comments...\n",
            "✅ Processed 100800 comments...\n",
            "✅ Processed 100840 comments...\n",
            "✅ Processed 100880 comments...\n",
            "✅ Processed 100920 comments...\n",
            "✅ Processed 100960 comments...\n",
            "✅ Processed 101000 comments...\n",
            "✅ Processed 101040 comments...\n",
            "✅ Processed 101080 comments...\n",
            "✅ Processed 101120 comments...\n",
            "✅ Processed 101160 comments...\n",
            "✅ Processed 101200 comments...\n",
            "✅ Processed 101240 comments...\n",
            "✅ Processed 101280 comments...\n",
            "✅ Processed 101320 comments...\n",
            "✅ Processed 101360 comments...\n",
            "✅ Processed 101400 comments...\n",
            "✅ Processed 101440 comments...\n",
            "✅ Processed 101480 comments...\n",
            "✅ Processed 101520 comments...\n",
            "✅ Processed 101560 comments...\n",
            "✅ Processed 101600 comments...\n",
            "✅ Processed 101640 comments...\n",
            "✅ Processed 101680 comments...\n",
            "✅ Processed 101720 comments...\n",
            "✅ Processed 101760 comments...\n",
            "✅ Processed 101800 comments...\n",
            "✅ Processed 101840 comments...\n",
            "✅ Processed 101880 comments...\n",
            "✅ Processed 101920 comments...\n",
            "✅ Processed 101960 comments...\n",
            "✅ Processed 102000 comments...\n",
            "✅ Processed 102040 comments...\n",
            "✅ Processed 102080 comments...\n",
            "✅ Processed 102120 comments...\n",
            "✅ Processed 102160 comments...\n",
            "✅ Processed 102200 comments...\n",
            "✅ Processed 102240 comments...\n",
            "✅ Processed 102280 comments...\n",
            "✅ Processed 102320 comments...\n",
            "✅ Processed 102360 comments...\n",
            "✅ Processed 102400 comments...\n",
            "✅ Processed 102440 comments...\n",
            "✅ Processed 102480 comments...\n",
            "✅ Processed 102520 comments...\n",
            "✅ Processed 102560 comments...\n",
            "✅ Processed 102600 comments...\n",
            "✅ Processed 102640 comments...\n",
            "✅ Processed 102680 comments...\n",
            "✅ Processed 102720 comments...\n",
            "✅ Processed 102760 comments...\n",
            "✅ Processed 102800 comments...\n",
            "✅ Processed 102840 comments...\n",
            "✅ Processed 102880 comments...\n",
            "✅ Processed 102920 comments...\n",
            "✅ Processed 102960 comments...\n",
            "✅ Processed 103000 comments...\n",
            "✅ Processed 103040 comments...\n",
            "✅ Processed 103080 comments...\n",
            "✅ Processed 103120 comments...\n",
            "✅ Processed 103160 comments...\n",
            "✅ Processed 103200 comments...\n",
            "✅ Processed 103240 comments...\n",
            "✅ Processed 103280 comments...\n",
            "✅ Processed 103320 comments...\n",
            "✅ Processed 103360 comments...\n",
            "✅ Processed 103400 comments...\n",
            "✅ Processed 103440 comments...\n",
            "✅ Processed 103480 comments...\n",
            "✅ Processed 103520 comments...\n",
            "✅ Processed 103560 comments...\n",
            "✅ Processed 103600 comments...\n",
            "✅ Processed 103640 comments...\n",
            "✅ Processed 103680 comments...\n",
            "✅ Processed 103720 comments...\n",
            "✅ Processed 103760 comments...\n",
            "✅ Processed 103800 comments...\n",
            "✅ Processed 103840 comments...\n",
            "✅ Processed 103880 comments...\n",
            "✅ Processed 103920 comments...\n",
            "✅ Processed 103960 comments...\n",
            "✅ Processed 104000 comments...\n",
            "✅ Processed 104040 comments...\n",
            "✅ Processed 104080 comments...\n",
            "✅ Processed 104120 comments...\n",
            "✅ Processed 104160 comments...\n",
            "✅ Processed 104200 comments...\n",
            "✅ Processed 104240 comments...\n",
            "✅ Processed 104280 comments...\n",
            "✅ Processed 104320 comments...\n",
            "✅ Processed 104360 comments...\n",
            "✅ Processed 104400 comments...\n",
            "✅ Processed 104440 comments...\n",
            "✅ Processed 104480 comments...\n",
            "✅ Processed 104520 comments...\n",
            "✅ Processed 104560 comments...\n",
            "✅ Processed 104600 comments...\n",
            "✅ Processed 104640 comments...\n",
            "✅ Processed 104680 comments...\n",
            "✅ Processed 104720 comments...\n",
            "✅ Processed 104760 comments...\n",
            "✅ Processed 104800 comments...\n",
            "✅ Processed 104840 comments...\n",
            "✅ Processed 104880 comments...\n",
            "✅ Processed 104920 comments...\n",
            "✅ Processed 104960 comments...\n",
            "✅ Processed 105000 comments...\n",
            "✅ Processed 105040 comments...\n",
            "✅ Processed 105080 comments...\n",
            "✅ Processed 105120 comments...\n",
            "✅ Processed 105160 comments...\n",
            "✅ Processed 105200 comments...\n",
            "✅ Processed 105240 comments...\n",
            "✅ Processed 105280 comments...\n",
            "✅ Processed 105320 comments...\n",
            "✅ Processed 105360 comments...\n",
            "✅ Processed 105400 comments...\n",
            "✅ Processed 105440 comments...\n",
            "✅ Processed 105480 comments...\n",
            "✅ Processed 105520 comments...\n",
            "✅ Processed 105560 comments...\n",
            "✅ Processed 105600 comments...\n",
            "✅ Processed 105640 comments...\n",
            "✅ Processed 105680 comments...\n",
            "✅ Processed 105720 comments...\n",
            "✅ Processed 105760 comments...\n",
            "✅ Processed 105800 comments...\n",
            "✅ Processed 105840 comments...\n",
            "✅ Processed 105880 comments...\n",
            "✅ Processed 105920 comments...\n",
            "✅ Processed 105960 comments...\n",
            "✅ Processed 106000 comments...\n",
            "✅ Processed 106040 comments...\n",
            "✅ Processed 106080 comments...\n",
            "✅ Processed 106120 comments...\n",
            "✅ Processed 106160 comments...\n",
            "✅ Processed 106200 comments...\n",
            "✅ Processed 106240 comments...\n",
            "✅ Processed 106280 comments...\n",
            "✅ Processed 106320 comments...\n",
            "✅ Processed 106360 comments...\n",
            "✅ Processed 106400 comments...\n",
            "✅ Processed 106440 comments...\n",
            "✅ Processed 106480 comments...\n",
            "✅ Processed 106520 comments...\n",
            "✅ Processed 106560 comments...\n",
            "✅ Processed 106600 comments...\n",
            "✅ Processed 106640 comments...\n",
            "✅ Processed 106680 comments...\n",
            "✅ Processed 106720 comments...\n",
            "✅ Processed 106760 comments...\n",
            "✅ Processed 106800 comments...\n",
            "✅ Processed 106840 comments...\n",
            "✅ Processed 106880 comments...\n",
            "✅ Processed 106920 comments...\n",
            "✅ Processed 106960 comments...\n",
            "✅ Processed 107000 comments...\n",
            "✅ Processed 107040 comments...\n",
            "✅ Processed 107080 comments...\n",
            "✅ Processed 107120 comments...\n",
            "✅ Processed 107160 comments...\n",
            "✅ Processed 107200 comments...\n",
            "✅ Processed 107240 comments...\n",
            "✅ Processed 107280 comments...\n",
            "✅ Processed 107320 comments...\n",
            "✅ Processed 107360 comments...\n",
            "✅ Processed 107400 comments...\n",
            "✅ Processed 107440 comments...\n",
            "✅ Processed 107480 comments...\n",
            "✅ Processed 107520 comments...\n",
            "✅ Processed 107560 comments...\n",
            "✅ Processed 107600 comments...\n",
            "✅ Processed 107640 comments...\n",
            "✅ Processed 107680 comments...\n",
            "✅ Processed 107720 comments...\n",
            "✅ Processed 107760 comments...\n",
            "✅ Processed 107800 comments...\n",
            "✅ Processed 107840 comments...\n",
            "✅ Processed 107880 comments...\n",
            "✅ Processed 107920 comments...\n",
            "✅ Processed 107960 comments...\n",
            "✅ Processed 108000 comments...\n",
            "✅ Processed 108040 comments...\n",
            "✅ Processed 108080 comments...\n",
            "✅ Processed 108120 comments...\n",
            "✅ Processed 108160 comments...\n",
            "✅ Processed 108200 comments...\n",
            "✅ Processed 108240 comments...\n",
            "✅ Processed 108280 comments...\n",
            "✅ Processed 108320 comments...\n",
            "✅ Processed 108360 comments...\n",
            "✅ Processed 108400 comments...\n",
            "✅ Processed 108440 comments...\n",
            "✅ Processed 108480 comments...\n",
            "✅ Processed 108520 comments...\n",
            "✅ Processed 108560 comments...\n",
            "✅ Processed 108600 comments...\n",
            "✅ Processed 108640 comments...\n",
            "✅ Processed 108680 comments...\n",
            "✅ Processed 108720 comments...\n",
            "✅ Processed 108760 comments...\n",
            "✅ Processed 108800 comments...\n",
            "✅ Processed 108840 comments...\n",
            "✅ Processed 108880 comments...\n",
            "✅ Processed 108920 comments...\n",
            "✅ Processed 108960 comments...\n",
            "✅ Processed 109000 comments...\n",
            "✅ Processed 109040 comments...\n",
            "✅ Processed 109080 comments...\n",
            "✅ Processed 109120 comments...\n",
            "✅ Processed 109160 comments...\n",
            "✅ Processed 109200 comments...\n",
            "✅ Processed 109240 comments...\n",
            "✅ Processed 109280 comments...\n",
            "✅ Processed 109320 comments...\n",
            "✅ Processed 109360 comments...\n",
            "✅ Processed 109400 comments...\n",
            "✅ Processed 109440 comments...\n",
            "✅ Processed 109480 comments...\n",
            "✅ Processed 109520 comments...\n",
            "✅ Processed 109560 comments...\n",
            "✅ Processed 109600 comments...\n",
            "✅ Processed 109640 comments...\n",
            "✅ Processed 109680 comments...\n",
            "✅ Processed 109720 comments...\n",
            "✅ Processed 109760 comments...\n",
            "✅ Processed 109800 comments...\n",
            "✅ Processed 109840 comments...\n",
            "✅ Processed 109880 comments...\n",
            "✅ Processed 109920 comments...\n",
            "✅ Processed 109960 comments...\n",
            "✅ Processed 110000 comments...\n",
            "✅ Processed 110040 comments...\n",
            "✅ Processed 110080 comments...\n",
            "✅ Processed 110120 comments...\n",
            "✅ Processed 110160 comments...\n",
            "✅ Processed 110200 comments...\n",
            "✅ Processed 110240 comments...\n",
            "✅ Processed 110280 comments...\n",
            "✅ Processed 110320 comments...\n",
            "✅ Processed 110360 comments...\n",
            "✅ Processed 110400 comments...\n",
            "✅ Processed 110440 comments...\n",
            "✅ Processed 110480 comments...\n",
            "✅ Processed 110520 comments...\n",
            "✅ Processed 110560 comments...\n",
            "✅ Processed 110600 comments...\n",
            "✅ Processed 110640 comments...\n",
            "✅ Processed 110680 comments...\n",
            "✅ Processed 110720 comments...\n",
            "✅ Processed 110760 comments...\n",
            "✅ Processed 110800 comments...\n",
            "✅ Processed 110840 comments...\n",
            "✅ Processed 110880 comments...\n",
            "✅ Processed 110920 comments...\n",
            "✅ Processed 110960 comments...\n",
            "✅ Processed 111000 comments...\n",
            "✅ Processed 111040 comments...\n",
            "✅ Processed 111080 comments...\n",
            "✅ Processed 111120 comments...\n",
            "✅ Processed 111160 comments...\n",
            "✅ Processed 111200 comments...\n",
            "✅ Processed 111240 comments...\n",
            "✅ Processed 111280 comments...\n",
            "✅ Processed 111320 comments...\n",
            "✅ Processed 111360 comments...\n",
            "✅ Processed 111400 comments...\n",
            "✅ Processed 111440 comments...\n",
            "✅ Processed 111480 comments...\n",
            "✅ Processed 111520 comments...\n",
            "✅ Processed 111560 comments...\n",
            "✅ Processed 111600 comments...\n",
            "✅ Processed 111640 comments...\n",
            "✅ Processed 111680 comments...\n",
            "✅ Processed 111720 comments...\n",
            "✅ Processed 111760 comments...\n",
            "✅ Processed 111800 comments...\n",
            "✅ Processed 111840 comments...\n",
            "✅ Processed 111880 comments...\n",
            "✅ Processed 111920 comments...\n",
            "✅ Processed 111960 comments...\n",
            "✅ Processed 112000 comments...\n",
            "✅ Processed 112040 comments...\n",
            "✅ Processed 112080 comments...\n",
            "✅ Processed 112120 comments...\n",
            "✅ Processed 112160 comments...\n",
            "✅ Processed 112200 comments...\n",
            "✅ Processed 112240 comments...\n",
            "✅ Processed 112280 comments...\n",
            "✅ Processed 112320 comments...\n",
            "✅ Processed 112360 comments...\n",
            "✅ Processed 112400 comments...\n",
            "✅ Processed 112440 comments...\n",
            "✅ Processed 112480 comments...\n",
            "✅ Processed 112520 comments...\n",
            "✅ Processed 112560 comments...\n",
            "✅ Processed 112600 comments...\n",
            "✅ Processed 112640 comments...\n",
            "✅ Processed 112680 comments...\n",
            "✅ Processed 112720 comments...\n",
            "✅ Processed 112760 comments...\n",
            "✅ Processed 112800 comments...\n",
            "✅ Processed 112840 comments...\n",
            "✅ Processed 112880 comments...\n",
            "✅ Processed 112920 comments...\n",
            "✅ Processed 112960 comments...\n",
            "✅ Processed 113000 comments...\n",
            "✅ Processed 113040 comments...\n",
            "✅ Processed 113080 comments...\n",
            "✅ Processed 113120 comments...\n",
            "✅ Processed 113160 comments...\n",
            "✅ Processed 113200 comments...\n",
            "✅ Processed 113240 comments...\n",
            "✅ Processed 113280 comments...\n",
            "✅ Processed 113320 comments...\n",
            "✅ Processed 113360 comments...\n",
            "✅ Processed 113400 comments...\n",
            "✅ Processed 113440 comments...\n",
            "✅ Processed 113480 comments...\n",
            "✅ Processed 113520 comments...\n",
            "✅ Processed 113560 comments...\n",
            "✅ Processed 113600 comments...\n",
            "✅ Processed 113640 comments...\n",
            "✅ Processed 113680 comments...\n",
            "✅ Processed 113720 comments...\n",
            "✅ Processed 113760 comments...\n",
            "✅ Processed 113800 comments...\n",
            "✅ Processed 113840 comments...\n",
            "✅ Processed 113880 comments...\n",
            "✅ Processed 113920 comments...\n",
            "✅ Processed 113960 comments...\n",
            "✅ Processed 114000 comments...\n",
            "✅ Processed 114040 comments...\n",
            "✅ Processed 114080 comments...\n",
            "✅ Processed 114120 comments...\n",
            "✅ Processed 114160 comments...\n",
            "✅ Processed 114200 comments...\n",
            "✅ Processed 114240 comments...\n",
            "✅ Processed 114280 comments...\n",
            "✅ Processed 114320 comments...\n",
            "✅ Processed 114360 comments...\n",
            "✅ Processed 114400 comments...\n",
            "✅ Processed 114440 comments...\n",
            "✅ Processed 114480 comments...\n",
            "✅ Processed 114520 comments...\n",
            "✅ Processed 114560 comments...\n",
            "✅ Processed 114600 comments...\n",
            "✅ Processed 114640 comments...\n",
            "✅ Processed 114680 comments...\n",
            "✅ Processed 114720 comments...\n",
            "✅ Processed 114760 comments...\n",
            "✅ Processed 114800 comments...\n",
            "✅ Processed 114840 comments...\n",
            "✅ Processed 114880 comments...\n",
            "✅ Processed 114920 comments...\n",
            "✅ Processed 114960 comments...\n",
            "✅ Processed 115000 comments...\n",
            "✅ Processed 115040 comments...\n",
            "✅ Processed 115080 comments...\n",
            "✅ Processed 115120 comments...\n",
            "✅ Processed 115160 comments...\n",
            "✅ Processed 115200 comments...\n",
            "✅ Processed 115240 comments...\n",
            "✅ Processed 115280 comments...\n",
            "✅ Processed 115320 comments...\n",
            "✅ Processed 115360 comments...\n",
            "✅ Processed 115400 comments...\n",
            "✅ Processed 115440 comments...\n",
            "✅ Processed 115480 comments...\n",
            "✅ Processed 115520 comments...\n",
            "✅ Processed 115560 comments...\n",
            "✅ Processed 115600 comments...\n",
            "✅ Processed 115640 comments...\n",
            "✅ Processed 115680 comments...\n",
            "✅ Processed 115720 comments...\n",
            "✅ Processed 115760 comments...\n",
            "✅ Processed 115800 comments...\n",
            "✅ Processed 115840 comments...\n",
            "✅ Processed 115880 comments...\n",
            "✅ Processed 115920 comments...\n",
            "✅ Processed 115960 comments...\n",
            "✅ Processed 116000 comments...\n",
            "✅ Processed 116040 comments...\n",
            "✅ Processed 116080 comments...\n",
            "✅ Processed 116120 comments...\n",
            "✅ Processed 116160 comments...\n",
            "✅ Processed 116200 comments...\n",
            "✅ Processed 116240 comments...\n",
            "✅ Processed 116280 comments...\n",
            "✅ Processed 116320 comments...\n",
            "✅ Processed 116360 comments...\n",
            "✅ Processed 116400 comments...\n",
            "✅ Processed 116440 comments...\n",
            "✅ Processed 116480 comments...\n",
            "✅ Processed 116520 comments...\n",
            "✅ Processed 116560 comments...\n",
            "✅ Processed 116600 comments...\n",
            "✅ Processed 116640 comments...\n",
            "✅ Processed 116680 comments...\n",
            "✅ Processed 116720 comments...\n",
            "✅ Processed 116760 comments...\n",
            "✅ Processed 116800 comments...\n",
            "✅ Processed 116840 comments...\n",
            "✅ Processed 116880 comments...\n",
            "✅ Processed 116920 comments...\n",
            "✅ Processed 116960 comments...\n",
            "✅ Processed 117000 comments...\n",
            "✅ Processed 117040 comments...\n",
            "✅ Processed 117080 comments...\n",
            "✅ Processed 117120 comments...\n",
            "✅ Processed 117160 comments...\n",
            "✅ Processed 117200 comments...\n",
            "✅ Processed 117240 comments...\n",
            "✅ Processed 117280 comments...\n",
            "✅ Processed 117320 comments...\n",
            "✅ Processed 117360 comments...\n",
            "✅ Processed 117400 comments...\n",
            "✅ Processed 117440 comments...\n",
            "✅ Processed 117480 comments...\n",
            "✅ Processed 117520 comments...\n",
            "✅ Processed 117560 comments...\n",
            "✅ Processed 117600 comments...\n",
            "✅ Processed 117640 comments...\n",
            "✅ Processed 117680 comments...\n",
            "✅ Processed 117720 comments...\n",
            "✅ Processed 117760 comments...\n",
            "✅ Processed 117800 comments...\n",
            "✅ Processed 117840 comments...\n",
            "✅ Processed 117880 comments...\n",
            "✅ Processed 117920 comments...\n",
            "✅ Processed 117960 comments...\n",
            "✅ Processed 118000 comments...\n",
            "✅ Processed 118040 comments...\n",
            "✅ Processed 118080 comments...\n",
            "✅ Processed 118120 comments...\n",
            "✅ Processed 118160 comments...\n",
            "✅ Processed 118200 comments...\n",
            "✅ Processed 118240 comments...\n",
            "✅ Processed 118280 comments...\n",
            "✅ Processed 118320 comments...\n",
            "✅ Processed 118360 comments...\n",
            "✅ Processed 118400 comments...\n",
            "✅ Processed 118440 comments...\n",
            "✅ Processed 118480 comments...\n",
            "✅ Processed 118520 comments...\n",
            "✅ Processed 118560 comments...\n",
            "✅ Processed 118600 comments...\n",
            "✅ Processed 118640 comments...\n",
            "✅ Processed 118680 comments...\n",
            "✅ Processed 118720 comments...\n",
            "✅ Processed 118760 comments...\n",
            "✅ Processed 118800 comments...\n",
            "✅ Processed 118840 comments...\n",
            "✅ Processed 118880 comments...\n",
            "✅ Processed 118920 comments...\n",
            "✅ Processed 118960 comments...\n",
            "✅ Processed 119000 comments...\n",
            "✅ Processed 119040 comments...\n",
            "✅ Processed 119080 comments...\n",
            "✅ Processed 119120 comments...\n",
            "✅ Processed 119160 comments...\n",
            "✅ Processed 119200 comments...\n",
            "✅ Processed 119240 comments...\n",
            "✅ Processed 119280 comments...\n",
            "✅ Processed 119320 comments...\n",
            "✅ Processed 119360 comments...\n",
            "✅ Processed 119400 comments...\n",
            "✅ Processed 119440 comments...\n",
            "✅ Processed 119480 comments...\n",
            "✅ Processed 119520 comments...\n",
            "✅ Processed 119560 comments...\n",
            "✅ Processed 119600 comments...\n",
            "✅ Processed 119640 comments...\n",
            "✅ Processed 119680 comments...\n",
            "✅ Processed 119720 comments...\n",
            "✅ Processed 119760 comments...\n",
            "✅ Processed 119800 comments...\n",
            "✅ Processed 119840 comments...\n",
            "✅ Processed 119880 comments...\n",
            "✅ Processed 119920 comments...\n",
            "✅ Processed 119960 comments...\n",
            "✅ Processed 120000 comments...\n",
            "✅ Processed 120040 comments...\n",
            "✅ Processed 120080 comments...\n",
            "✅ Processed 120120 comments...\n",
            "✅ Processed 120160 comments...\n",
            "✅ Processed 120200 comments...\n",
            "✅ Processed 120240 comments...\n",
            "✅ Processed 120280 comments...\n",
            "✅ Processed 120320 comments...\n",
            "✅ Processed 120360 comments...\n",
            "✅ Processed 120400 comments...\n",
            "✅ Processed 120440 comments...\n",
            "✅ Processed 120480 comments...\n",
            "✅ Processed 120520 comments...\n",
            "✅ Processed 120560 comments...\n",
            "✅ Processed 120600 comments...\n",
            "✅ Processed 120640 comments...\n",
            "✅ Processed 120680 comments...\n",
            "✅ Processed 120720 comments...\n",
            "✅ Processed 120760 comments...\n",
            "✅ Processed 120800 comments...\n",
            "✅ Processed 120840 comments...\n",
            "✅ Processed 120880 comments...\n",
            "✅ Processed 120920 comments...\n",
            "✅ Processed 120960 comments...\n",
            "✅ Processed 121000 comments...\n",
            "✅ Processed 121040 comments...\n",
            "✅ Processed 121080 comments...\n",
            "✅ Processed 121120 comments...\n",
            "✅ Processed 121160 comments...\n",
            "✅ Processed 121200 comments...\n",
            "✅ Processed 121240 comments...\n",
            "✅ Processed 121280 comments...\n",
            "✅ Processed 121320 comments...\n",
            "✅ Processed 121360 comments...\n",
            "✅ Processed 121400 comments...\n",
            "✅ Processed 121440 comments...\n",
            "✅ Processed 121480 comments...\n",
            "✅ Processed 121520 comments...\n",
            "✅ Processed 121560 comments...\n",
            "✅ Processed 121600 comments...\n",
            "✅ Processed 121640 comments...\n",
            "✅ Processed 121680 comments...\n",
            "✅ Processed 121720 comments...\n",
            "✅ Processed 121760 comments...\n",
            "✅ Processed 121800 comments...\n",
            "✅ Processed 121840 comments...\n",
            "✅ Processed 121880 comments...\n",
            "✅ Processed 121920 comments...\n",
            "✅ Processed 121960 comments...\n",
            "✅ Processed 122000 comments...\n",
            "✅ Processed 122040 comments...\n",
            "✅ Processed 122080 comments...\n",
            "✅ Processed 122120 comments...\n",
            "✅ Processed 122160 comments...\n",
            "✅ Processed 122200 comments...\n",
            "✅ Processed 122240 comments...\n",
            "✅ Processed 122280 comments...\n",
            "✅ Processed 122320 comments...\n",
            "✅ Processed 122360 comments...\n",
            "✅ Processed 122400 comments...\n",
            "✅ Processed 122440 comments...\n",
            "✅ Processed 122480 comments...\n",
            "✅ Processed 122520 comments...\n",
            "✅ Processed 122560 comments...\n",
            "✅ Processed 122600 comments...\n",
            "✅ Processed 122640 comments...\n",
            "✅ Processed 122680 comments...\n",
            "✅ Processed 122720 comments...\n",
            "✅ Processed 122760 comments...\n",
            "✅ Processed 122800 comments...\n",
            "✅ Processed 122840 comments...\n",
            "✅ Processed 122880 comments...\n",
            "✅ Processed 122920 comments...\n",
            "✅ Processed 122960 comments...\n",
            "✅ Processed 123000 comments...\n",
            "✅ Processed 123040 comments...\n",
            "✅ Processed 123080 comments...\n",
            "✅ Processed 123120 comments...\n",
            "✅ Processed 123160 comments...\n",
            "✅ Processed 123200 comments...\n",
            "✅ Processed 123240 comments...\n",
            "✅ Processed 123280 comments...\n",
            "✅ Processed 123320 comments...\n",
            "✅ Processed 123360 comments...\n",
            "✅ Processed 123400 comments...\n",
            "✅ Processed 123440 comments...\n",
            "✅ Processed 123480 comments...\n",
            "✅ Processed 123520 comments...\n",
            "✅ Processed 123560 comments...\n",
            "✅ Processed 123600 comments...\n",
            "✅ Processed 123640 comments...\n",
            "✅ Processed 123680 comments...\n",
            "✅ Processed 123720 comments...\n",
            "✅ Processed 123760 comments...\n",
            "✅ Processed 123800 comments...\n",
            "✅ Processed 123840 comments...\n",
            "✅ Processed 123880 comments...\n",
            "✅ Processed 123920 comments...\n",
            "✅ Processed 123960 comments...\n",
            "✅ Processed 124000 comments...\n",
            "✅ Processed 124040 comments...\n",
            "✅ Processed 124080 comments...\n",
            "✅ Processed 124120 comments...\n",
            "✅ Processed 124160 comments...\n",
            "✅ Processed 124200 comments...\n",
            "✅ Processed 124240 comments...\n",
            "✅ Processed 124280 comments...\n",
            "✅ Processed 124320 comments...\n",
            "✅ Processed 124360 comments...\n",
            "✅ Processed 124400 comments...\n",
            "✅ Processed 124440 comments...\n",
            "✅ Processed 124480 comments...\n",
            "✅ Processed 124520 comments...\n",
            "✅ Processed 124560 comments...\n",
            "✅ Processed 124600 comments...\n",
            "✅ Processed 124640 comments...\n",
            "✅ Processed 124680 comments...\n",
            "✅ Processed 124720 comments...\n",
            "✅ Processed 124760 comments...\n",
            "✅ Processed 124800 comments...\n",
            "✅ Processed 124840 comments...\n",
            "✅ Processed 124880 comments...\n",
            "✅ Processed 124920 comments...\n",
            "✅ Processed 124960 comments...\n",
            "✅ Processed 125000 comments...\n",
            "✅ Processed 125040 comments...\n",
            "✅ Processed 125080 comments...\n",
            "✅ Processed 125120 comments...\n",
            "✅ Processed 125160 comments...\n",
            "✅ Processed 125200 comments...\n",
            "✅ Processed 125240 comments...\n",
            "✅ Processed 125280 comments...\n",
            "✅ Processed 125320 comments...\n",
            "✅ Processed 125360 comments...\n",
            "✅ Processed 125400 comments...\n",
            "✅ Processed 125440 comments...\n",
            "✅ Processed 125480 comments...\n",
            "✅ Processed 125520 comments...\n",
            "✅ Processed 125560 comments...\n",
            "✅ Processed 125600 comments...\n",
            "✅ Processed 125640 comments...\n",
            "✅ Processed 125680 comments...\n",
            "✅ Processed 125720 comments...\n",
            "✅ Processed 125760 comments...\n",
            "✅ Processed 125800 comments...\n",
            "✅ Processed 125840 comments...\n",
            "✅ Processed 125880 comments...\n",
            "✅ Processed 125920 comments...\n",
            "✅ Processed 125960 comments...\n",
            "✅ Processed 126000 comments...\n",
            "✅ Processed 126040 comments...\n",
            "✅ Processed 126080 comments...\n",
            "✅ Processed 126120 comments...\n",
            "✅ Processed 126160 comments...\n",
            "✅ Processed 126200 comments...\n",
            "✅ Processed 126240 comments...\n",
            "✅ Processed 126280 comments...\n",
            "✅ Processed 126320 comments...\n",
            "✅ Processed 126360 comments...\n",
            "✅ Processed 126400 comments...\n",
            "✅ Processed 126440 comments...\n",
            "✅ Processed 126480 comments...\n",
            "✅ Processed 126520 comments...\n",
            "✅ Processed 126560 comments...\n",
            "✅ Processed 126600 comments...\n",
            "✅ Processed 126640 comments...\n",
            "✅ Processed 126680 comments...\n",
            "✅ Processed 126720 comments...\n",
            "✅ Processed 126760 comments...\n",
            "✅ Processed 126800 comments...\n",
            "✅ Processed 126840 comments...\n",
            "✅ Processed 126880 comments...\n",
            "✅ Processed 126920 comments...\n",
            "✅ Processed 126960 comments...\n",
            "✅ Processed 127000 comments...\n",
            "✅ Processed 127040 comments...\n",
            "✅ Processed 127080 comments...\n",
            "✅ Processed 127120 comments...\n",
            "✅ Processed 127160 comments...\n",
            "✅ Processed 127200 comments...\n",
            "✅ Processed 127240 comments...\n",
            "✅ Processed 127280 comments...\n",
            "✅ Processed 127320 comments...\n",
            "✅ Processed 127360 comments...\n",
            "✅ Processed 127400 comments...\n",
            "✅ Processed 127440 comments...\n",
            "✅ Processed 127480 comments...\n",
            "✅ Processed 127520 comments...\n",
            "✅ Processed 127560 comments...\n",
            "✅ Processed 127600 comments...\n",
            "✅ Processed 127640 comments...\n",
            "✅ Processed 127680 comments...\n",
            "✅ Processed 127720 comments...\n",
            "✅ Processed 127760 comments...\n",
            "✅ Processed 127800 comments...\n",
            "✅ Processed 127840 comments...\n",
            "✅ Processed 127880 comments...\n",
            "✅ Processed 127920 comments...\n",
            "✅ Processed 127960 comments...\n",
            "✅ Processed 128000 comments...\n",
            "✅ Processed 128040 comments...\n",
            "✅ Processed 128080 comments...\n",
            "✅ Processed 128120 comments...\n",
            "✅ Processed 128160 comments...\n",
            "✅ Processed 128200 comments...\n",
            "✅ Processed 128240 comments...\n",
            "✅ Processed 128280 comments...\n",
            "✅ Processed 128320 comments...\n",
            "✅ Processed 128360 comments...\n",
            "✅ Processed 128400 comments...\n",
            "✅ Processed 128440 comments...\n",
            "✅ Processed 128480 comments...\n",
            "✅ Processed 128520 comments...\n",
            "✅ Processed 128560 comments...\n",
            "✅ Processed 128600 comments...\n",
            "✅ Processed 128640 comments...\n",
            "✅ Processed 128680 comments...\n",
            "✅ Processed 128720 comments...\n",
            "✅ Processed 128760 comments...\n",
            "✅ Processed 128800 comments...\n",
            "✅ Processed 128840 comments...\n",
            "✅ Processed 128880 comments...\n",
            "✅ Processed 128920 comments...\n",
            "✅ Processed 128960 comments...\n",
            "✅ Processed 129000 comments...\n",
            "✅ Processed 129040 comments...\n",
            "✅ Processed 129080 comments...\n",
            "✅ Processed 129120 comments...\n",
            "✅ Processed 129160 comments...\n",
            "✅ Processed 129200 comments...\n",
            "✅ Processed 129240 comments...\n",
            "✅ Processed 129280 comments...\n",
            "✅ Processed 129320 comments...\n",
            "✅ Processed 129360 comments...\n",
            "✅ Processed 129400 comments...\n",
            "✅ Processed 129440 comments...\n",
            "✅ Processed 129480 comments...\n",
            "✅ Processed 129520 comments...\n",
            "✅ Processed 129560 comments...\n",
            "✅ Processed 129600 comments...\n",
            "✅ Processed 129640 comments...\n",
            "✅ Processed 129680 comments...\n",
            "✅ Processed 129720 comments...\n",
            "✅ Processed 129760 comments...\n",
            "✅ Processed 129800 comments...\n",
            "✅ Processed 129840 comments...\n",
            "✅ Processed 129880 comments...\n",
            "✅ Processed 129920 comments...\n",
            "✅ Processed 129960 comments...\n",
            "✅ Processed 130000 comments...\n",
            "✅ Processed 130040 comments...\n",
            "✅ Processed 130080 comments...\n",
            "✅ Processed 130120 comments...\n",
            "✅ Processed 130160 comments...\n",
            "✅ Processed 130200 comments...\n",
            "✅ Processed 130240 comments...\n",
            "✅ Processed 130280 comments...\n",
            "✅ Processed 130320 comments...\n",
            "✅ Processed 130360 comments...\n",
            "✅ Processed 130400 comments...\n",
            "✅ Processed 130440 comments...\n",
            "✅ Processed 130480 comments...\n",
            "✅ Processed 130520 comments...\n",
            "✅ Processed 130560 comments...\n",
            "✅ Processed 130600 comments...\n",
            "✅ Processed 130640 comments...\n",
            "✅ Processed 130680 comments...\n",
            "✅ Processed 130720 comments...\n",
            "✅ Processed 130760 comments...\n",
            "✅ Processed 130800 comments...\n",
            "✅ Processed 130840 comments...\n",
            "✅ Processed 130880 comments...\n",
            "✅ Processed 130920 comments...\n",
            "✅ Processed 130960 comments...\n",
            "✅ Processed 131000 comments...\n",
            "✅ Processed 131040 comments...\n",
            "✅ Processed 131080 comments...\n",
            "✅ Processed 131120 comments...\n",
            "✅ Processed 131160 comments...\n",
            "✅ Processed 131200 comments...\n",
            "✅ Processed 131240 comments...\n",
            "✅ Processed 131280 comments...\n",
            "✅ Processed 131320 comments...\n",
            "✅ Processed 131360 comments...\n",
            "✅ Processed 131400 comments...\n",
            "✅ Processed 131440 comments...\n",
            "✅ Processed 131480 comments...\n",
            "✅ Processed 131520 comments...\n",
            "✅ Processed 131560 comments...\n",
            "✅ Processed 131600 comments...\n",
            "✅ Processed 131640 comments...\n",
            "✅ Processed 131680 comments...\n",
            "✅ Processed 131720 comments...\n",
            "✅ Processed 131760 comments...\n",
            "✅ Processed 131800 comments...\n",
            "✅ Processed 131840 comments...\n",
            "✅ Processed 131880 comments...\n",
            "✅ Processed 131920 comments...\n",
            "✅ Processed 131960 comments...\n",
            "✅ Processed 132000 comments...\n",
            "✅ Processed 132040 comments...\n",
            "✅ Processed 132080 comments...\n",
            "✅ Processed 132120 comments...\n",
            "✅ Processed 132160 comments...\n",
            "✅ Processed 132200 comments...\n",
            "✅ Processed 132240 comments...\n",
            "✅ Processed 132280 comments...\n",
            "✅ Processed 132320 comments...\n",
            "✅ Processed 132360 comments...\n",
            "✅ Processed 132400 comments...\n",
            "✅ Processed 132440 comments...\n",
            "✅ Processed 132480 comments...\n",
            "✅ Processed 132520 comments...\n",
            "✅ Processed 132560 comments...\n",
            "✅ Processed 132600 comments...\n",
            "✅ Processed 132640 comments...\n",
            "✅ Processed 132680 comments...\n",
            "✅ Processed 132720 comments...\n",
            "✅ Processed 132760 comments...\n",
            "✅ Processed 132800 comments...\n",
            "✅ Processed 132840 comments...\n",
            "✅ Processed 132880 comments...\n",
            "✅ Processed 132920 comments...\n",
            "✅ Processed 132960 comments...\n",
            "✅ Processed 133000 comments...\n",
            "✅ Processed 133040 comments...\n",
            "✅ Processed 133080 comments...\n",
            "✅ Processed 133120 comments...\n",
            "✅ Processed 133160 comments...\n",
            "✅ Processed 133200 comments...\n",
            "✅ Processed 133240 comments...\n",
            "✅ Processed 133280 comments...\n",
            "✅ Processed 133320 comments...\n",
            "✅ Processed 133360 comments...\n",
            "✅ Processed 133400 comments...\n",
            "✅ Processed 133440 comments...\n",
            "✅ Processed 133480 comments...\n",
            "✅ Processed 133520 comments...\n",
            "✅ Processed 133560 comments...\n",
            "✅ Processed 133600 comments...\n",
            "✅ Processed 133640 comments...\n",
            "✅ Processed 133680 comments...\n",
            "✅ Processed 133720 comments...\n",
            "✅ Processed 133760 comments...\n",
            "✅ Processed 133800 comments...\n",
            "✅ Processed 133840 comments...\n",
            "✅ Processed 133880 comments...\n",
            "✅ Processed 133920 comments...\n",
            "✅ Processed 133960 comments...\n",
            "✅ Processed 134000 comments...\n",
            "✅ Processed 134040 comments...\n",
            "✅ Processed 134080 comments...\n",
            "✅ Processed 134120 comments...\n",
            "✅ Processed 134160 comments...\n",
            "✅ Processed 134200 comments...\n",
            "✅ Processed 134240 comments...\n",
            "✅ Processed 134280 comments...\n",
            "✅ Processed 134320 comments...\n",
            "✅ Processed 134360 comments...\n",
            "✅ Processed 134400 comments...\n",
            "✅ Processed 134440 comments...\n",
            "✅ Processed 134480 comments...\n",
            "✅ Processed 134520 comments...\n",
            "✅ Processed 134560 comments...\n",
            "✅ Processed 134600 comments...\n",
            "✅ Processed 134640 comments...\n",
            "✅ Processed 134680 comments...\n",
            "✅ Processed 134720 comments...\n",
            "✅ Processed 134760 comments...\n",
            "✅ Processed 134800 comments...\n",
            "✅ Processed 134840 comments...\n",
            "✅ Processed 134880 comments...\n",
            "✅ Processed 134920 comments...\n",
            "✅ Processed 134960 comments...\n",
            "✅ Processed 135000 comments...\n",
            "✅ Processed 135040 comments...\n",
            "✅ Processed 135080 comments...\n",
            "✅ Processed 135120 comments...\n",
            "✅ Processed 135160 comments...\n",
            "✅ Processed 135200 comments...\n",
            "✅ Processed 135240 comments...\n",
            "✅ Processed 135280 comments...\n",
            "✅ Processed 135320 comments...\n",
            "✅ Processed 135360 comments...\n",
            "✅ Processed 135400 comments...\n",
            "✅ Processed 135440 comments...\n",
            "✅ Processed 135480 comments...\n",
            "✅ Processed 135520 comments...\n",
            "✅ Processed 135560 comments...\n",
            "✅ Processed 135600 comments...\n",
            "✅ Processed 135640 comments...\n",
            "✅ Processed 135680 comments...\n",
            "✅ Processed 135720 comments...\n",
            "✅ Processed 135760 comments...\n",
            "✅ Processed 135800 comments...\n",
            "✅ Processed 135840 comments...\n",
            "✅ Processed 135880 comments...\n",
            "✅ Processed 135920 comments...\n",
            "✅ Processed 135960 comments...\n",
            "✅ Processed 136000 comments...\n",
            "✅ Processed 136040 comments...\n",
            "✅ Processed 136080 comments...\n",
            "✅ Processed 136120 comments...\n",
            "✅ Processed 136160 comments...\n",
            "✅ Processed 136200 comments...\n",
            "✅ Processed 136240 comments...\n",
            "✅ Processed 136280 comments...\n",
            "✅ Processed 136320 comments...\n",
            "✅ Processed 136360 comments...\n",
            "✅ Processed 136400 comments...\n",
            "✅ Processed 136440 comments...\n",
            "✅ Processed 136480 comments...\n",
            "✅ Processed 136520 comments...\n",
            "✅ Processed 136560 comments...\n",
            "✅ Processed 136600 comments...\n",
            "✅ Processed 136640 comments...\n",
            "✅ Processed 136680 comments...\n",
            "✅ Processed 136720 comments...\n",
            "✅ Processed 136760 comments...\n",
            "✅ Processed 136800 comments...\n",
            "✅ Processed 136840 comments...\n",
            "✅ Processed 136880 comments...\n",
            "✅ Processed 136920 comments...\n",
            "✅ Processed 136960 comments...\n",
            "✅ Processed 137000 comments...\n",
            "✅ Processed 137040 comments...\n",
            "✅ Processed 137080 comments...\n",
            "✅ Processed 137120 comments...\n",
            "✅ Processed 137160 comments...\n",
            "✅ Processed 137200 comments...\n",
            "✅ Processed 137240 comments...\n",
            "✅ Processed 137280 comments...\n",
            "✅ Processed 137320 comments...\n",
            "✅ Processed 137360 comments...\n",
            "✅ Processed 137400 comments...\n",
            "✅ Processed 137440 comments...\n",
            "✅ Processed 137480 comments...\n",
            "✅ Processed 137520 comments...\n",
            "✅ Processed 137560 comments...\n",
            "✅ Processed 137600 comments...\n",
            "✅ Processed 137640 comments...\n",
            "✅ Processed 137680 comments...\n",
            "✅ Processed 137720 comments...\n",
            "✅ Processed 137760 comments...\n",
            "✅ Processed 137800 comments...\n",
            "✅ Processed 137840 comments...\n",
            "✅ Processed 137880 comments...\n",
            "✅ Processed 137920 comments...\n",
            "✅ Processed 137960 comments...\n",
            "✅ Processed 138000 comments...\n",
            "✅ Processed 138040 comments...\n",
            "✅ Processed 138080 comments...\n",
            "✅ Processed 138120 comments...\n",
            "✅ Processed 138160 comments...\n",
            "✅ Processed 138200 comments...\n",
            "✅ Processed 138240 comments...\n",
            "✅ Processed 138280 comments...\n",
            "✅ Processed 138320 comments...\n",
            "✅ Processed 138360 comments...\n",
            "✅ Processed 138400 comments...\n",
            "✅ Processed 138440 comments...\n",
            "✅ Processed 138480 comments...\n",
            "✅ Processed 138520 comments...\n",
            "✅ Processed 138560 comments...\n",
            "✅ Processed 138600 comments...\n",
            "✅ Processed 138640 comments...\n",
            "✅ Processed 138680 comments...\n",
            "✅ Processed 138720 comments...\n",
            "✅ Processed 138760 comments...\n",
            "✅ Processed 138800 comments...\n",
            "✅ Processed 138840 comments...\n",
            "✅ Processed 138880 comments...\n",
            "✅ Processed 138920 comments...\n",
            "✅ Processed 138960 comments...\n",
            "✅ Processed 139000 comments...\n",
            "✅ Processed 139040 comments...\n",
            "✅ Processed 139080 comments...\n",
            "✅ Processed 139120 comments...\n",
            "✅ Processed 139160 comments...\n",
            "✅ Processed 139200 comments...\n",
            "✅ Processed 139240 comments...\n",
            "✅ Processed 139280 comments...\n",
            "✅ Processed 139320 comments...\n",
            "✅ Processed 139360 comments...\n",
            "✅ Processed 139400 comments...\n",
            "✅ Processed 139440 comments...\n",
            "✅ Processed 139480 comments...\n",
            "✅ Processed 139520 comments...\n",
            "✅ Processed 139560 comments...\n",
            "✅ Processed 139600 comments...\n",
            "✅ Processed 139640 comments...\n",
            "✅ Processed 139680 comments...\n",
            "✅ Processed 139720 comments...\n",
            "✅ Processed 139760 comments...\n",
            "✅ Processed 139800 comments...\n",
            "✅ Processed 139840 comments...\n",
            "✅ Processed 139880 comments...\n",
            "✅ Processed 139920 comments...\n",
            "✅ Processed 139960 comments...\n",
            "✅ Processed 140000 comments...\n",
            "✅ Processed 140040 comments...\n",
            "✅ Processed 140080 comments...\n",
            "✅ Processed 140120 comments...\n",
            "✅ Processed 140160 comments...\n",
            "✅ Processed 140200 comments...\n",
            "✅ Processed 140240 comments...\n",
            "✅ Processed 140280 comments...\n",
            "✅ Processed 140320 comments...\n",
            "✅ Processed 140360 comments...\n",
            "✅ Processed 140400 comments...\n",
            "✅ Processed 140440 comments...\n",
            "✅ Processed 140480 comments...\n",
            "✅ Processed 140520 comments...\n",
            "✅ Processed 140560 comments...\n",
            "✅ Processed 140600 comments...\n",
            "✅ Processed 140640 comments...\n",
            "✅ Processed 140680 comments...\n",
            "✅ Processed 140720 comments...\n",
            "✅ Processed 140760 comments...\n",
            "✅ Processed 140800 comments...\n",
            "✅ Processed 140840 comments...\n",
            "✅ Processed 140880 comments...\n",
            "✅ Processed 140920 comments...\n",
            "✅ Processed 140960 comments...\n",
            "✅ Processed 141000 comments...\n",
            "✅ Processed 141040 comments...\n",
            "✅ Processed 141080 comments...\n",
            "✅ Processed 141120 comments...\n",
            "✅ Processed 141160 comments...\n",
            "✅ Processed 141200 comments...\n",
            "✅ Processed 141240 comments...\n",
            "✅ Processed 141280 comments...\n",
            "✅ Processed 141320 comments...\n",
            "✅ Processed 141360 comments...\n",
            "✅ Processed 141400 comments...\n",
            "✅ Processed 141440 comments...\n",
            "✅ Processed 141480 comments...\n",
            "✅ Processed 141520 comments...\n",
            "✅ Processed 141560 comments...\n",
            "✅ Processed 141600 comments...\n",
            "✅ Processed 141640 comments...\n",
            "✅ Processed 141680 comments...\n",
            "✅ Processed 141720 comments...\n",
            "✅ Processed 141760 comments...\n",
            "✅ Processed 141800 comments...\n",
            "✅ Processed 141840 comments...\n",
            "✅ Processed 141880 comments...\n",
            "✅ Processed 141920 comments...\n",
            "✅ Processed 141960 comments...\n",
            "✅ Processed 142000 comments...\n",
            "✅ Processed 142040 comments...\n",
            "✅ Processed 142080 comments...\n",
            "✅ Processed 142120 comments...\n",
            "✅ Processed 142160 comments...\n",
            "✅ Processed 142200 comments...\n",
            "✅ Processed 142240 comments...\n",
            "✅ Processed 142280 comments...\n",
            "✅ Processed 142320 comments...\n",
            "✅ Processed 142360 comments...\n",
            "✅ Processed 142400 comments...\n",
            "✅ Processed 142440 comments...\n",
            "✅ Processed 142480 comments...\n",
            "✅ Processed 142520 comments...\n",
            "✅ Processed 142560 comments...\n",
            "✅ Processed 142600 comments...\n",
            "✅ Processed 142640 comments...\n",
            "✅ Processed 142680 comments...\n",
            "✅ Processed 142720 comments...\n",
            "✅ Processed 142760 comments...\n",
            "✅ Processed 142800 comments...\n",
            "✅ Processed 142840 comments...\n",
            "✅ Processed 142880 comments...\n",
            "✅ Processed 142920 comments...\n",
            "✅ Processed 142960 comments...\n",
            "✅ Processed 143000 comments...\n",
            "✅ Processed 143040 comments...\n",
            "✅ Processed 143080 comments...\n",
            "✅ Processed 143120 comments...\n",
            "✅ Processed 143160 comments...\n",
            "✅ Processed 143200 comments...\n",
            "✅ Processed 143240 comments...\n",
            "✅ Processed 143280 comments...\n",
            "✅ Processed 143320 comments...\n",
            "✅ Processed 143360 comments...\n",
            "✅ Processed 143400 comments...\n",
            "✅ Processed 143440 comments...\n",
            "✅ Processed 143480 comments...\n",
            "✅ Processed 143520 comments...\n",
            "✅ Processed 143560 comments...\n",
            "✅ Processed 143600 comments...\n",
            "✅ Processed 143640 comments...\n",
            "✅ Processed 143680 comments...\n",
            "✅ Processed 143720 comments...\n",
            "✅ Processed 143760 comments...\n",
            "✅ Processed 143800 comments...\n",
            "✅ Processed 143840 comments...\n",
            "✅ Processed 143880 comments...\n",
            "✅ Processed 143920 comments...\n",
            "✅ Processed 143960 comments...\n",
            "✅ Processed 144000 comments...\n",
            "✅ Processed 144040 comments...\n",
            "✅ Processed 144080 comments...\n",
            "✅ Processed 144120 comments...\n",
            "✅ Processed 144160 comments...\n",
            "✅ Processed 144200 comments...\n",
            "✅ Processed 144240 comments...\n",
            "✅ Processed 144280 comments...\n",
            "✅ Processed 144320 comments...\n",
            "✅ Processed 144360 comments...\n",
            "✅ Processed 144400 comments...\n",
            "✅ Processed 144440 comments...\n",
            "✅ Processed 144480 comments...\n",
            "✅ Processed 144520 comments...\n",
            "✅ Processed 144560 comments...\n",
            "✅ Processed 144600 comments...\n",
            "✅ Processed 144640 comments...\n",
            "✅ Processed 144680 comments...\n",
            "✅ Processed 144720 comments...\n",
            "✅ Processed 144760 comments...\n",
            "✅ Processed 144800 comments...\n",
            "✅ Processed 144840 comments...\n",
            "✅ Processed 144880 comments...\n",
            "✅ Processed 144920 comments...\n",
            "✅ Processed 144960 comments...\n",
            "✅ Processed 145000 comments...\n",
            "✅ Processed 145040 comments...\n",
            "✅ Processed 145080 comments...\n",
            "✅ Processed 145120 comments...\n",
            "✅ Processed 145160 comments...\n",
            "✅ Processed 145200 comments...\n",
            "✅ Processed 145240 comments...\n",
            "✅ Processed 145280 comments...\n",
            "✅ Processed 145320 comments...\n",
            "✅ Processed 145360 comments...\n",
            "✅ Processed 145400 comments...\n",
            "✅ Processed 145440 comments...\n",
            "✅ Processed 145480 comments...\n",
            "✅ Processed 145520 comments...\n",
            "✅ Processed 145560 comments...\n",
            "✅ Processed 145600 comments...\n",
            "✅ Processed 145640 comments...\n",
            "✅ Processed 145680 comments...\n",
            "✅ Processed 145720 comments...\n",
            "✅ Processed 145760 comments...\n",
            "✅ Processed 145800 comments...\n",
            "✅ Processed 145840 comments...\n",
            "✅ Processed 145880 comments...\n",
            "✅ Processed 145920 comments...\n",
            "✅ Processed 145960 comments...\n",
            "✅ Processed 146000 comments...\n",
            "✅ Processed 146040 comments...\n",
            "✅ Processed 146080 comments...\n",
            "✅ Processed 146120 comments...\n",
            "✅ Processed 146160 comments...\n",
            "✅ Processed 146200 comments...\n",
            "✅ Processed 146240 comments...\n",
            "✅ Processed 146280 comments...\n",
            "✅ Processed 146320 comments...\n",
            "✅ Processed 146360 comments...\n",
            "✅ Processed 146400 comments...\n",
            "✅ Processed 146440 comments...\n",
            "✅ Processed 146480 comments...\n",
            "✅ Processed 146520 comments...\n",
            "✅ Processed 146560 comments...\n",
            "✅ Processed 146600 comments...\n",
            "✅ Processed 146640 comments...\n",
            "✅ Processed 146680 comments...\n",
            "✅ Processed 146720 comments...\n",
            "✅ Processed 146760 comments...\n",
            "✅ Processed 146800 comments...\n",
            "✅ Processed 146840 comments...\n",
            "✅ Processed 146880 comments...\n",
            "✅ Processed 146920 comments...\n",
            "✅ Processed 146960 comments...\n",
            "✅ Processed 147000 comments...\n",
            "✅ Processed 147040 comments...\n",
            "✅ Processed 147080 comments...\n",
            "✅ Processed 147120 comments...\n",
            "✅ Processed 147160 comments...\n",
            "✅ Processed 147200 comments...\n",
            "✅ Processed 147240 comments...\n",
            "✅ Processed 147280 comments...\n",
            "✅ Processed 147320 comments...\n",
            "✅ Processed 147360 comments...\n",
            "✅ Processed 147400 comments...\n",
            "✅ Processed 147440 comments...\n",
            "✅ Processed 147480 comments...\n",
            "✅ Processed 147520 comments...\n",
            "✅ Processed 147560 comments...\n",
            "✅ Processed 147600 comments...\n",
            "✅ Processed 147640 comments...\n",
            "✅ Processed 147680 comments...\n",
            "✅ Processed 147720 comments...\n",
            "✅ Processed 147760 comments...\n",
            "✅ Processed 147800 comments...\n",
            "✅ Processed 147840 comments...\n",
            "✅ Processed 147880 comments...\n",
            "✅ Processed 147920 comments...\n",
            "✅ Processed 147960 comments...\n",
            "✅ Processed 148000 comments...\n",
            "✅ Processed 148040 comments...\n",
            "✅ Processed 148080 comments...\n",
            "✅ Processed 148120 comments...\n",
            "✅ Processed 148160 comments...\n",
            "✅ Processed 148200 comments...\n",
            "✅ Processed 148240 comments...\n",
            "✅ Processed 148280 comments...\n",
            "✅ Processed 148320 comments...\n",
            "✅ Processed 148360 comments...\n",
            "✅ Processed 148400 comments...\n",
            "✅ Processed 148440 comments...\n",
            "✅ Processed 148480 comments...\n",
            "✅ Processed 148520 comments...\n",
            "✅ Processed 148560 comments...\n",
            "✅ Processed 148600 comments...\n",
            "✅ Processed 148640 comments...\n",
            "✅ Processed 148680 comments...\n",
            "✅ Processed 148720 comments...\n",
            "✅ Processed 148760 comments...\n",
            "✅ Processed 148800 comments...\n",
            "✅ Processed 148840 comments...\n",
            "✅ Processed 148880 comments...\n",
            "✅ Processed 148920 comments...\n",
            "✅ Processed 148960 comments...\n",
            "✅ Processed 149000 comments...\n",
            "✅ Processed 149040 comments...\n",
            "✅ Processed 149080 comments...\n",
            "✅ Processed 149120 comments...\n",
            "✅ Processed 149160 comments...\n",
            "✅ Processed 149200 comments...\n",
            "✅ Processed 149240 comments...\n",
            "✅ Processed 149280 comments...\n",
            "✅ Processed 149320 comments...\n",
            "✅ Processed 149360 comments...\n",
            "✅ Processed 149400 comments...\n",
            "✅ Processed 149440 comments...\n",
            "✅ Processed 149480 comments...\n",
            "✅ Processed 149520 comments...\n",
            "✅ Processed 149560 comments...\n",
            "✅ Processed 149600 comments...\n",
            "✅ Processed 149640 comments...\n",
            "✅ Processed 149680 comments...\n",
            "✅ Processed 149720 comments...\n",
            "✅ Processed 149760 comments...\n",
            "✅ Processed 149800 comments...\n",
            "✅ Processed 149840 comments...\n",
            "✅ Processed 149880 comments...\n",
            "✅ Processed 149920 comments...\n",
            "✅ Processed 149960 comments...\n",
            "✅ Processed 150000 comments...\n",
            "✅ Processed 150040 comments...\n",
            "✅ Processed 150080 comments...\n",
            "✅ Processed 150120 comments...\n",
            "✅ Processed 150160 comments...\n",
            "✅ Processed 150200 comments...\n",
            "✅ Processed 150240 comments...\n",
            "✅ Processed 150280 comments...\n",
            "✅ Processed 150320 comments...\n",
            "✅ Processed 150360 comments...\n",
            "✅ Processed 150400 comments...\n",
            "✅ Processed 150440 comments...\n",
            "✅ Processed 150480 comments...\n",
            "✅ Processed 150520 comments...\n",
            "✅ Processed 150560 comments...\n",
            "✅ Processed 150600 comments...\n",
            "✅ Processed 150640 comments...\n",
            "✅ Processed 150680 comments...\n",
            "✅ Processed 150720 comments...\n",
            "✅ Processed 150760 comments...\n",
            "✅ Processed 150800 comments...\n",
            "✅ Processed 150840 comments...\n",
            "✅ Processed 150880 comments...\n",
            "✅ Processed 150920 comments...\n",
            "✅ Processed 150960 comments...\n",
            "✅ Processed 151000 comments...\n",
            "✅ Processed 151040 comments...\n",
            "✅ Processed 151080 comments...\n",
            "✅ Processed 151120 comments...\n",
            "✅ Processed 151160 comments...\n",
            "✅ Processed 151200 comments...\n",
            "✅ Processed 151240 comments...\n",
            "✅ Processed 151280 comments...\n",
            "✅ Processed 151320 comments...\n",
            "✅ Processed 151360 comments...\n",
            "✅ Processed 151400 comments...\n",
            "✅ Processed 151440 comments...\n",
            "✅ Processed 151480 comments...\n",
            "✅ Processed 151520 comments...\n",
            "✅ Processed 151560 comments...\n",
            "✅ Processed 151600 comments...\n",
            "✅ Processed 151640 comments...\n",
            "✅ Processed 151680 comments...\n",
            "✅ Processed 151720 comments...\n",
            "✅ Processed 151760 comments...\n",
            "✅ Processed 151800 comments...\n",
            "✅ Processed 151840 comments...\n",
            "✅ Processed 151880 comments...\n",
            "✅ Processed 151920 comments...\n",
            "✅ Processed 151960 comments...\n",
            "✅ Processed 152000 comments...\n",
            "✅ Processed 152040 comments...\n",
            "✅ Processed 152080 comments...\n",
            "✅ Processed 152120 comments...\n",
            "✅ Processed 152160 comments...\n",
            "✅ Processed 152200 comments...\n",
            "✅ Processed 152240 comments...\n",
            "✅ Processed 152280 comments...\n",
            "✅ Processed 152320 comments...\n",
            "✅ Processed 152360 comments...\n",
            "✅ Processed 152400 comments...\n",
            "✅ Processed 152440 comments...\n",
            "✅ Processed 152480 comments...\n",
            "✅ Processed 152520 comments...\n",
            "✅ Processed 152560 comments...\n",
            "✅ Processed 152600 comments...\n",
            "✅ Processed 152640 comments...\n",
            "✅ Processed 152680 comments...\n",
            "✅ Processed 152720 comments...\n",
            "✅ Processed 152760 comments...\n",
            "✅ Processed 152800 comments...\n",
            "✅ Processed 152840 comments...\n",
            "✅ Processed 152880 comments...\n",
            "✅ Processed 152920 comments...\n",
            "✅ Processed 152960 comments...\n",
            "✅ Processed 153000 comments...\n",
            "✅ Processed 153040 comments...\n",
            "✅ Processed 153080 comments...\n",
            "✅ Processed 153120 comments...\n",
            "✅ Processed 153160 comments...\n",
            "✅ Inference complete! Predictions saved to 'test_predictions.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"test_predictions.csv\")\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNaozVne7UHM",
        "outputId": "aef63389-1a82-4778-984c-de7689fd7823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  id                                       comment_text  \\\n",
            "0   00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
            "1   0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
            "2   00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
            "3   00017563c3f7919a  :If you have a look back at the source, the in...   \n",
            "4   00017695ad8997eb          I don't anonymously edit articles at all.   \n",
            "5   0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
            "6   00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
            "7   000247e83dcc1211                   :Dear god this site is horrible.   \n",
            "8   00025358d4737918  \" \\n Only a fool can believe in such numbers. ...   \n",
            "9   00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...   \n",
            "10  0002eadc3b301559  I think its crap that the link to roggenbier i...   \n",
            "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n",
            "12  0003806b11932181  , 25 February 2010 (UTC) \\n\\n :::Looking it ov...   \n",
            "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n",
            "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n",
            "15  000634272d0d44eb  ==Current Position== \\n Anyone have confirmati...   \n",
            "16  000663aff0fffc80                           this other one from 1897   \n",
            "17  000689dd34e20979  == Reason for banning throwing == \\n\\n This ar...   \n",
            "18  000834769115370c  :: Wallamoose was changing the cited material ...   \n",
            "19  000844b52dee5f3f             |blocked]] from editing Wikipedia.   |   \n",
            "\n",
            "    predicted_label  \n",
            "0                 1  \n",
            "1                 1  \n",
            "2                 0  \n",
            "3                 0  \n",
            "4                 1  \n",
            "5                 0  \n",
            "6                 0  \n",
            "7                 0  \n",
            "8                 0  \n",
            "9                 0  \n",
            "10                1  \n",
            "11                1  \n",
            "12                0  \n",
            "13                1  \n",
            "14                1  \n",
            "15                0  \n",
            "16                0  \n",
            "17                1  \n",
            "18                1  \n",
            "19                0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "7jAR38Lc7_Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1BLg3v5e8DEl",
        "outputId": "809d7860-9f1a-491b-f258-eb6f2bc5db28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2cf7bd40-56e9-4d99-b30f-c82972e12d84\", \"model.pth\", 438003462)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}